#!/usr/bin/env python3
"""
å›æµ‹é¡µé¢ç»„ä»¶
ç”¨äºå±•ç¤ºè‚¡ç¥¨åˆ†æç»“æœçš„å›æµ‹æ•ˆæœ
"""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging
import re

logger = logging.getLogger(__name__)

try:
    from web.utils.mongodb_report_manager import MongoDBReportManager, MONGODB_AVAILABLE
except ImportError:
    MONGODB_AVAILABLE = False
    logger.warning("MongoDBæ¨¡å—ä¸å¯ç”¨")


def get_market_index_code(stock_code: str) -> tuple[str, str]:
    """
    æ ¹æ®è‚¡ç¥¨ä»£ç ç¡®å®šå¯¹åº”çš„å¤§ç›˜æŒ‡æ•°ä»£ç 
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        
    Returns:
        (index_code, index_name): æŒ‡æ•°ä»£ç å’Œåç§°
    """
    # Aè‚¡ï¼šæ ¹æ®ä»£ç å‰ç¼€åˆ¤æ–­å¸‚åœº
    if stock_code.startswith(('60', '68', '90')):
        # ä¸Šæµ·å¸‚åœº - ä½¿ç”¨ä¸Šè¯æŒ‡æ•°
        return "000001", "ä¸Šè¯æŒ‡æ•°"
    elif stock_code.startswith(('00', '30', '20')):
        # æ·±åœ³å¸‚åœº - ä½¿ç”¨æ·±è¯æˆæŒ‡
        return "399001", "æ·±è¯æˆæŒ‡"
    else:
        # é»˜è®¤ä½¿ç”¨ä¸Šè¯æŒ‡æ•°
        return "000001", "ä¸Šè¯æŒ‡æ•°"


def parse_stock_data(data_str: str) -> pd.DataFrame:
    """
    è§£æè‚¡ç¥¨æ•°æ®å­—ç¬¦ä¸²ä¸ºDataFrame
    
    Args:
        data_str: è‚¡ç¥¨æ•°æ®å­—ç¬¦ä¸²ï¼ˆé€šå¸¸åŒ…å«æ—¥æœŸã€æ”¶ç›˜ä»·ç­‰ä¿¡æ¯ï¼‰
        
    Returns:
        DataFrame: åŒ…å«æ—¥æœŸå’Œæ”¶ç›˜ä»·çš„DataFrame
    """
    try:
        # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°æ®
        # æ•°æ®æ ¼å¼å¯èƒ½æ˜¯å¤šç§ï¼Œéœ€è¦çµæ´»å¤„ç†
        lines = data_str.strip().split('\n')
        
        dates = []
        closes = []
        opens = []
        highs = []
        lows = []
        volumes = []
        
        for line in lines:
            # è·³è¿‡ç©ºè¡Œå’Œæ ‡é¢˜è¡Œ
            if not line.strip() or 'æ—¥æœŸ' in line or 'Date' in line or line.startswith('#'):
                continue
            
            # å°è¯•è§£ææ•°æ®è¡Œ
            # å¯èƒ½çš„æ ¼å¼ï¼šæ—¥æœŸ,å¼€ç›˜,æœ€é«˜,æœ€ä½,æ”¶ç›˜,æˆäº¤é‡
            parts = [p.strip() for p in line.split(',')]
            if len(parts) < 5:
                parts = [p.strip() for p in line.split('\t')]
            
            if len(parts) >= 5:
                try:
                    date_str = parts[0]
                    # å°è¯•è§£ææ—¥æœŸ
                    try:
                        date = pd.to_datetime(date_str)
                    except:
                        # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•å…¶ä»–æ ¼å¼
                        date = pd.to_datetime(date_str, errors='coerce')
                    
                    if pd.isna(date):
                        continue
                    
                    # å°è¯•è§£ææ•°å€¼
                    try:
                        open_price = float(parts[1])
                        high = float(parts[2])
                        low = float(parts[3])
                        close = float(parts[4])
                        volume = float(parts[5]) if len(parts) > 5 else 0
                        
                        dates.append(date)
                        opens.append(open_price)
                        highs.append(high)
                        lows.append(low)
                        closes.append(close)
                        volumes.append(volume)
                    except (ValueError, IndexError):
                        continue
                except Exception:
                    continue
        
        if not dates:
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ç©ºDataFrame
            return pd.DataFrame()
        
        df = pd.DataFrame({
            'date': dates,
            'open': opens,
            'high': highs,
            'low': lows,
            'close': closes,
            'volume': volumes
        })
        
        df = df.sort_values('date').reset_index(drop=True)
        return df
        
    except Exception as e:
        logger.error(f"è§£æè‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()


def get_stock_data_from_api(stock_code: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    ä»APIè·å–è‚¡ç¥¨æ•°æ®
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        
    Returns:
        DataFrame: è‚¡ç¥¨æ•°æ®
    """
    try:
        # å°è¯•ç›´æ¥ä»æ•°æ®æºç®¡ç†å™¨è·å–DataFrame
        from tradingagents.dataflows.data_source_manager import get_data_source_manager
        from tradingagents.utils.stock_utils import StockUtils
        
        manager = get_data_source_manager()
        market_info = StockUtils.get_market_info(stock_code)
        
        if market_info['is_china']:
            # Aè‚¡ï¼šå°è¯•ä»Tushareé€‚é…å™¨ç›´æ¥è·å–DataFrame
            try:
                from tradingagents.dataflows.tushare_adapter import get_tushare_adapter
                adapter = get_tushare_adapter()
                if adapter and adapter.provider and adapter.provider.connected:
                    df = adapter.provider.get_stock_data(stock_code, start_date, end_date)
                    if df is not None and not df.empty:
                        # ç¡®ä¿åˆ—åæ ‡å‡†åŒ–
                        if 'trade_date' in df.columns:
                            df['date'] = pd.to_datetime(df['trade_date'])
                        elif 'date' not in df.columns:
                            if df.index.name == 'date':
                                df = df.reset_index()
                            elif hasattr(df.index, 'dtype') and pd.api.types.is_datetime64_any_dtype(df.index):
                                # å¦‚æœç´¢å¼•æ˜¯æ—¥æœŸç±»å‹ï¼Œé‡ç½®ä¸ºåˆ—
                                df = df.reset_index()
                                df['date'] = pd.to_datetime(df.index) if 'date' not in df.columns else df['date']
                            else:
                                logger.warning(f"æ— æ³•ä»æ•°æ®ä¸­æå–æ—¥æœŸåˆ—ï¼Œæ•°æ®åˆ—: {list(df.columns)}")
                                return pd.DataFrame()
                        
                        # æ ‡å‡†åŒ–åˆ—å
                        column_mapping = {
                            'close': 'close',
                            'open': 'open',
                            'high': 'high',
                            'low': 'low',
                            'vol': 'volume',
                            'volume': 'volume',
                            'amount': 'volume'  # å¦‚æœåªæœ‰amountï¼Œä½¿ç”¨å®ƒä½œä¸ºvolume
                        }
                        
                        for old_col, new_col in column_mapping.items():
                            if old_col in df.columns and new_col not in df.columns:
                                df[new_col] = df[old_col]
                        
                        # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
                        required_cols = ['date', 'close']
                        if all(col in df.columns for col in required_cols):
                            df = df.sort_values('date').reset_index(drop=True)
                            return df
                        else:
                            logger.warning(f"æ•°æ®ç¼ºå°‘å¿…è¦åˆ—ï¼Œå·²æœ‰åˆ—: {list(df.columns)}ï¼Œéœ€è¦åˆ—: {required_cols}")
                            return pd.DataFrame()
            except Exception as e:
                logger.debug(f"ä»Tushareé€‚é…å™¨è·å–æ•°æ®å¤±è´¥: {e}")
        
        # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ç»Ÿä¸€æ¥å£è·å–å­—ç¬¦ä¸²æ•°æ®å¹¶è§£æ
        try:
            from tradingagents.dataflows.interface import get_stock_data_by_market
            
            # è·å–è‚¡ç¥¨æ•°æ®å­—ç¬¦ä¸²
            data_str = get_stock_data_by_market(stock_code, start_date, end_date)
            
            if not data_str or "å¤±è´¥" in data_str or "é”™è¯¯" in data_str:
                logger.warning(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {data_str}")
                return pd.DataFrame()
            
            # è§£ææ•°æ®
            df = parse_stock_data(data_str)
            return df
        except ImportError as e:
            logger.error(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
            return pd.DataFrame()
        
    except Exception as e:
        logger.error(f"ä»APIè·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()


def get_index_data_from_api(index_code: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    ä»APIè·å–æŒ‡æ•°æ•°æ®
    
    Args:
        index_code: æŒ‡æ•°ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        
    Returns:
        DataFrame: æŒ‡æ•°æ•°æ®
    """
    try:
        # å°è¯•ä»Tushareé€‚é…å™¨ç›´æ¥è·å–DataFrame
        try:
            from tradingagents.dataflows.tushare_adapter import get_tushare_adapter
            adapter = get_tushare_adapter()
            if adapter and adapter.provider and adapter.provider.connected:
                # å¯¹äºæŒ‡æ•°ï¼Œå¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†
                # å°è¯•ä½¿ç”¨æŒ‡æ•°çš„æ ‡å‡†æ ¼å¼
                if index_code == "000001":
                    # ä¸Šè¯æŒ‡æ•°ï¼šå¯èƒ½éœ€è¦ä½¿ç”¨ "000001.SH" æˆ–å…¶ä»–æ ¼å¼
                    index_symbols = ["000001.SH", "000001"]
                elif index_code == "399001":
                    # æ·±è¯æˆæŒ‡
                    index_symbols = ["399001.SZ", "399001"]
                else:
                    index_symbols = [index_code]
                
                for symbol in index_symbols:
                    try:
                        df = adapter.provider.get_stock_data(symbol, start_date, end_date)
                        if df is not None and not df.empty:
                            # ç¡®ä¿åˆ—åæ ‡å‡†åŒ–
                            if 'trade_date' in df.columns:
                                df['date'] = pd.to_datetime(df['trade_date'])
                            elif 'date' not in df.columns and df.index.name == 'date':
                                df = df.reset_index()
                            
                            # æ ‡å‡†åŒ–åˆ—å
                            if 'close' in df.columns:
                                df = df.sort_values('date').reset_index(drop=True)
                                return df
                    except Exception:
                        continue
        except Exception as e:
            logger.debug(f"ä»Tushareé€‚é…å™¨è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
        
        # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ç»Ÿä¸€æ¥å£è·å–å­—ç¬¦ä¸²æ•°æ®å¹¶è§£æ
        from tradingagents.dataflows.interface import get_china_stock_data_unified
        
        # å°è¯•è·å–æŒ‡æ•°æ•°æ®ï¼ˆä½¿ç”¨ä¸è‚¡ç¥¨ç›¸åŒçš„æ¥å£ï¼‰
        data_str = get_china_stock_data_unified(index_code, start_date, end_date)
        
        if not data_str or "å¤±è´¥" in data_str or "é”™è¯¯" in data_str:
            logger.warning(f"è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {data_str}")
            return pd.DataFrame()
        
        # è§£ææ•°æ®
        df = parse_stock_data(data_str)
        return df
        
    except Exception as e:
        logger.error(f"ä»APIè·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()


def extract_predicted_price(analysis_result: Dict[str, Any]) -> Optional[float]:
    """
    ä»åˆ†æç»“æœä¸­æå–é¢„æµ‹ä»·æ ¼
    
    Args:
        analysis_result: åˆ†æç»“æœå­—å…¸
        
    Returns:
        é¢„æµ‹ä»·æ ¼ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
    """
    try:
        # å°è¯•ä»formatted_decisionä¸­æå–
        formatted_decision = analysis_result.get('formatted_decision', {})
        if isinstance(formatted_decision, dict):
            target_price = formatted_decision.get('target_price')
            if target_price is not None:
                try:
                    if isinstance(target_price, str):
                        # æ¸…ç†å­—ç¬¦ä¸²æ ¼å¼çš„ä»·æ ¼
                        clean_price = target_price.replace('$', '').replace('Â¥', '').replace('ï¿¥', '').replace('å…ƒ', '').strip()
                        return float(clean_price) if clean_price and clean_price.lower() not in ['none', 'null', ''] else None
                    elif isinstance(target_price, (int, float)):
                        return float(target_price)
                except (ValueError, TypeError):
                    pass
        
        # å°è¯•ä»reportsä¸­æå–
        reports = analysis_result.get('reports', {})
        if isinstance(reports, dict):
            # æœç´¢æ‰€æœ‰æŠ¥å‘Šä¸­çš„ç›®æ ‡ä»·æ ¼
            for report_key, report_content in reports.items():
                if isinstance(report_content, str):
                    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ä»·æ ¼
                    patterns = [
                        r'ç›®æ ‡[ä»·ä½æ ¼]*[ï¼š:]\s*[Â¥$ï¿¥]?(\d+\.?\d*)',
                        r'ç›®æ ‡[ä»·ä½æ ¼]*[ï¼š:]\s*(\d+\.?\d*)[å…ƒ]?',
                        r'target\s*price[ï¼š:]\s*[Â¥$ï¿¥]?(\d+\.?\d*)',
                    ]
                    for pattern in patterns:
                        match = re.search(pattern, report_content, re.IGNORECASE)
                        if match:
                            try:
                                return float(match.group(1))
                            except (ValueError, TypeError):
                                continue
        
        return None
        
    except Exception as e:
        logger.error(f"æå–é¢„æµ‹ä»·æ ¼å¤±è´¥: {e}")
        return None


def prepare_backtest_data(
    stock_code: str,
    analysis_date: str,
    predicted_price: Optional[float],
    min_points: int = 30
) -> Dict[str, Any]:
    """
    å‡†å¤‡å›æµ‹æ•°æ®
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        analysis_date: åˆ†ææ—¥æœŸ
        predicted_price: é¢„æµ‹ä»·æ ¼
        min_points: æœ€å°‘æ•°æ®ç‚¹æ•°
        
    Returns:
        åŒ…å«è‚¡ç¥¨æ•°æ®ã€æŒ‡æ•°æ•°æ®å’Œé¢„æµ‹æ•°æ®çš„å­—å…¸
    """
    try:
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        analysis_dt = pd.to_datetime(analysis_date)
        today = datetime.now()
        
        # é¦–å…ˆè·å–åˆ†ææ—¥æœŸä¹‹åçš„æ•°æ®
        end_date = today.strftime('%Y-%m-%d')
        start_date_post = (analysis_dt + timedelta(days=1)).strftime('%Y-%m-%d')
        
        # è·å–åˆ†ææ—¥æœŸä¹‹åçš„è‚¡ç¥¨æ•°æ®
        stock_df_post = get_stock_data_from_api(stock_code, start_date_post, end_date)
        
        # è·å–å¯¹åº”çš„å¤§ç›˜æŒ‡æ•°ä»£ç 
        index_code, index_name = get_market_index_code(stock_code)
        index_df_post = get_index_data_from_api(index_code, start_date_post, end_date)
        
        # å¦‚æœåˆ†ææ—¥æœŸåçš„æ•°æ®ç‚¹å°‘äºmin_pointsï¼Œéœ€è¦è·å–åˆ†ææ—¥æœŸå‰çš„æ•°æ®
        total_points = len(stock_df_post)
        if total_points < min_points:
            # è®¡ç®—éœ€è¦è·å–å¤šå°‘å¤©å‰çš„æ•°æ®
            days_before = (min_points - total_points) + 10  # å¤šè·å–ä¸€äº›ï¼Œä»¥é˜²æœ‰ç¼ºå¤±æ•°æ®
            start_date_pre = (analysis_dt - timedelta(days=days_before)).strftime('%Y-%m-%d')
            end_date_pre = analysis_date
            
            # è·å–åˆ†ææ—¥æœŸå‰çš„æ•°æ®
            stock_df_pre = get_stock_data_from_api(stock_code, start_date_pre, end_date_pre)
            index_df_pre = get_index_data_from_api(index_code, start_date_pre, end_date_pre)
            
            # åˆå¹¶æ•°æ®ï¼ˆæ£€æŸ¥æ˜¯å¦æœ‰dateåˆ—ï¼‰
            if not stock_df_pre.empty and 'date' in stock_df_pre.columns:
                if not stock_df_post.empty and 'date' in stock_df_post.columns:
                    stock_df = pd.concat([stock_df_pre, stock_df_post], ignore_index=True)
                    stock_df = stock_df.sort_values('date').reset_index(drop=True)
                else:
                    stock_df = stock_df_pre
            else:
                stock_df = stock_df_post if not stock_df_post.empty else stock_df_pre
            
            if not index_df_pre.empty and 'date' in index_df_pre.columns:
                if not index_df_post.empty and 'date' in index_df_post.columns:
                    index_df = pd.concat([index_df_pre, index_df_post], ignore_index=True)
                    index_df = index_df.sort_values('date').reset_index(drop=True)
                else:
                    index_df = index_df_pre
            else:
                index_df = index_df_post if not index_df_post.empty else index_df_pre
        else:
            stock_df = stock_df_post
            index_df = index_df_post
        
        # ç¡®ä¿æ•°æ®ç‚¹ä¸å°‘äºmin_pointsï¼ˆå¦‚æœæ•°æ®ä¸è¶³ï¼Œè‡³å°‘è¿”å›ç°æœ‰æ•°æ®ï¼‰
        if len(stock_df) < min_points and len(stock_df) > 0:
            # å¦‚æœæ•°æ®ä»ç„¶ä¸è¶³ï¼Œå°è¯•è·å–æ›´å¤šå†å²æ•°æ®
            days_before = min_points * 2
            start_date_pre = (analysis_dt - timedelta(days=days_before)).strftime('%Y-%m-%d')
            end_date_pre = analysis_date
            
            stock_df_pre = get_stock_data_from_api(stock_code, start_date_pre, end_date_pre)
            index_df_pre = get_index_data_from_api(index_code, start_date_pre, end_date_pre)
            
            if not stock_df_pre.empty and 'date' in stock_df_pre.columns:
                if not stock_df.empty and 'date' in stock_df.columns:
                    stock_df = pd.concat([stock_df_pre, stock_df], ignore_index=True)
                    stock_df = stock_df.sort_values('date').reset_index(drop=True)
                    stock_df = stock_df.drop_duplicates(subset=['date']).reset_index(drop=True)
                else:
                    stock_df = stock_df_pre
            
            if not index_df_pre.empty and 'date' in index_df_pre.columns:
                if not index_df.empty and 'date' in index_df.columns:
                    index_df = pd.concat([index_df_pre, index_df], ignore_index=True)
                    index_df = index_df.sort_values('date').reset_index(drop=True)
                    index_df = index_df.drop_duplicates(subset=['date']).reset_index(drop=True)
                else:
                    index_df = index_df_pre
        
        # æ ‡è®°åˆ†ææ—¥æœŸï¼ˆåªåœ¨æœ‰æ•°æ®æ—¶ï¼‰
        analysis_date_dt = pd.to_datetime(analysis_date)
        if not stock_df.empty and 'date' in stock_df.columns:
            stock_df['is_after_analysis'] = stock_df['date'] >= analysis_date_dt
        elif not stock_df.empty:
            # å¦‚æœæ²¡æœ‰dateåˆ—ï¼Œå°è¯•åˆ›å»º
            logger.warning(f"è‚¡ç¥¨æ•°æ®ç¼ºå°‘dateåˆ—ï¼Œå°è¯•ä¿®å¤...")
            if 'trade_date' in stock_df.columns:
                stock_df['date'] = pd.to_datetime(stock_df['trade_date'])
                stock_df['is_after_analysis'] = stock_df['date'] >= analysis_date_dt
            else:
                logger.error(f"è‚¡ç¥¨æ•°æ®æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘dateå’Œtrade_dateåˆ—")
                stock_df = pd.DataFrame()
        
        if not index_df.empty and 'date' in index_df.columns:
            index_df['is_after_analysis'] = index_df['date'] >= analysis_date_dt
        elif not index_df.empty:
            # å¦‚æœæ²¡æœ‰dateåˆ—ï¼Œå°è¯•åˆ›å»º
            logger.warning(f"æŒ‡æ•°æ•°æ®ç¼ºå°‘dateåˆ—ï¼Œå°è¯•ä¿®å¤...")
            if 'trade_date' in index_df.columns:
                index_df['date'] = pd.to_datetime(index_df['trade_date'])
                index_df['is_after_analysis'] = index_df['date'] >= analysis_date_dt
            else:
                logger.error(f"æŒ‡æ•°æ•°æ®æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘dateå’Œtrade_dateåˆ—")
                index_df = pd.DataFrame()
        
        return {
            'stock_data': stock_df,
            'index_data': index_df,
            'predicted_price': predicted_price,
            'analysis_date': analysis_date,
            'index_code': index_code,
            'index_name': index_name
        }
        
    except Exception as e:
        logger.error(f"å‡†å¤‡å›æµ‹æ•°æ®å¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return {
            'stock_data': pd.DataFrame(),
            'index_data': pd.DataFrame(),
            'predicted_price': predicted_price,
            'analysis_date': analysis_date,
            'index_code': '',
            'index_name': ''
        }


def render_backtest_chart(backtest_data: Dict[str, Any], stock_code: str):
    """
    æ¸²æŸ“å›æµ‹å›¾è¡¨
    
    Args:
        backtest_data: å›æµ‹æ•°æ®å­—å…¸
        stock_code: è‚¡ç¥¨ä»£ç 
    """
    stock_df = backtest_data['stock_data']
    index_df = backtest_data['index_data']
    predicted_price = backtest_data['predicted_price']
    analysis_date = backtest_data['analysis_date']
    index_name = backtest_data['index_name']
    
    if stock_df.empty:
        st.warning("æš‚æ— è‚¡ç¥¨æ•°æ®ï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨")
        return
    
    # åˆ›å»ºå­å›¾
    fig = make_subplots(
        rows=2, cols=1,
        shared_xaxes=True,
        vertical_spacing=0.1,
        row_heights=[0.7, 0.3],
        subplot_titles=(f'{stock_code} å›æµ‹å¯¹æ¯”å›¾', 'æˆäº¤é‡')
    )
    
    # åˆ†ææ—¥æœŸ
    analysis_date_dt = pd.to_datetime(analysis_date)
    
    # åˆ†ç¦»åˆ†ææ—¥æœŸå‰åçš„æ•°æ®
    stock_before = stock_df[stock_df['date'] < analysis_date_dt]
    stock_after = stock_df[stock_df['date'] >= analysis_date_dt]
    
    # ç»˜åˆ¶è‚¡ç¥¨æ”¶ç›˜ä»·
    if not stock_before.empty:
        fig.add_trace(
            go.Scatter(
                x=stock_before['date'],
                y=stock_before['close'],
                mode='lines',
                name=f'{stock_code} å®é™…æ”¶ç›˜ä»·ï¼ˆåˆ†æå‰ï¼‰',
                line=dict(color='lightblue', width=2),
                legendgroup='stock'
            ),
            row=1, col=1
        )
    
    if not stock_after.empty:
        fig.add_trace(
            go.Scatter(
                x=stock_after['date'],
                y=stock_after['close'],
                mode='lines',
                name=f'{stock_code} å®é™…æ”¶ç›˜ä»·ï¼ˆåˆ†æåï¼‰',
                line=dict(color='blue', width=2),
                legendgroup='stock'
            ),
            row=1, col=1
        )
    
    # ç»˜åˆ¶æŒ‡æ•°æ•°æ®ï¼ˆå½’ä¸€åŒ–åˆ°è‚¡ç¥¨ä»·æ ¼èŒƒå›´ï¼‰
    if not index_df.empty:
        # è®¡ç®—å½’ä¸€åŒ–ç³»æ•°ï¼ˆä½¿æŒ‡æ•°ä¸è‚¡ç¥¨ä»·æ ¼åœ¨åŒä¸€é‡çº§ï¼‰
        stock_price_range = stock_df['close'].max() - stock_df['close'].min()
        index_price_range = index_df['close'].max() - index_df['close'].min()
        
        if index_price_range > 0 and stock_price_range > 0:
            # æ‰¾åˆ°åˆ†ææ—¥æœŸå½“å¤©çš„è‚¡ç¥¨ä»·æ ¼å’ŒæŒ‡æ•°ï¼Œç”¨äºå¯¹é½
            analysis_stock_price = stock_df[stock_df['date'] <= analysis_date_dt]['close'].iloc[-1] if not stock_df[stock_df['date'] <= analysis_date_dt].empty else stock_df['close'].iloc[0]
            analysis_index_price = index_df[index_df['date'] <= analysis_date_dt]['close'].iloc[-1] if not index_df[index_df['date'] <= analysis_date_dt].empty else index_df['close'].iloc[0]
            
            # è®¡ç®—å½’ä¸€åŒ–ç³»æ•°
            scale_factor = analysis_stock_price / analysis_index_price if analysis_index_price > 0 else 1
            index_normalized = index_df['close'] * scale_factor
            
            index_before = index_df[index_df['date'] < analysis_date_dt]
            index_after = index_df[index_df['date'] >= analysis_date_dt]
            
            if not index_before.empty:
                fig.add_trace(
                    go.Scatter(
                        x=index_before['date'],
                        y=index_normalized[index_before.index],
                        mode='lines',
                        name=f'{index_name}ï¼ˆåˆ†æå‰ï¼‰',
                        line=dict(color='lightgreen', width=2, dash='dash'),
                        legendgroup='index'
                    ),
                    row=1, col=1
                )
            
            if not index_after.empty:
                fig.add_trace(
                    go.Scatter(
                        x=index_after['date'],
                        y=index_normalized[index_after.index],
                        mode='lines',
                        name=f'{index_name}ï¼ˆåˆ†æåï¼‰',
                        line=dict(color='green', width=2, dash='dash'),
                        legendgroup='index'
                    ),
                    row=1, col=1
                )
    
    # ç»˜åˆ¶é¢„æµ‹ä»·æ ¼çº¿
    if predicted_price is not None:
        # åœ¨åˆ†ææ—¥æœŸä¹‹åç»˜åˆ¶é¢„æµ‹ä»·æ ¼çº¿
        if not stock_after.empty:
            predicted_dates = stock_after['date'].tolist()
            predicted_prices = [predicted_price] * len(predicted_dates)
            
            fig.add_trace(
                go.Scatter(
                    x=predicted_dates,
                    y=predicted_prices,
                    mode='lines',
                    name=f'é¢„æµ‹ä»·æ ¼: {predicted_price:.2f}',
                    line=dict(color='red', width=2, dash='dot'),
                    legendgroup='predicted'
                ),
                row=1, col=1
            )
    
    # æ·»åŠ åˆ†ææ—¥æœŸæ ‡è®°çº¿
    fig.add_vline(
        x=analysis_date_dt,
        line_dash="dash",
        line_color="orange",
        annotation_text="åˆ†ææ—¥æœŸ",
        annotation_position="top",
        row=1, col=1
    )
    
    # ç»˜åˆ¶æˆäº¤é‡
    if 'volume' in stock_df.columns:
        volume_before = stock_before['volume'] if not stock_before.empty else pd.Series()
        volume_after = stock_after['volume'] if not stock_after.empty else pd.Series()
        
        if not stock_before.empty:
            fig.add_trace(
                go.Bar(
                    x=stock_before['date'],
                    y=stock_before['volume'],
                    name='æˆäº¤é‡ï¼ˆåˆ†æå‰ï¼‰',
                    marker_color='lightgray',
                    legendgroup='volume',
                    showlegend=False
                ),
                row=2, col=1
            )
        
        if not stock_after.empty:
            fig.add_trace(
                go.Bar(
                    x=stock_after['date'],
                    y=stock_after['volume'],
                    name='æˆäº¤é‡ï¼ˆåˆ†æåï¼‰',
                    marker_color='gray',
                    legendgroup='volume',
                    showlegend=False
                ),
                row=2, col=1
            )
    
    # æ›´æ–°å¸ƒå±€
    fig.update_xaxes(title_text="æ—¥æœŸ", row=2, col=1)
    fig.update_yaxes(title_text="ä»·æ ¼", row=1, col=1)
    fig.update_yaxes(title_text="æˆäº¤é‡", row=2, col=1)
    
    fig.update_layout(
        height=800,
        title_text=f"{stock_code} å›æµ‹åˆ†æ",
        hovermode='x unified'
    )
    
    st.plotly_chart(fig, use_container_width=True)


def render_backtest_table(backtest_data: Dict[str, Any], stock_code: str):
    """
    æ¸²æŸ“å›æµ‹æ•°æ®è¡¨
    
    Args:
        backtest_data: å›æµ‹æ•°æ®å­—å…¸
        stock_code: è‚¡ç¥¨ä»£ç 
    """
    stock_df = backtest_data['stock_data']
    index_df = backtest_data['index_data']
    predicted_price = backtest_data['predicted_price']
    analysis_date = backtest_data['analysis_date']
    index_name = backtest_data['index_name']
    
    if stock_df.empty:
        st.warning("æš‚æ— è‚¡ç¥¨æ•°æ®ï¼Œæ— æ³•æ˜¾ç¤ºæ•°æ®è¡¨")
        return
    
    # åˆå¹¶æ•°æ®
    result_df = stock_df[['date', 'close']].copy()
    result_df.columns = ['æ—¥æœŸ', f'{stock_code}æ”¶ç›˜ä»·']
    
    # æ·»åŠ æŒ‡æ•°æ•°æ®
    if not index_df.empty:
        index_data_dict = dict(zip(index_df['date'], index_df['close']))
        result_df[f'{index_name}'] = result_df['æ—¥æœŸ'].map(index_data_dict)
    
    # æ·»åŠ é¢„æµ‹ä»·æ ¼
    if predicted_price is not None:
        analysis_date_dt = pd.to_datetime(analysis_date)
        result_df['é¢„æµ‹ä»·æ ¼'] = result_df.apply(
            lambda row: predicted_price if pd.to_datetime(row['æ—¥æœŸ']) >= analysis_date_dt else None,
            axis=1
        )
    
    # æ·»åŠ åˆ†ææ—¥æœŸæ ‡è®°
    analysis_date_dt = pd.to_datetime(analysis_date)
    result_df['æ˜¯å¦åˆ†æå'] = result_df['æ—¥æœŸ'] >= analysis_date_dt
    
    # è®¡ç®—é¢„æµ‹è¯¯å·®ï¼ˆå¦‚æœåˆ†ææ—¥æœŸåï¼‰
    if predicted_price is not None:
        result_df['é¢„æµ‹è¯¯å·®'] = result_df.apply(
            lambda row: abs(row[f'{stock_code}æ”¶ç›˜ä»·'] - predicted_price) if row['æ˜¯å¦åˆ†æå'] and pd.notna(row[f'{stock_code}æ”¶ç›˜ä»·']) else None,
            axis=1
        )
        result_df['é¢„æµ‹è¯¯å·®ç‡(%)'] = result_df.apply(
            lambda row: abs((row[f'{stock_code}æ”¶ç›˜ä»·'] - predicted_price) / predicted_price * 100) if row['æ˜¯å¦åˆ†æå'] and pd.notna(row[f'{stock_code}æ”¶ç›˜ä»·']) and predicted_price > 0 else None,
            axis=1
        )
    
    # æ ¼å¼åŒ–æ—¥æœŸ
    result_df['æ—¥æœŸ'] = result_df['æ—¥æœŸ'].dt.strftime('%Y-%m-%d')
    
    # é‡æ–°æ’åˆ—åˆ—
    columns = ['æ—¥æœŸ', f'{stock_code}æ”¶ç›˜ä»·']
    if not index_df.empty:
        columns.append(f'{index_name}')
    if predicted_price is not None:
        columns.extend(['é¢„æµ‹ä»·æ ¼', 'é¢„æµ‹è¯¯å·®', 'é¢„æµ‹è¯¯å·®ç‡(%)'])
    columns.append('æ˜¯å¦åˆ†æå')
    
    result_df = result_df[columns]
    
    # æ˜¾ç¤ºæ•°æ®è¡¨
    st.subheader("ğŸ“Š å›æµ‹æ•°æ®å¯¹æ¯”è¡¨")
    st.dataframe(result_df, use_container_width=True)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if predicted_price is not None:
        after_analysis = result_df[result_df['æ˜¯å¦åˆ†æå'] == True]
        if not after_analysis.empty and 'é¢„æµ‹è¯¯å·®' in after_analysis.columns:
            errors = after_analysis['é¢„æµ‹è¯¯å·®'].dropna()
            if not errors.empty:
                st.subheader("ğŸ“ˆ é¢„æµ‹å‡†ç¡®æ€§ç»Ÿè®¡")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("å¹³å‡è¯¯å·®", f"{errors.mean():.2f}")
                with col2:
                    st.metric("æœ€å¤§è¯¯å·®", f"{errors.max():.2f}")
                with col3:
                    st.metric("æœ€å°è¯¯å·®", f"{errors.min():.2f}")
                with col4:
                    if 'é¢„æµ‹è¯¯å·®ç‡(%)' in after_analysis.columns:
                        error_rates = after_analysis['é¢„æµ‹è¯¯å·®ç‡(%)'].dropna()
                        if not error_rates.empty:
                            st.metric("å¹³å‡è¯¯å·®ç‡", f"{error_rates.mean():.2f}%")


def render_backtest_page():
    """æ¸²æŸ“å›æµ‹é¡µé¢"""
    st.header("ğŸ“ˆ åˆ†æç»“æœå›æµ‹")
    
    # æ£€æŸ¥MongoDBè¿æ¥
    if not MONGODB_AVAILABLE:
        st.error("âŒ MongoDBæœªè¿æ¥ï¼Œæ— æ³•è¯»å–åˆ†æç»“æœã€‚è¯·æ£€æŸ¥MongoDBé…ç½®ã€‚")
        return
    
    # è¾“å…¥è‚¡ç¥¨ä»£ç 
    stock_code = st.text_input(
        "è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ",
        value="",
        help="ä¾‹å¦‚ï¼š000001ï¼ˆå¹³å®‰é“¶è¡Œï¼‰ã€600036ï¼ˆæ‹›å•†é“¶è¡Œï¼‰",
        key="backtest_stock_code"
    )
    
    if not stock_code:
        st.info("ğŸ‘† è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ä»¥å¼€å§‹å›æµ‹")
        return
    
    # æŸ¥è¯¢æŒ‰é’®
    col1, col2 = st.columns([1, 4])
    with col1:
        query_button = st.button("ğŸ” æŸ¥è¯¢åˆ†æç»“æœ", key="query_analysis_results", type="primary")
    
    # åˆå§‹åŒ–session state
    if 'backtest_analysis_reports' not in st.session_state:
        st.session_state.backtest_analysis_reports = None
    if 'backtest_selected_report' not in st.session_state:
        st.session_state.backtest_selected_report = None
    
    # ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®
    if query_button:
        try:
            mongodb_manager = MongoDBReportManager()
            if not mongodb_manager.connected:
                st.error("âŒ æ— æ³•è¿æ¥åˆ°MongoDBï¼Œè¯·æ£€æŸ¥æ•°æ®åº“é…ç½®ã€‚")
                st.session_state.backtest_analysis_reports = None
                return
            
            # æ ¹æ®è‚¡ç¥¨ä»£ç æŸ¥è¯¢åˆ†æç»“æœ
            with st.spinner("æ­£åœ¨æŸ¥è¯¢åˆ†æç»“æœ..."):
                analysis_reports = mongodb_manager.get_analysis_reports(
                    limit=100,
                    stock_symbol=stock_code
                )
            
            if not analysis_reports:
                st.warning(f"âš ï¸ æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„åˆ†æç»“æœã€‚è¯·å…ˆè¿›è¡Œè‚¡ç¥¨åˆ†æã€‚")
                st.session_state.backtest_analysis_reports = None
            else:
                # æŒ‰æ—¶é—´å€’åºæ’åˆ—
                analysis_reports = sorted(analysis_reports, key=lambda x: x.get('timestamp', 0), reverse=True)
                st.session_state.backtest_analysis_reports = analysis_reports
                st.success(f"âœ… æ‰¾åˆ° {len(analysis_reports)} æ¡åˆ†æç»“æœ")
        
        except Exception as e:
            logger.error(f"æŸ¥è¯¢åˆ†æç»“æœå¤±è´¥: {e}")
            st.error(f"âŒ æŸ¥è¯¢åˆ†æç»“æœå¤±è´¥: {str(e)}")
            st.session_state.backtest_analysis_reports = None
    
    # æ˜¾ç¤ºåˆ†æç»“æœåˆ—è¡¨
    analysis_reports = st.session_state.backtest_analysis_reports
    
    if analysis_reports is None:
        if not query_button:
            st.info("ğŸ‘† è¯·è¾“å…¥è‚¡ç¥¨ä»£ç åï¼Œç‚¹å‡»ã€ŒæŸ¥è¯¢åˆ†æç»“æœã€æŒ‰é’®")
        return
    
    if not analysis_reports:
        st.warning(f"âš ï¸ æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„åˆ†æç»“æœã€‚è¯·å…ˆè¿›è¡Œè‚¡ç¥¨åˆ†æã€‚")
        return
    
    # æ˜¾ç¤ºåˆ†æç»“æœåˆ—è¡¨
    st.subheader("ğŸ“‹ åˆ†æç»“æœåˆ—è¡¨")
    
    # åˆ›å»ºé€‰æ‹©æ¡†
    report_options = []
    for report in analysis_reports:
        timestamp = report.get('timestamp', 0)
        if isinstance(timestamp, (int, float)):
            date_str = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')
        else:
            date_str = str(timestamp)
        
        analysis_date = report.get('analysis_date', '')
        if not analysis_date:
            # å°è¯•ä»timestampæå–
            if isinstance(timestamp, (int, float)):
                analysis_date = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
            else:
                analysis_date = date_str
        
        option_text = f"{analysis_date} - {report.get('analysis_id', 'N/A')}"
        report_options.append((option_text, report))
    
    if not report_options:
        st.warning("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ†æç»“æœã€‚")
        return
    
    # æ˜¾ç¤ºåˆ†æç»“æœé€‰æ‹©æ¡†
    selected_option = st.selectbox(
        "é€‰æ‹©è¦å›æµ‹çš„åˆ†æç»“æœ",
        options=[opt[0] for opt in report_options],
        key="backtest_report_select",
        help="é€‰æ‹©ä¸€æ¡åˆ†æç»“æœè¿›è¡Œå›æµ‹"
    )
    
    selected_index = [opt[0] for opt in report_options].index(selected_option)
    selected_report = report_options[selected_index][1]
    
    # ä¿å­˜é€‰ä¸­çš„æŠ¥å‘Š
    st.session_state.backtest_selected_report = selected_report
        
    # æ˜¾ç¤ºåˆ†æç»“æœä¿¡æ¯
    st.markdown("---")
    st.subheader("ğŸ“Š é€‰ä¸­çš„åˆ†æç»“æœä¿¡æ¯")
    
    col1, col2 = st.columns(2)
    with col1:
        st.info(f"""
        **åˆ†æID**: {selected_report.get('analysis_id', 'N/A')}  
        **åˆ†ææ—¥æœŸ**: {selected_report.get('analysis_date', 'N/A')}  
        """)
    with col2:
        st.info(f"""
        **åˆ†æå¸ˆ**: {', '.join(selected_report.get('analysts', []))}  
        **ç ”ç©¶æ·±åº¦**: {selected_report.get('research_depth', 'N/A')}
        """)
    
    # å¼€å§‹å›æµ‹æŒ‰é’®
    st.markdown("---")
    start_backtest = st.button("ğŸš€ å¼€å§‹å›æµ‹", key="start_backtest", type="primary")
    
    if not start_backtest:
        st.info("ğŸ‘† ç¡®è®¤åˆ†æç»“æœåï¼Œç‚¹å‡»ã€Œå¼€å§‹å›æµ‹ã€æŒ‰é’®è¿›è¡Œå›æµ‹")
        return
    
    # æå–åˆ†ææ—¥æœŸå’Œé¢„æµ‹ä»·æ ¼
    analysis_date = selected_report.get('analysis_date', '')
    if not analysis_date:
        # ä»timestampæå–
        timestamp = selected_report.get('timestamp', 0)
        if isinstance(timestamp, (int, float)):
            analysis_date = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
        elif hasattr(timestamp, 'strftime'):
            # å¦‚æœæ˜¯datetimeå¯¹è±¡
            analysis_date = timestamp.strftime('%Y-%m-%d')
        else:
            st.error("æ— æ³•ç¡®å®šåˆ†ææ—¥æœŸ")
            return
    
    # æå–é¢„æµ‹ä»·æ ¼
    predicted_price = extract_predicted_price(selected_report)
    
    if predicted_price is None:
        st.warning("âš ï¸ æœªæ‰¾åˆ°é¢„æµ‹ä»·æ ¼ä¿¡æ¯ï¼Œå°†ä»…æ˜¾ç¤ºå®é™…ä»·æ ¼å’ŒæŒ‡æ•°å¯¹æ¯”ã€‚")
    
    # å‡†å¤‡å›æµ‹æ•°æ®
    try:
        with st.spinner("æ­£åœ¨å‡†å¤‡å›æµ‹æ•°æ®..."):
            backtest_data = prepare_backtest_data(
                stock_code=stock_code,
                analysis_date=analysis_date,
                predicted_price=predicted_price,
                min_points=30
            )
        
        # æ£€æŸ¥æ•°æ®æ˜¯å¦å‡†å¤‡æˆåŠŸ
        if backtest_data['stock_data'].empty:
            st.error("âŒ æ— æ³•è·å–è‚¡ç¥¨äº¤æ˜“æ•°æ®ï¼Œè¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®ã€‚")
            return
        
        # æ˜¾ç¤ºå›æµ‹å›¾è¡¨
        st.markdown("---")
        st.subheader("ğŸ“ˆ å›æµ‹å›¾è¡¨")
        render_backtest_chart(backtest_data, stock_code)
        
        # æ˜¾ç¤ºå›æµ‹æ•°æ®è¡¨
        st.markdown("---")
        render_backtest_table(backtest_data, stock_code)
        
    except Exception as e:
        logger.error(f"å›æµ‹æ•°æ®å¤„ç†å¤±è´¥: {e}")
        st.error(f"âŒ å›æµ‹æ•°æ®å¤„ç†å¤±è´¥: {str(e)}")

