#!/usr/bin/env python3
"""
å›æµ‹é¡µé¢ç»„ä»¶
ç”¨äºå±•ç¤ºè‚¡ç¥¨åˆ†æç»“æœçš„å›æµ‹æ•ˆæœ
"""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import logging
import re

logger = logging.getLogger(__name__)

try:
    from tradingagents.storage.mongodb.report_manager import MongoDBReportManager
    MONGODB_AVAILABLE = True
except ImportError:
    MONGODB_AVAILABLE = False
    MongoDBReportManager = None
    logger.warning("MongoDBæ¨¡å—ä¸å¯ç”¨")


def _normalize_date_column(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ ‡å‡†åŒ–DataFrameçš„æ—¥æœŸåˆ—
    
    Args:
        df: è¾“å…¥çš„DataFrame
        
    Returns:
        æ ‡å‡†åŒ–åçš„DataFrameï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›ç©ºDataFrame
    """
    if df.empty:
        return df
    
    # å¦‚æœå·²ç»æœ‰dateåˆ—ï¼Œç›´æ¥è¿”å›
    if 'date' in df.columns:
        return df
    
    # å¦‚æœæœ‰trade_dateåˆ—ï¼Œè½¬æ¢ä¸ºdate
    if 'trade_date' in df.columns:
        df['date'] = pd.to_datetime(df['trade_date'])
        return df
    
    # å¦‚æœç´¢å¼•æ˜¯æ—¥æœŸç±»å‹ï¼Œé‡ç½®ä¸ºåˆ—
    if df.index.name == 'date':
        df = df.reset_index()
        if 'date' not in df.columns:
            logger.warning(f"é‡ç½®ç´¢å¼•åä»æœªæ‰¾åˆ°dateåˆ—ï¼Œæ•°æ®åˆ—: {list(df.columns)}")
            return pd.DataFrame()
        return df
    
    if hasattr(df.index, 'dtype') and pd.api.types.is_datetime64_any_dtype(df.index):
        index_name = df.index.name if df.index.name else 'index'
        df = df.reset_index()
        if index_name in df.columns:
            df['date'] = pd.to_datetime(df[index_name])
        elif 'index' in df.columns:
            df['date'] = pd.to_datetime(df['index'])
        else:
            logger.warning(f"é‡ç½®æ—¥æœŸç´¢å¼•åæœªæ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œæ•°æ®åˆ—: {list(df.columns)}")
            return pd.DataFrame()
        return df
    
    logger.warning(f"æ— æ³•ä»æ•°æ®ä¸­æå–æ—¥æœŸåˆ—ï¼Œæ•°æ®åˆ—: {list(df.columns)}")
    return pd.DataFrame()


def _normalize_column_names(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ ‡å‡†åŒ–DataFrameçš„åˆ—å
    
    Args:
        df: è¾“å…¥çš„DataFrame
        
    Returns:
        æ ‡å‡†åŒ–åçš„DataFrame
    """
    column_mapping = {
        'close': 'close',
        'open': 'open',
        'high': 'high',
        'low': 'low',
        'vol': 'volume',
        'volume': 'volume',
        'amount': 'volume'
    }
    
    for old_col, new_col in column_mapping.items():
        if old_col in df.columns and new_col not in df.columns:
            df[new_col] = df[old_col]
    
    return df


def _timestamp_to_milliseconds(timestamp_obj) -> float:
    """
    å°†æ—¶é—´æˆ³å¯¹è±¡è½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³
    
    Args:
        timestamp_obj: pandas Timestamp æˆ– datetime å¯¹è±¡
        
    Returns:
        æ¯«ç§’æ—¶é—´æˆ³ï¼ˆfloatï¼‰
    """
    try:
        return timestamp_obj.timestamp() * 1000
    except AttributeError:
        if hasattr(timestamp_obj, 'to_pydatetime'):
            return timestamp_obj.to_pydatetime().timestamp() * 1000
        return pd.to_datetime(timestamp_obj).timestamp() * 1000


def _merge_dataframes(df_pre: pd.DataFrame, df_post: pd.DataFrame) -> pd.DataFrame:
    """
    åˆå¹¶ä¸¤ä¸ªDataFrameï¼ŒæŒ‰æ—¥æœŸæ’åº
    
    Args:
        df_pre: å‰ä¸€ä¸ªDataFrame
        df_post: åä¸€ä¸ªDataFrame
        
    Returns:
        åˆå¹¶åçš„DataFrame
    """
    if df_pre.empty:
        return df_post if not df_post.empty else df_pre
    if df_post.empty:
        return df_pre
    
    if 'date' not in df_pre.columns or 'date' not in df_post.columns:
        return df_post if not df_post.empty else df_pre
    
    df = pd.concat([df_pre, df_post], ignore_index=True)
    df = df.sort_values('date').reset_index(drop=True)
    df = df.drop_duplicates(subset=['date']).reset_index(drop=True)
    return df


def get_market_index_code(stock_code: str) -> tuple[str, str]:
    """
    æ ¹æ®è‚¡ç¥¨ä»£ç ç¡®å®šå¯¹åº”çš„å¤§ç›˜æŒ‡æ•°ä»£ç 
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        
    Returns:
        (index_code, index_name): æŒ‡æ•°ä»£ç å’Œåç§°
    """
    # Aè‚¡ï¼šæ ¹æ®ä»£ç å‰ç¼€åˆ¤æ–­å¸‚åœº
    if stock_code.startswith(('60', '68', '90')):
        # ä¸Šæµ·å¸‚åœº - ä½¿ç”¨ä¸Šè¯æŒ‡æ•°
        return "000001", "ä¸Šè¯æŒ‡æ•°"
    elif stock_code.startswith(('00', '30', '20')):
        # æ·±åœ³å¸‚åœº - ä½¿ç”¨æ·±è¯æˆæŒ‡
        return "399001", "æ·±è¯æˆæŒ‡"
    else:
        # é»˜è®¤ä½¿ç”¨ä¸Šè¯æŒ‡æ•°
        return "000001", "ä¸Šè¯æŒ‡æ•°"


def parse_stock_data(data_str: str) -> pd.DataFrame:
    """
    è§£æè‚¡ç¥¨æ•°æ®å­—ç¬¦ä¸²ä¸ºDataFrame
    
    Args:
        data_str: è‚¡ç¥¨æ•°æ®å­—ç¬¦ä¸²ï¼ˆé€šå¸¸åŒ…å«æ—¥æœŸã€æ”¶ç›˜ä»·ç­‰ä¿¡æ¯ï¼‰
        
    Returns:
        DataFrame: åŒ…å«æ—¥æœŸå’Œæ”¶ç›˜ä»·çš„DataFrame
    """
    try:
        # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°æ®
        # æ•°æ®æ ¼å¼å¯èƒ½æ˜¯å¤šç§ï¼Œéœ€è¦çµæ´»å¤„ç†
        lines = data_str.strip().split('\n')
        
        dates = []
        closes = []
        opens = []
        highs = []
        lows = []
        volumes = []
        
        for line in lines:
            # è·³è¿‡ç©ºè¡Œå’Œæ ‡é¢˜è¡Œ
            if not line.strip() or 'æ—¥æœŸ' in line or 'Date' in line or line.startswith('#'):
                continue
            
            # å°è¯•è§£ææ•°æ®è¡Œ
            # å¯èƒ½çš„æ ¼å¼ï¼šæ—¥æœŸ,å¼€ç›˜,æœ€é«˜,æœ€ä½,æ”¶ç›˜,æˆäº¤é‡
            parts = [p.strip() for p in line.split(',')]
            if len(parts) < 5:
                parts = [p.strip() for p in line.split('\t')]
            
            if len(parts) >= 5:
                try:
                    date_str = parts[0]
                    # å°è¯•è§£ææ—¥æœŸ
                    try:
                        date = pd.to_datetime(date_str)
                    except:
                        # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•å…¶ä»–æ ¼å¼
                        date = pd.to_datetime(date_str, errors='coerce')
                    
                    if pd.isna(date):
                        continue
                    
                    # å°è¯•è§£ææ•°å€¼
                    try:
                        open_price = float(parts[1])
                        high = float(parts[2])
                        low = float(parts[3])
                        close = float(parts[4])
                        volume = float(parts[5]) if len(parts) > 5 else 0
                        
                        dates.append(date)
                        opens.append(open_price)
                        highs.append(high)
                        lows.append(low)
                        closes.append(close)
                        volumes.append(volume)
                    except (ValueError, IndexError):
                        continue
                except Exception:
                    continue
        
        if not dates:
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ç©ºDataFrame
            return pd.DataFrame()
        
        df = pd.DataFrame({
            'date': dates,
            'open': opens,
            'high': highs,
            'low': lows,
            'close': closes,
            'volume': volumes
        })
        
        df = df.sort_values('date').reset_index(drop=True)
        return df
        
    except Exception as e:
        logger.error(f"è§£æè‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()


def get_stock_data_from_api(stock_code: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    ä»APIè·å–è‚¡ç¥¨æ•°æ®
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        
    Returns:
        DataFrame: è‚¡ç¥¨æ•°æ®
    """
    try:
        # å°è¯•ç›´æ¥ä»æ•°æ®æºç®¡ç†å™¨è·å–DataFrame
        from tradingagents.dataflows.data_source_manager import get_data_source_manager
        from tradingagents.utils.stock_utils import StockUtils
        
        manager = get_data_source_manager()
        market_info = StockUtils.get_market_info(stock_code)
        
        if market_info['is_china']:
            # Aè‚¡ï¼šå°è¯•ä»Tushareé€‚é…å™¨ç›´æ¥è·å–DataFrame
            try:
                from tradingagents.dataflows.tushare_adapter import get_tushare_adapter
                adapter = get_tushare_adapter()
                if adapter and adapter.provider and adapter.provider.connected:
                    df = adapter.provider.get_stock_daily(stock_code, start_date, end_date)
                    if df is not None and not df.empty:
                        df = _normalize_date_column(df)
                        if df.empty:
                            return pd.DataFrame()
                        
                        df = _normalize_column_names(df)
                        
                        if 'date' in df.columns and 'close' in df.columns:
                            df = df.sort_values('date').reset_index(drop=True)
                            return df
                        else:
                            logger.warning(f"æ•°æ®ç¼ºå°‘å¿…è¦åˆ—ï¼Œå·²æœ‰åˆ—: {list(df.columns)}ï¼Œéœ€è¦åˆ—: ['date', 'close']")
                            return pd.DataFrame()
            except Exception as e:
                logger.debug(f"ä»Tushareé€‚é…å™¨è·å–æ•°æ®å¤±è´¥: {e}")
        
        # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ç»Ÿä¸€æ¥å£è·å–å­—ç¬¦ä¸²æ•°æ®å¹¶è§£æ
        try:
            from tradingagents.dataflows.interface import get_stock_data_by_market
            
            # è·å–è‚¡ç¥¨æ•°æ®å­—ç¬¦ä¸²
            data_str = get_stock_data_by_market(stock_code, start_date, end_date)
            
            if not data_str or "å¤±è´¥" in data_str or "é”™è¯¯" in data_str:
                logger.warning(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {data_str}")
                return pd.DataFrame()
            
            # è§£ææ•°æ®
            df = parse_stock_data(data_str)
            return df
        except ImportError as e:
            logger.error(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
            return pd.DataFrame()
        
    except Exception as e:
        logger.error(f"ä»APIè·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()


def get_index_data_from_api(index_code: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    ä»APIè·å–æŒ‡æ•°æ•°æ®
    
    Args:
        index_code: æŒ‡æ•°ä»£ç ï¼ˆå¦‚ï¼š000001ã€399001ï¼‰
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        
    Returns:
        DataFrame: æŒ‡æ•°æ•°æ®
    """
    try:
        # ä½¿ç”¨æŒ‡æ•°æ•°æ®æ¥å£
        try:
            from tradingagents.dataflows.tushare_utils import get_china_index_data_tushare
            from tradingagents.dataflows.tushare_adapter import get_tushare_adapter
            
            # å…ˆå°è¯•ä»Tushareé€‚é…å™¨çš„Providerç›´æ¥è·å–
            adapter = get_tushare_adapter()
            if adapter and adapter.provider and adapter.provider.connected:
                # å¯¹äºæŒ‡æ•°ï¼Œéœ€è¦è½¬æ¢ä¸ºTushareæ ‡å‡†æ ¼å¼
                if index_code == "000001":
                    # ä¸Šè¯æŒ‡æ•°
                    index_symbols = ["000001.SH", "000001"]
                elif index_code == "399001":
                    # æ·±è¯æˆæŒ‡
                    index_symbols = ["399001.SZ", "399001"]
                else:
                    # å°è¯•è‡ªåŠ¨åˆ¤æ–­äº¤æ˜“æ‰€
                    if index_code.startswith('39'):
                        index_symbols = [f"{index_code}.SZ", index_code]
                    elif index_code.startswith('00'):
                        index_symbols = [f"{index_code}.SH", index_code]
                    else:
                        index_symbols = [index_code]
                
                for symbol in index_symbols:
                    try:
                        df = adapter.provider.get_index_daily(symbol, start_date, end_date)
                        if df is not None and not df.empty:
                            df = _normalize_date_column(df)
                            if df.empty:
                                continue
                            
                            df = _normalize_column_names(df)
                            
                            if 'close' in df.columns and 'date' in df.columns:
                                df = df.sort_values('date').reset_index(drop=True)
                                logger.debug(f"âœ… æˆåŠŸè·å–æŒ‡æ•°æ•°æ®: {index_code}, æ•°æ®æ¡æ•°: {len(df)}")
                                return df
                    except Exception as e:
                        logger.debug(f"å°è¯•æŒ‡æ•°ä»£ç  {symbol} å¤±è´¥: {e}")
                        continue
        except Exception as e:
            logger.debug(f"ä»Tushareé€‚é…å™¨è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
        
        # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ä¾¿æ·å‡½æ•°
        try:
            from tradingagents.dataflows.tushare_utils import get_china_index_data_tushare
            
            # è½¬æ¢æŒ‡æ•°ä»£ç æ ¼å¼
            if index_code == "000001":
                ts_code = "000001.SH"
            elif index_code == "399001":
                ts_code = "399001.SZ"
            elif index_code.startswith('39'):
                ts_code = f"{index_code}.SZ"
            elif index_code.startswith('00'):
                ts_code = f"{index_code}.SH"
            else:
                ts_code = index_code
            
            df = get_china_index_data_tushare(ts_code, start_date, end_date)
            if df is not None and not df.empty:
                df = _normalize_date_column(df)
                if df.empty:
                    return pd.DataFrame()
                
                df = _normalize_column_names(df)
                
                if 'close' in df.columns and 'date' in df.columns:
                    df = df.sort_values('date').reset_index(drop=True)
                    logger.debug(f"âœ… é™çº§æ–¹æ¡ˆæˆåŠŸè·å–æŒ‡æ•°æ•°æ®: {index_code}, æ•°æ®æ¡æ•°: {len(df)}")
                    return df
        except Exception as e:
            logger.warning(f"é™çº§æ–¹æ¡ˆè·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
        
        # æœ€ç»ˆé™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ç»Ÿä¸€æ¥å£è·å–å­—ç¬¦ä¸²æ•°æ®å¹¶è§£æï¼ˆä¸æ¨èï¼Œä½†ä½œä¸ºæœ€åæ‰‹æ®µï¼‰
        from tradingagents.dataflows.interface import get_china_stock_data_unified
        
        data_str = get_china_stock_data_unified(index_code, start_date, end_date)
        
        if not data_str or "å¤±è´¥" in data_str or "é”™è¯¯" in data_str:
            logger.warning(f"è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {data_str}")
            return pd.DataFrame()
        
        # è§£ææ•°æ®
        df = parse_stock_data(data_str)
        return df
        
    except Exception as e:
        logger.error(f"ä»APIè·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()




def prepare_backtest_data(
    stock_code: str,
    analysis_date: str,
    target_price: Optional[float],
    min_points: int = 30
) -> Dict[str, Any]:
    """
    å‡†å¤‡å›æµ‹æ•°æ®
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        analysis_date: åˆ†ææ—¥æœŸ
        target_price: ç›®æ ‡ä»·æ ¼
        min_points: æœ€å°‘æ•°æ®ç‚¹æ•°
        
    Returns:
        åŒ…å«è‚¡ç¥¨æ•°æ®ã€æŒ‡æ•°æ•°æ®å’Œç›®æ ‡ä»·æ ¼çš„å­—å…¸
    """
    try:
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        analysis_dt = pd.to_datetime(analysis_date)
        today = datetime.now()
        
        # é¦–å…ˆè·å–åˆ†ææ—¥æœŸä¹‹åçš„æ•°æ®
        end_date = today.strftime('%Y-%m-%d')
        start_date_post = (analysis_dt + timedelta(days=1)).strftime('%Y-%m-%d')
        
        # è·å–åˆ†ææ—¥æœŸä¹‹åçš„è‚¡ç¥¨æ•°æ®
        stock_df_post = get_stock_data_from_api(stock_code, start_date_post, end_date)
        
        # è·å–å¯¹åº”çš„å¤§ç›˜æŒ‡æ•°ä»£ç 
        index_code, index_name = get_market_index_code(stock_code)
        index_df_post = get_index_data_from_api(index_code, start_date_post, end_date)
        
        # å¦‚æœåˆ†ææ—¥æœŸåçš„æ•°æ®ç‚¹å°‘äºmin_pointsï¼Œéœ€è¦è·å–åˆ†ææ—¥æœŸå‰çš„æ•°æ®
        total_points = len(stock_df_post)
        if total_points < min_points:
            # è®¡ç®—éœ€è¦è·å–å¤šå°‘å¤©å‰çš„æ•°æ®
            days_before = (min_points - total_points) + 10  # å¤šè·å–ä¸€äº›ï¼Œä»¥é˜²æœ‰ç¼ºå¤±æ•°æ®
            start_date_pre = (analysis_dt - timedelta(days=days_before)).strftime('%Y-%m-%d')
            end_date_pre = analysis_date
            
            # è·å–åˆ†ææ—¥æœŸå‰çš„æ•°æ®
            stock_df_pre = get_stock_data_from_api(stock_code, start_date_pre, end_date_pre)
            index_df_pre = get_index_data_from_api(index_code, start_date_pre, end_date_pre)
            
            # åˆå¹¶æ•°æ®
            stock_df = _merge_dataframes(stock_df_pre, stock_df_post)
            index_df = _merge_dataframes(index_df_pre, index_df_post)
        else:
            stock_df = stock_df_post
            index_df = index_df_post
        
        # ç¡®ä¿æ•°æ®ç‚¹ä¸å°‘äºmin_pointsï¼ˆå¦‚æœæ•°æ®ä¸è¶³ï¼Œè‡³å°‘è¿”å›ç°æœ‰æ•°æ®ï¼‰
        if len(stock_df) < min_points and len(stock_df) > 0:
            # å¦‚æœæ•°æ®ä»ç„¶ä¸è¶³ï¼Œå°è¯•è·å–æ›´å¤šå†å²æ•°æ®
            days_before = min_points * 2
            start_date_pre = (analysis_dt - timedelta(days=days_before)).strftime('%Y-%m-%d')
            end_date_pre = analysis_date
            
            stock_df_pre = get_stock_data_from_api(stock_code, start_date_pre, end_date_pre)
            index_df_pre = get_index_data_from_api(index_code, start_date_pre, end_date_pre)
            
            stock_df = _merge_dataframes(stock_df_pre, stock_df)
            index_df = _merge_dataframes(index_df_pre, index_df)
        
        # æ ‡è®°åˆ†ææ—¥æœŸï¼ˆåªåœ¨æœ‰æ•°æ®æ—¶ï¼‰
        analysis_date_dt = pd.to_datetime(analysis_date)
        
        for df_name, df in [('stock', stock_df), ('index', index_df)]:
            if df.empty:
                continue
            
            if 'date' not in df.columns:
                logger.warning(f"{df_name}æ•°æ®ç¼ºå°‘dateåˆ—ï¼Œå°è¯•ä¿®å¤...")
                df = _normalize_date_column(df)
                if df_name == 'stock':
                    stock_df = df
                else:
                    index_df = df
                if df.empty:
                    continue
            
            if 'date' in df.columns:
                df['is_after_analysis'] = df['date'] >= analysis_date_dt
                if df_name == 'stock':
                    stock_df = df
                else:
                    index_df = df
        
        return {
            'stock_data': stock_df,
            'index_data': index_df,
            'target_price': target_price,
            'analysis_date': analysis_date,
            'index_code': index_code,
            'index_name': index_name
        }
        
    except Exception as e:
        logger.error(f"å‡†å¤‡å›æµ‹æ•°æ®å¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return {
            'stock_data': pd.DataFrame(),
            'index_data': pd.DataFrame(),
            'target_price': target_price,
            'analysis_date': analysis_date,
            'index_code': '',
            'index_name': ''
        }


def _get_stock_name(stock_code: str) -> str:
    """
    è·å–è‚¡ç¥¨åç§°
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        
    Returns:
        è‚¡ç¥¨åç§°ï¼Œå¦‚æœè·å–å¤±è´¥åˆ™è¿”å›è‚¡ç¥¨ä»£ç 
    """
    try:
        from tradingagents.dataflows.interface import get_china_stock_info_unified
        stock_info = get_china_stock_info_unified(stock_code)
        if "è‚¡ç¥¨åç§°:" in stock_info:
            return stock_info.split("è‚¡ç¥¨åç§°:")[1].split("\n")[0].strip()
    except Exception as e:
        logger.debug(f"è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")
    
    # é™çº§æ–¹æ¡ˆï¼šå°è¯•ä»æ•°æ®æºç®¡ç†å™¨è·å–
    try:
        from tradingagents.dataflows.data_source_manager import get_data_source_manager
        from tradingagents.utils.stock_utils import StockUtils
        
        manager = get_data_source_manager()
        market_info = StockUtils.get_market_info(stock_code)
        if market_info['is_china']:
            from tradingagents.dataflows.tushare_adapter import get_tushare_adapter
            adapter = get_tushare_adapter()
            if adapter and adapter.provider and adapter.provider.connected:
                try:
                    stock_basic = adapter.provider.get_stock_basic_info(stock_code)
                    if stock_basic and 'name' in stock_basic:
                        return stock_basic['name']
                except:
                    pass
    except Exception as e:
        logger.debug(f"ä»æ•°æ®æºç®¡ç†å™¨è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")
    
    return stock_code


def render_backtest_chart(backtest_data: Dict[str, Any], stock_code: str):
    """
    æ¸²æŸ“å›æµ‹å›¾è¡¨
    
    Args:
        backtest_data: å›æµ‹æ•°æ®å­—å…¸
        stock_code: è‚¡ç¥¨ä»£ç 
    """
    stock_df = backtest_data['stock_data']
    index_df = backtest_data['index_data']
    target_price = backtest_data['target_price']
    analysis_date = backtest_data['analysis_date']
    index_name = backtest_data['index_name']
    
    if stock_df.empty:
        st.warning("æš‚æ— è‚¡ç¥¨æ•°æ®ï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨")
        return
    
    # è·å–è‚¡ç¥¨åç§°
    stock_name = _get_stock_name(stock_code)
    
    # åˆ›å»ºå­å›¾
    fig = make_subplots(
        rows=2, cols=1,
        shared_xaxes=False,  # ä¸å…±äº«xè½´ï¼Œè®©ä¸¤ä¸ªå›¾éƒ½èƒ½æ˜¾ç¤ºæ—¥æœŸæ ‡ç­¾
        vertical_spacing=0.15,  # å¢åŠ é—´è·ï¼Œé¿å…ä»·æ ¼å›¾çš„xè½´æ ‡ç­¾è¢«é®ç›–
        row_heights=[0.7, 0.3],
        subplot_titles=(f'{stock_name} ({stock_code}) å›æµ‹å¯¹æ¯”å›¾', 'æˆäº¤é‡')
    )
    
    # åˆ†ææ—¥æœŸ
    analysis_date_dt = pd.to_datetime(analysis_date)
    
    # ç»˜åˆ¶è‚¡ç¥¨æ”¶ç›˜ä»·ï¼ˆä¸æ‹†åˆ†ï¼Œåˆå¹¶ä¸ºä¸€æ¡çº¿ï¼‰
    if not stock_df.empty:
        fig.add_trace(
            go.Scatter(
                x=stock_df['date'],
                y=stock_df['close'],
                mode='lines',
                name=f'{stock_name} å®é™…æ”¶ç›˜ä»·',
                line=dict(color='blue', width=2),
                legendgroup='stock'
            ),
            row=1, col=1
        )
    
    # ç»˜åˆ¶æŒ‡æ•°æ•°æ®ï¼ˆå½’ä¸€åŒ–åˆ°è‚¡ç¥¨ä»·æ ¼èŒƒå›´ï¼‰
    if not index_df.empty:
        # è®¡ç®—å½’ä¸€åŒ–ç³»æ•°ï¼ˆä½¿æŒ‡æ•°ä¸è‚¡ç¥¨ä»·æ ¼åœ¨åŒä¸€é‡çº§ï¼‰
        stock_price_range = stock_df['close'].max() - stock_df['close'].min()
        index_price_range = index_df['close'].max() - index_df['close'].min()
        
        if index_price_range > 0 and stock_price_range > 0:
            # æ‰¾åˆ°åˆ†ææ—¥æœŸå½“å¤©çš„è‚¡ç¥¨ä»·æ ¼å’ŒæŒ‡æ•°ï¼Œç”¨äºå¯¹é½
            stock_filtered = stock_df[stock_df['date'] <= analysis_date_dt]
            index_filtered = index_df[index_df['date'] <= analysis_date_dt]
            analysis_stock_price = stock_filtered['close'].iloc[-1] if not stock_filtered.empty else stock_df['close'].iloc[0]
            analysis_index_price = index_filtered['close'].iloc[-1] if not index_filtered.empty else index_df['close'].iloc[0]
            
            # è®¡ç®—å½’ä¸€åŒ–ç³»æ•°
            scale_factor = analysis_stock_price / analysis_index_price if analysis_index_price > 0 else 1
            
            # æŒ‡æ•°æ•°æ®ä¹Ÿä¸æ‹†åˆ†ï¼Œåˆå¹¶ä¸ºä¸€æ¡çº¿
            if not index_df.empty:
                index_normalized = index_df['close'] * scale_factor
                fig.add_trace(
                    go.Scatter(
                        x=index_df['date'],
                        y=index_normalized,
                        mode='lines',
                        name=f'{index_name}',
                        line=dict(color='green', width=2, dash='dash'),
                        legendgroup='index'
                    ),
                    row=1, col=1
                )
    
    # ç»˜åˆ¶ç›®æ ‡ä»·æ ¼çº¿ï¼ˆä»…åœ¨åˆ†ææ—¥æœŸä¹‹åï¼‰
    if target_price is not None:
        stock_after = stock_df[stock_df['date'] >= analysis_date_dt]
        if not stock_after.empty:
            fig.add_trace(
                go.Scatter(
                    x=stock_after['date'],
                    y=[target_price] * len(stock_after),
                    mode='lines',
                    name=f'ç›®æ ‡ä»·æ ¼: {target_price:.2f}',
                    line=dict(color='red', width=2, dash='dot'),
                    legendgroup='target'
                ),
                row=1, col=1
            )
    
    # æ·»åŠ åˆ†ææ—¥æœŸæ ‡è®°çº¿ï¼ˆplotly çš„ add_vline éœ€è¦ int/float ç±»å‹ï¼‰
    analysis_date_timestamp = _timestamp_to_milliseconds(analysis_date_dt)
    fig.add_vline(
        x=analysis_date_timestamp,
        line_dash="dash",
        line_color="orange",
        annotation_text="åˆ†ææ—¥æœŸ",
        annotation_position="top",
        row=1, col=1
    )
    
    # ç»˜åˆ¶æˆäº¤é‡ï¼ˆä¸æ‹†åˆ†ï¼Œåˆå¹¶ä¸ºä¸€æ¡ï¼‰
    if 'volume' in stock_df.columns and not stock_df.empty:
        fig.add_trace(
            go.Bar(
                x=stock_df['date'],
                y=stock_df['volume'],
                name='æˆäº¤é‡',
                marker_color='gray',
                legendgroup='volume',
                showlegend=False
            ),
            row=2, col=1
        )
    
    # æ›´æ–°å¸ƒå±€
    # ä»·æ ¼å›¾çš„xè½´ï¼šæ˜¾ç¤ºæ—¥æœŸæ ‡ç­¾ï¼ˆä»…æœˆ-æ—¥ï¼‰
    fig.update_xaxes(
        title_text="æ—¥æœŸ",
        tickformat='%m-%d',
        type='date',
        tickangle=-45,
        showgrid=True,
        showticklabels=True,
        row=1, col=1
    )
    # æˆäº¤é‡å›¾çš„xè½´ï¼šæ˜¾ç¤ºæ—¥æœŸæ ‡ç­¾ï¼ˆä»…æœˆ-æ—¥ï¼‰
    fig.update_xaxes(
        title_text="æ—¥æœŸ",
        tickformat='%m-%d',
        type='date',
        tickangle=-45,
        showgrid=True,
        showticklabels=True,
        row=2, col=1
    )
    fig.update_yaxes(title_text="ä»·æ ¼", row=1, col=1)
    fig.update_yaxes(title_text="æˆäº¤é‡", row=2, col=1)
    
    fig.update_layout(
        height=850,  # ç¨å¾®å¢åŠ é«˜åº¦ï¼Œä¸ºxè½´æ ‡ç­¾ç•™å‡ºç©ºé—´
        title_text=f"{stock_name} ({stock_code}) å›æµ‹åˆ†æ",
        hovermode='x unified',
        margin=dict(b=100)  # å¢åŠ åº•éƒ¨è¾¹è·ï¼Œç¡®ä¿xè½´æ ‡ç­¾å¯è§
    )
    
    st.plotly_chart(fig, use_container_width=True)


def render_backtest_table(backtest_data: Dict[str, Any], stock_code: str):
    """
    æ¸²æŸ“å›æµ‹æ•°æ®è¡¨
    
    Args:
        backtest_data: å›æµ‹æ•°æ®å­—å…¸
        stock_code: è‚¡ç¥¨ä»£ç 
    """
    stock_df = backtest_data['stock_data']
    index_df = backtest_data['index_data']
    target_price = backtest_data['target_price']
    analysis_date = backtest_data['analysis_date']
    index_name = backtest_data['index_name']
    
    if stock_df.empty:
        st.warning("æš‚æ— è‚¡ç¥¨æ•°æ®ï¼Œæ— æ³•æ˜¾ç¤ºæ•°æ®è¡¨")
        return
    
    # åˆå¹¶æ•°æ®
    result_df = stock_df[['date', 'close']].copy()
    result_df.columns = ['æ—¥æœŸ', f'{stock_code}æ”¶ç›˜ä»·']
    
    # æ·»åŠ æŒ‡æ•°æ•°æ®
    if not index_df.empty:
        index_data_dict = dict(zip(index_df['date'], index_df['close']))
        result_df[f'{index_name}'] = result_df['æ—¥æœŸ'].map(index_data_dict)
    
    # æ·»åŠ ç›®æ ‡ä»·æ ¼
    if target_price is not None:
        analysis_date_dt = pd.to_datetime(analysis_date)
        result_df['ç›®æ ‡ä»·æ ¼'] = result_df.apply(
            lambda row: target_price if pd.to_datetime(row['æ—¥æœŸ']) >= analysis_date_dt else None,
            axis=1
        )
    
    # æ·»åŠ åˆ†ææ—¥æœŸæ ‡è®°
    analysis_date_dt = pd.to_datetime(analysis_date)
    result_df['æ˜¯å¦åˆ†æå'] = result_df['æ—¥æœŸ'] >= analysis_date_dt
    
    # è®¡ç®—ç›®æ ‡ä»·æ ¼è¯¯å·®ï¼ˆå¦‚æœåˆ†ææ—¥æœŸåï¼‰
    if target_price is not None:
        result_df['ä»·æ ¼è¯¯å·®'] = result_df.apply(
            lambda row: abs(row[f'{stock_code}æ”¶ç›˜ä»·'] - target_price) if row['æ˜¯å¦åˆ†æå'] and pd.notna(row[f'{stock_code}æ”¶ç›˜ä»·']) else None,
            axis=1
        )
        result_df['ä»·æ ¼è¯¯å·®ç‡(%)'] = result_df.apply(
            lambda row: abs((row[f'{stock_code}æ”¶ç›˜ä»·'] - target_price) / target_price * 100) if row['æ˜¯å¦åˆ†æå'] and pd.notna(row[f'{stock_code}æ”¶ç›˜ä»·']) and target_price > 0 else None,
            axis=1
        )
    
    # æ ¼å¼åŒ–æ—¥æœŸ
    result_df['æ—¥æœŸ'] = result_df['æ—¥æœŸ'].dt.strftime('%Y-%m-%d')
    
    # é‡æ–°æ’åˆ—åˆ—
    columns = ['æ—¥æœŸ', f'{stock_code}æ”¶ç›˜ä»·']
    if not index_df.empty:
        columns.append(f'{index_name}')
    if target_price is not None:
        columns.extend(['ç›®æ ‡ä»·æ ¼', 'ä»·æ ¼è¯¯å·®', 'ä»·æ ¼è¯¯å·®ç‡(%)'])
    columns.append('æ˜¯å¦åˆ†æå')
    
    result_df = result_df[columns]
    
    # æ˜¾ç¤ºæ•°æ®è¡¨
    st.subheader("ğŸ“Š å›æµ‹æ•°æ®å¯¹æ¯”è¡¨")
    st.dataframe(result_df, use_container_width=True)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if target_price is not None:
        after_analysis = result_df[result_df['æ˜¯å¦åˆ†æå'] == True]
        if not after_analysis.empty and 'ä»·æ ¼è¯¯å·®' in after_analysis.columns:
            errors = after_analysis['ä»·æ ¼è¯¯å·®'].dropna()
            if not errors.empty:
                st.subheader("ğŸ“ˆ ç›®æ ‡ä»·æ ¼å‡†ç¡®æ€§ç»Ÿè®¡")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("å¹³å‡è¯¯å·®", f"{errors.mean():.2f}")
                with col2:
                    st.metric("æœ€å¤§è¯¯å·®", f"{errors.max():.2f}")
                with col3:
                    st.metric("æœ€å°è¯¯å·®", f"{errors.min():.2f}")
                with col4:
                    if 'ä»·æ ¼è¯¯å·®ç‡(%)' in after_analysis.columns:
                        error_rates = after_analysis['ä»·æ ¼è¯¯å·®ç‡(%)'].dropna()
                        if not error_rates.empty:
                            st.metric("å¹³å‡è¯¯å·®ç‡", f"{error_rates.mean():.2f}%")


def render_backtest_page():
    """æ¸²æŸ“å›æµ‹é¡µé¢"""
    st.header("ğŸ“ˆ åˆ†æç»“æœå›æµ‹")
    
    # æ£€æŸ¥MongoDBè¿æ¥
    if not MONGODB_AVAILABLE:
        st.error("âŒ MongoDBæœªè¿æ¥ï¼Œæ— æ³•è¯»å–åˆ†æç»“æœã€‚è¯·æ£€æŸ¥MongoDBé…ç½®ã€‚")
        return
    
    # è¾“å…¥è‚¡ç¥¨ä»£ç 
    stock_code = st.text_input(
        "è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ",
        value="",
        help="ä¾‹å¦‚ï¼š000001ï¼ˆå¹³å®‰é“¶è¡Œï¼‰ã€600036ï¼ˆæ‹›å•†é“¶è¡Œï¼‰",
        key="backtest_stock_code"
    )
    
    if not stock_code:
        st.info("ğŸ‘† è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ä»¥å¼€å§‹å›æµ‹")
        return
    
    # æŸ¥è¯¢æŒ‰é’®
    col1, col2 = st.columns([1, 4])
    with col1:
        query_button = st.button("ğŸ” æŸ¥è¯¢åˆ†æç»“æœ", key="query_analysis_results", type="primary")
    
    # åˆå§‹åŒ–session state
    if 'backtest_analysis_reports' not in st.session_state:
        st.session_state.backtest_analysis_reports = None
    if 'backtest_selected_report' not in st.session_state:
        st.session_state.backtest_selected_report = None
    
    # ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®
    if query_button:
        try:
            mongodb_manager = MongoDBReportManager()
            if not mongodb_manager.connected:
                st.error("âŒ æ— æ³•è¿æ¥åˆ°MongoDBï¼Œè¯·æ£€æŸ¥æ•°æ®åº“é…ç½®ã€‚")
                st.session_state.backtest_analysis_reports = None
                return
            
            # æ ¹æ®è‚¡ç¥¨ä»£ç æŸ¥è¯¢åˆ†æç»“æœ
            with st.spinner("æ­£åœ¨æŸ¥è¯¢åˆ†æç»“æœ..."):
                analysis_reports = mongodb_manager.get_analysis_reports(
                    limit=100,
                    stock_symbol=stock_code
                )
            
            if not analysis_reports:
                st.warning(f"âš ï¸ æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„åˆ†æç»“æœã€‚è¯·å…ˆè¿›è¡Œè‚¡ç¥¨åˆ†æã€‚")
                st.session_state.backtest_analysis_reports = None
            else:
                # æŒ‰æ—¶é—´å€’åºæ’åˆ—
                analysis_reports = sorted(analysis_reports, key=lambda x: x.get('timestamp', 0), reverse=True)
                st.session_state.backtest_analysis_reports = analysis_reports
                st.success(f"âœ… æ‰¾åˆ° {len(analysis_reports)} æ¡åˆ†æç»“æœ")
        
        except Exception as e:
            logger.error(f"æŸ¥è¯¢åˆ†æç»“æœå¤±è´¥: {e}")
            st.error(f"âŒ æŸ¥è¯¢åˆ†æç»“æœå¤±è´¥: {str(e)}")
            st.session_state.backtest_analysis_reports = None
    
    # æ˜¾ç¤ºåˆ†æç»“æœåˆ—è¡¨
    analysis_reports = st.session_state.backtest_analysis_reports
    
    if analysis_reports is None:
        if not query_button:
            st.info("ğŸ‘† è¯·è¾“å…¥è‚¡ç¥¨ä»£ç åï¼Œç‚¹å‡»ã€ŒæŸ¥è¯¢åˆ†æç»“æœã€æŒ‰é’®")
        return
    
    if not analysis_reports:
        st.warning(f"âš ï¸ æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„åˆ†æç»“æœã€‚è¯·å…ˆè¿›è¡Œè‚¡ç¥¨åˆ†æã€‚")
        return
    
    # æ˜¾ç¤ºåˆ†æç»“æœåˆ—è¡¨
    st.subheader("ğŸ“‹ åˆ†æç»“æœåˆ—è¡¨")
    
    # åˆ›å»ºé€‰æ‹©æ¡†
    report_options = []
    for report in analysis_reports:
        timestamp = report.get('timestamp', 0)
        if isinstance(timestamp, (int, float)):
            date_str = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')
        else:
            date_str = str(timestamp)
        
        analysis_date = report.get('analysis_date', '')
        if not analysis_date:
            # å°è¯•ä»timestampæå–
            if isinstance(timestamp, (int, float)):
                analysis_date = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
            else:
                analysis_date = date_str
        
        option_text = f"{analysis_date} - {report.get('analysis_id', 'N/A')}"
        report_options.append((option_text, report))
    
    if not report_options:
        st.warning("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ†æç»“æœã€‚")
        return
    
    # æ˜¾ç¤ºåˆ†æç»“æœé€‰æ‹©æ¡†
    selected_option = st.selectbox(
        "é€‰æ‹©è¦å›æµ‹çš„åˆ†æç»“æœ",
        options=[opt[0] for opt in report_options],
        key="backtest_report_select",
        help="é€‰æ‹©ä¸€æ¡åˆ†æç»“æœè¿›è¡Œå›æµ‹"
    )
    
    selected_index = [opt[0] for opt in report_options].index(selected_option)
    selected_report = report_options[selected_index][1]
    
    # ä¿å­˜é€‰ä¸­çš„æŠ¥å‘Š
    st.session_state.backtest_selected_report = selected_report
        
    # æ˜¾ç¤ºåˆ†æç»“æœä¿¡æ¯
    st.markdown("---")
    st.subheader("ğŸ“Š é€‰ä¸­çš„åˆ†æç»“æœä¿¡æ¯")
    
    col1, col2 = st.columns(2)
    with col1:
        st.info(f"""
        **åˆ†æID**: {selected_report.get('analysis_id', 'N/A')}  
        **åˆ†ææ—¥æœŸ**: {selected_report.get('analysis_date', 'N/A')}  
        """)
    with col2:
        st.info(f"""
        **åˆ†æå¸ˆ**: {', '.join(selected_report.get('analysts', []))}  
        **ç ”ç©¶æ·±åº¦**: {selected_report.get('research_depth', 'N/A')}
        """)
    
    # å¼€å§‹å›æµ‹æŒ‰é’®
    st.markdown("---")
    start_backtest = st.button("ğŸš€ å¼€å§‹å›æµ‹", key="start_backtest", type="primary")
    
    if not start_backtest:
        st.info("ğŸ‘† ç¡®è®¤åˆ†æç»“æœåï¼Œç‚¹å‡»ã€Œå¼€å§‹å›æµ‹ã€æŒ‰é’®è¿›è¡Œå›æµ‹")
        return
    
    # æå–åˆ†ææ—¥æœŸå’Œç›®æ ‡ä»·æ ¼
    analysis_date = selected_report.get('analysis_date', '')
    if not analysis_date:
        # ä»timestampæå–
        timestamp = selected_report.get('timestamp', 0)
        if isinstance(timestamp, (int, float)):
            analysis_date = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
        elif hasattr(timestamp, 'strftime'):
            # å¦‚æœæ˜¯datetimeå¯¹è±¡
            analysis_date = timestamp.strftime('%Y-%m-%d')
        else:
            st.error("æ— æ³•ç¡®å®šåˆ†ææ—¥æœŸ")
            return
    
    # æå–formatted_decisionä¿¡æ¯
    formatted_decision = selected_report.get('formatted_decision', {})
    if not formatted_decision:
        st.warning("âš ï¸ æœªæ‰¾åˆ°å†³ç­–ä¿¡æ¯ï¼Œå°†ä»…æ˜¾ç¤ºå®é™…ä»·æ ¼å’ŒæŒ‡æ•°å¯¹æ¯”ã€‚")
    
    # æå–ç›®æ ‡ä»·æ ¼
    target_price = None
    if isinstance(formatted_decision, dict):
        target_price = formatted_decision.get('target_price')
        if target_price is not None:
            try:
                if isinstance(target_price, str):
                    # æ¸…ç†å­—ç¬¦ä¸²æ ¼å¼çš„ä»·æ ¼
                    clean_price = target_price.replace('$', '').replace('Â¥', '').replace('ï¿¥', '').replace('å…ƒ', '').strip()
                    target_price = float(clean_price) if clean_price and clean_price.lower() not in ['none', 'null', ''] else None
                elif isinstance(target_price, (int, float)):
                    target_price = float(target_price)
            except (ValueError, TypeError):
                target_price = None
    
    # æ˜¾ç¤ºå†³ç­–ä¿¡æ¯
    if formatted_decision:
        st.markdown("---")
        st.subheader("ğŸ“‹ äº¤æ˜“å†³ç­–ä¿¡æ¯")
        
        col1, col2 = st.columns(2)
        with col1:
            action = formatted_decision.get('action', 'N/A')
            action_color = 'red' if action == 'å–å‡º' else ('green' if action == 'ä¹°å…¥' else 'gray')
            st.markdown(f"**æ“ä½œå»ºè®®**: <span style='color:{action_color};font-weight:bold'>{action}</span>", unsafe_allow_html=True)
            
            target_price_str = f"{target_price:.2f}" if target_price is not None else "N/A"
            st.markdown(f"**ç›®æ ‡ä»·æ ¼**: {target_price_str}")
        
        with col2:
            confidence = formatted_decision.get('confidence', 0)
            confidence_str = f"{confidence:.1%}" if isinstance(confidence, (int, float)) else str(confidence)
            st.markdown(f"**ç½®ä¿¡åº¦**: {confidence_str}")
            
            risk_score = formatted_decision.get('risk_score', 0)
            risk_score_str = f"{risk_score:.2f}" if isinstance(risk_score, (int, float)) else str(risk_score)
            st.markdown(f"**é£é™©è¯„åˆ†**: {risk_score_str}")
        
        # æ˜¾ç¤ºå†³ç­–ç†ç”±
        reasoning = formatted_decision.get('reasoning', '')
        if reasoning:
            with st.expander("ğŸ“ å†³ç­–ç†ç”±", expanded=False):
                st.write(reasoning)
    
    # å‡†å¤‡å›æµ‹æ•°æ®
    try:
        with st.spinner("æ­£åœ¨å‡†å¤‡å›æµ‹æ•°æ®..."):
            backtest_data = prepare_backtest_data(
                stock_code=stock_code,
                analysis_date=analysis_date,
                target_price=target_price,
                min_points=30
            )
        
        # æ£€æŸ¥æ•°æ®æ˜¯å¦å‡†å¤‡æˆåŠŸ
        if backtest_data['stock_data'].empty:
            st.error("âŒ æ— æ³•è·å–è‚¡ç¥¨äº¤æ˜“æ•°æ®ï¼Œè¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®ã€‚")
            return
        
        # æ˜¾ç¤ºå›æµ‹å›¾è¡¨
        st.markdown("---")
        st.subheader("ğŸ“ˆ å›æµ‹å›¾è¡¨")
        render_backtest_chart(backtest_data, stock_code)
        
        # æ˜¾ç¤ºå›æµ‹æ•°æ®è¡¨
        st.markdown("---")
        render_backtest_table(backtest_data, stock_code)
        
    except Exception as e:
        logger.error(f"å›æµ‹æ•°æ®å¤„ç†å¤±è´¥: {e}")
        st.error(f"âŒ å›æµ‹æ•°æ®å¤„ç†å¤±è´¥: {str(e)}")

