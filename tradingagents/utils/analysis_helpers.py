"""
åˆ†æè¾…åŠ©å‡½æ•°æ¨¡å—
æä¾›ç¯å¢ƒéªŒè¯ã€è‚¡ç¥¨ä»£ç æ ¼å¼åŒ–ã€æˆæœ¬ä¼°ç®—ç­‰è¾…åŠ©åŠŸèƒ½
"""

import os
from typing import Dict, Any, Optional, Callable
from pathlib import Path

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger, get_logger_manager
from tradingagents.messaging.business.messages import NodeStatus
from tradingagents.tasks import get_task_manager
logger = get_logger('analysis')


def validate_environment(
    analysis_id: Optional[str] = None,
    async_tracker: Optional[Any] = None
) -> tuple[bool, Optional[str]]:
    """
    éªŒè¯ç¯å¢ƒå˜é‡é…ç½®
    
    Args:
        
    Returns:
        (æ˜¯å¦é€šè¿‡éªŒè¯, é”™è¯¯ä¿¡æ¯)
    """
    
    dashscope_key = os.getenv("DASHSCOPE_API_KEY")
    finnhub_key = os.getenv("FINNHUB_API_KEY")
    
    logger.info(f"ç¯å¢ƒå˜é‡æ£€æŸ¥:")
    logger.info(f"  DASHSCOPE_API_KEY: {'å·²è®¾ç½®' if dashscope_key else 'æœªè®¾ç½®'}")
    logger.info(f"  FINNHUB_API_KEY: {'å·²è®¾ç½®' if finnhub_key else 'æœªè®¾ç½®'}")
    
    if not dashscope_key:
        error_msg = "DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®"
        return False, error_msg
    
    # if not finnhub_key:
    #     error_msg = "FINNHUB_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®"
    #     return False, error_msg
    
    return True, None


def format_stock_symbol(stock_symbol: str, market_type: str) -> str:
    """
    æ ¹æ®å¸‚åœºç±»å‹æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 
    
    Args:
        stock_symbol: åŸå§‹è‚¡ç¥¨ä»£ç 
        market_type: å¸‚åœºç±»å‹ï¼ˆAè‚¡/æ¸¯è‚¡/ç¾è‚¡ï¼‰
        
    Returns:
        æ ¼å¼åŒ–åçš„è‚¡ç¥¨ä»£ç 
    """
    logger.debug(f"ğŸ” [ä»£ç æ ¼å¼åŒ–] åŸå§‹ä»£ç : '{stock_symbol}', å¸‚åœºç±»å‹: '{market_type}'")
    
    if market_type == "Aè‚¡":
        # Aè‚¡ä»£ç ä¸éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œä¿æŒåŸæ ·
        formatted_symbol = stock_symbol
        logger.debug(f"ğŸ” [ä»£ç æ ¼å¼åŒ–] Aè‚¡ä»£ç ä¿æŒåŸæ ·: '{formatted_symbol}'")
    elif market_type == "æ¸¯è‚¡":
        # æ¸¯è‚¡ä»£ç è½¬ä¸ºå¤§å†™ï¼Œç¡®ä¿.HKåç¼€
        formatted_symbol = stock_symbol.upper()
        if not formatted_symbol.endswith('.HK'):
            # å¦‚æœæ˜¯çº¯æ•°å­—ï¼Œæ·»åŠ .HKåç¼€
            if formatted_symbol.isdigit():
                formatted_symbol = f"{formatted_symbol.zfill(4)}.HK"
        logger.debug(f"ğŸ” [ä»£ç æ ¼å¼åŒ–] æ¸¯è‚¡ä»£ç : '{stock_symbol}' -> '{formatted_symbol}'")
    else:
        # ç¾è‚¡ä»£ç è½¬ä¸ºå¤§å†™
        formatted_symbol = stock_symbol.upper()
        logger.debug(f"ğŸ” [ä»£ç æ ¼å¼åŒ–] ç¾è‚¡ä»£ç è½¬å¤§å†™: '{stock_symbol}' -> '{formatted_symbol}'")
    
    logger.debug(f"ğŸ” [ä»£ç æ ¼å¼åŒ–] æœ€ç»ˆä»£ç : '{formatted_symbol}'")
    return formatted_symbol


def estimate_analysis_cost(
    llm_provider: str,
    llm_model: str,
    analysts: list,
    research_depth: int,
    analysis_id: Optional[str] = None,
    async_tracker: Optional[Any] = None
) -> Optional[float]:
    """
    ä¼°ç®—åˆ†ææˆæœ¬
    
    Args:
        llm_provider: LLMæä¾›å•†
        llm_model: æ¨¡å‹åç§°
        analysts: åˆ†æå¸ˆåˆ—è¡¨
        research_depth: ç ”ç©¶æ·±åº¦
        analysis_id: åˆ†æIDï¼ˆç”¨äºæ¶ˆæ¯å‘å¸ƒï¼‰
        async_tracker: å¼‚æ­¥è¿›åº¦è·Ÿè¸ªå™¨ï¼ˆç”¨äºæ¶ˆæ¯å‘å¸ƒï¼‰
        
    Returns:
        ä¼°ç®—çš„æˆæœ¬ï¼ˆå…ƒï¼‰ï¼Œå¦‚æœæ— æ³•ä¼°ç®—åˆ™è¿”å›None
    """
    # è·å–æ¶ˆæ¯ç”Ÿäº§è€…ï¼ˆå¦‚æœæ¶ˆæ¯æ¨¡å¼å¯ç”¨ï¼‰
    message_producer = None
    if analysis_id:
        try:
            from tradingagents.messaging.config import get_message_producer, is_message_mode_enabled
            message_producer = get_message_producer() if is_message_mode_enabled() else None
        except Exception:
            pass
    try:
        from tradingagents.config.config_manager import token_tracker
    except ImportError:
        return False, None, "âš ï¸ Tokenè·Ÿè¸ªåŠŸèƒ½æœªå¯ç”¨ï¼Œæ— æ³•ä¼°ç®—æˆæœ¬"
    
    # ä¼°ç®—æ¯ä¸ªåˆ†æå¸ˆçš„tokenä½¿ç”¨é‡ï¼ˆæ ¹æ®ç ”ç©¶æ·±åº¦è°ƒæ•´ï¼‰
    base_input_tokens = 2000
    base_output_tokens = 1000
    
    # ç ”ç©¶æ·±åº¦è¶Šé«˜ï¼Œtokenä½¿ç”¨è¶Šå¤š
    depth_multiplier = {
        1: 1.0,
        2: 1.2,
        3: 1.5,
        4: 2.0,
        5: 2.5,
    }.get(research_depth, 1.5)
    
    estimated_input = int(base_input_tokens * len(analysts) * depth_multiplier)
    estimated_output = int(base_output_tokens * len(analysts) * depth_multiplier)
    
    estimated_cost = token_tracker.estimate_cost(
        llm_provider, llm_model, estimated_input, estimated_output
    )
    return True, estimated_cost, None


def prepare_stock_data_for_analysis(
    stock_symbol: str,
    market_type: str,
    analysis_date: str,
    analysis_id: Optional[str] = None,
    async_tracker: Optional[Any] = None
) -> tuple[bool, Optional[str], Optional[Any]]:
    """
    é¢„è·å–å’ŒéªŒè¯è‚¡ç¥¨æ•°æ®
    
    Args:
        stock_symbol: è‚¡ç¥¨ä»£ç 
        market_type: å¸‚åœºç±»å‹
        analysis_date: åˆ†ææ—¥æœŸ
        
    Returns:
        (æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯, å‡†å¤‡ç»“æœ)
    """
    
    try:
        from tradingagents.utils.stock_validator import prepare_stock_data
        
        # é¢„è·å–è‚¡ç¥¨æ•°æ®ï¼ˆé»˜è®¤30å¤©å†å²æ•°æ®ï¼‰
        preparation_result = prepare_stock_data(
            stock_code=stock_symbol,
            market_type=market_type,
            period_days=30,
            analysis_date=analysis_date
        )
        
        if not preparation_result.is_valid:
            error_msg = f"âŒ è‚¡ç¥¨æ•°æ®éªŒè¯å¤±è´¥: {preparation_result.error_message}"
            logger.error(error_msg)
            return False, preparation_result.error_message, preparation_result
        
        # æ•°æ®é¢„è·å–æˆåŠŸ
        success_msg = f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ: {preparation_result.stock_name} ({preparation_result.market_type})"
        logger.info(success_msg)
        logger.info(f"ç¼“å­˜çŠ¶æ€: {preparation_result.cache_status}")
        return True, None, preparation_result
        
    except Exception as e:
        error_msg = f"âŒ æ•°æ®é¢„è·å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        logger.error(error_msg)
        return False, error_msg, None


def check_task_control(
    analysis_id: Optional[str],
    async_tracker: Optional[Any]
) -> bool:
    """
    æ£€æŸ¥ä»»åŠ¡æ§åˆ¶ä¿¡å·ï¼ˆæš‚åœ/åœæ­¢ï¼‰
    
    Args:
        analysis_id: åˆ†æä»»åŠ¡ID
        async_tracker: å¼‚æ­¥è¿›åº¦è·Ÿè¸ªå™¨
        
    Returns:
        æ˜¯å¦ç»§ç»­æ‰§è¡Œï¼ˆTrueç»§ç»­ï¼ŒFalseåœæ­¢ï¼‰
    """
    if not analysis_id:
        return True  # æ²¡æœ‰analysis_idï¼Œç»§ç»­æ‰§è¡Œ
    
    try:
        from tradingagents.tasks import get_task_manager
        task_manager = get_task_manager()
        
        # æ£€æŸ¥åœæ­¢ä¿¡å·
        if task_manager.should_stop(analysis_id):
            logger.info(f"â¹ï¸ [ä»»åŠ¡æ§åˆ¶] æ”¶åˆ°åœæ­¢ä¿¡å·: {analysis_id}")
            if async_tracker:
                async_tracker.mark_stopped("ç”¨æˆ·åœæ­¢äº†åˆ†æä»»åŠ¡")
            return False
        
        # æ£€æŸ¥æš‚åœä¿¡å·
        if task_manager.should_pause(analysis_id):
            logger.info(f"â¸ï¸ [ä»»åŠ¡æ§åˆ¶] æ”¶åˆ°æš‚åœä¿¡å·: {analysis_id}")
            if async_tracker:
                async_tracker.mark_paused()
            
            # ç­‰å¾…ç›´åˆ°æ¢å¤æˆ–åœæ­¢
            task_manager.wait_if_paused(analysis_id)
            
            # æ£€æŸ¥æ˜¯å¦åœ¨æš‚åœæœŸé—´è¢«åœæ­¢
            if task_manager.should_stop(analysis_id):
                logger.info(f"â¹ï¸ [ä»»åŠ¡æ§åˆ¶] æš‚åœæœŸé—´æ”¶åˆ°åœæ­¢ä¿¡å·: {analysis_id}")
                if async_tracker:
                    async_tracker.mark_stopped("ç”¨æˆ·åœæ­¢äº†åˆ†æä»»åŠ¡")
                return False
            
            # æ¢å¤æ‰§è¡Œ
            logger.info(f"â–¶ï¸ [ä»»åŠ¡æ§åˆ¶] ä»»åŠ¡æ¢å¤æ‰§è¡Œ: {analysis_id}")
            if async_tracker:
                async_tracker.mark_resumed()
        
        return True  # ç»§ç»­æ‰§è¡Œ
        
    except Exception as e:
        logger.error(f"âŒ [ä»»åŠ¡æ§åˆ¶] æ£€æŸ¥ä»»åŠ¡æ§åˆ¶çŠ¶æ€å¤±è´¥: {e}")
        return True  # å‡ºé”™æ—¶ç»§ç»­æ‰§è¡Œ


def track_token_usage(
    results: Dict[str, Any],
    params: Dict[str, Any]
) -> Optional[float]:
    """
    è®°å½•Tokenä½¿ç”¨æƒ…å†µ
    
    Args:
        results: åˆ†æç»“æœå­—å…¸ï¼ŒåŒ…å« llm_provider, llm_model, session_id, analysts, research_depth
        params: å‚æ•°å­—å…¸ï¼ŒåŒ…å« market_type
        
    Returns:
        æ€»æˆæœ¬ï¼ˆå…ƒï¼‰ï¼Œå¦‚æœæ— æ³•è·Ÿè¸ªåˆ™è¿”å›None
    """
    try:
        from tradingagents.config.config_manager import token_tracker
    except ImportError:
        return None
    
    # ä» results å’Œ params ä¸­æå–æ‰€éœ€ä¿¡æ¯
    analysts = results.get('analysts', [])
    research_depth = results.get('research_depth', 2)
    market_type = params.get('market_type', 'ç¾è‚¡')
    
    # ä¼°ç®—å®é™…ä½¿ç”¨çš„tokenï¼ˆåŸºäºåˆ†æå¸ˆæ•°é‡å’Œç ”ç©¶æ·±åº¦ï¼‰
    depth_token_map = {
        1: (1500, 800),
        2: (2000, 1000),
        3: (2500, 1200),
        4: (3000, 1500),
        5: (4000, 2000),
    }
    
    input_per_analyst, output_per_analyst = depth_token_map.get(research_depth, (2500, 1200))
    
    usage_record = token_tracker.track_usage(
        provider=results.get('llm_provider', 'dashscope'),
        model_name=results.get('llm_model', 'qwen-max'),
        input_tokens=len(analysts) * input_per_analyst,
        output_tokens=len(analysts) * output_per_analyst,
        session_id=results.get('session_id', ''),
        analysis_type=f"{market_type}_analysis"
    )

    return usage_record.cost if usage_record else None


def prepare_analysis_steps(
    stock_symbol: str,
    analysis_date: str,
    market_type: str,
    analysts: list,
    research_depth: int,
    llm_provider: str,
    llm_model: str,
    analysis_id: Optional[str],
    async_tracker: Optional[Any]
) -> tuple[bool, Optional[Dict[str, Any]], Optional[str]]:
    """
    å‡†å¤‡åˆ†ææ­¥éª¤ï¼šæ‰§è¡Œæ‰€æœ‰å‰æœŸå‡†å¤‡å·¥ä½œ
    
    å‡†å¤‡æ­¥éª¤åŒ…æ‹¬ï¼š
    - å‡†å¤‡æ­¥éª¤1: ğŸš€ åˆ†æå¯åŠ¨
    - å‡†å¤‡æ­¥éª¤2: ğŸ’° æˆæœ¬ä¼°ç®—
    - å‡†å¤‡æ­¥éª¤3: ğŸ” æ•°æ®é¢„è·å–å’ŒéªŒè¯
    - å‡†å¤‡æ­¥éª¤4: ğŸ”§ ç¯å¢ƒéªŒè¯
    - å‡†å¤‡æ­¥éª¤5: âš™ï¸ æ„å»ºé…ç½®
    - å‡†å¤‡æ­¥éª¤6: ğŸ“ æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 
    - å‡†å¤‡æ­¥éª¤7: ğŸ—ï¸ åˆå§‹åŒ–åˆ†æå¼•æ“
    - å‡†å¤‡æ­¥éª¤8: ğŸ“ æ­¥éª¤è¾“å‡ºç›®å½•å‡†å¤‡

    Args:
        stock_symbol: è‚¡ç¥¨ä»£ç 
        analysis_date: åˆ†ææ—¥æœŸ
        market_type: å¸‚åœºç±»å‹
        analysts: åˆ†æå¸ˆåˆ—è¡¨
        research_depth: ç ”ç©¶æ·±åº¦
        llm_provider: LLMæä¾›å•†
        llm_model: æ¨¡å‹åç§°
        analysis_id: åˆ†æä»»åŠ¡ID
        async_tracker: å¼‚æ­¥è¿›åº¦è·Ÿè¸ªå™¨
        
    Returns:
        (æ˜¯å¦æˆåŠŸ, å‡†å¤‡ç»“æœå­—å…¸, é”™è¯¯ä¿¡æ¯)
        å‡†å¤‡ç»“æœå­—å…¸åŒ…å«: config, formatted_symbol, graph, session_id
    """
    task_manager = get_task_manager()
    if not task_manager or not analysis_id:
        raise ValueError("Task manager or analysis_id: {analysis_id} is not available")
    from .analysis_config import AnalysisConfigBuilder
    
    preparation_result = None
    formatted_symbol = None
    config = None
    graph = None
    step_name = ""
    
    def _update_step_start(message: str):
        task_manager.update_task_progress(analysis_id, step_name, message, 'start')

    def _update_step_success(message: str):
        task_manager.update_task_progress(analysis_id, step_name, message, 'success')
    
    def _update_step_error(message: str):
        task_manager.update_task_progress(analysis_id, step_name, message, 'error')
    
    # ========== Step 1: åˆ†æå¯åŠ¨ ==========
    step_name = "analysis_start"
    _update_step_start("ğŸš€ å¼€å§‹è‚¡ç¥¨åˆ†æ...")
    logger_manager, analysis_start_time = log_analysis_start(analysis_id)
    _update_step_success("âœ… åˆ†æå¯åŠ¨å®Œæˆ")

    # ========== Step 2: æˆæœ¬ä¼°ç®— ==========
    step_name = "cost_estimation"
    _update_step_start("ğŸ’° å¼€å§‹æˆæœ¬ä¼°ç®—...")
    success, estimated_cost, exec_msg = estimate_analysis_cost(
        llm_provider, llm_model, analysts, research_depth, 
        analysis_id, async_tracker
    )
    if not success:
        _update_step_error(exec_msg)
    _update_step_success(f"âœ… æˆæœ¬ä¼°ç®—å®Œæˆï¼ŒğŸ’° é¢„ä¼°åˆ†ææˆæœ¬: Â¥{estimated_cost:.4f}")
    
    # ========== Step 3: æ•°æ®é¢„è·å–å’ŒéªŒè¯ ==========
    step_name = "data_preparation"
    _update_step_start("ğŸ” éªŒè¯è‚¡ç¥¨ä»£ç å¹¶é¢„è·å–æ•°æ®...")
    success, exec_msg, preparation_result = prepare_stock_data_for_analysis(
        stock_symbol, market_type, analysis_date, analysis_id, async_tracker
    )
    
    if not success:
        _update_step_error(exec_msg)
        return False, None, exec_msg
    _update_step_success(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ: {preparation_result.stock_name} ({preparation_result.market_type})")
    
    # ========== Step 4: ç¯å¢ƒéªŒè¯ ==========
    step_name = "environment_validation"
    _update_step_start("ğŸ”§ å¼€å§‹ç¯å¢ƒéªŒè¯...")
    env_valid, env_error = validate_environment(analysis_id, async_tracker)
    if not env_valid:
        _update_step_error(f"âš ï¸ ç¯å¢ƒéªŒè¯å¤±è´¥ï¼š{env_error}")
        return False, None, env_error
    _update_step_success("âœ… ç¯å¢ƒéªŒè¯å®Œæˆ")
    
    # ========== Step 5: æ„å»ºé…ç½® ==========
    step_name = "config_builder"
    _update_step_start("âš™ï¸ å¼€å§‹æ„å»ºé…ç½®...")
    try:
        config_builder = AnalysisConfigBuilder()
        config = config_builder.build_config(
            llm_provider=llm_provider,
            llm_model=llm_model,
            research_depth=research_depth,
            market_type=market_type
        )
        _update_step_success("âœ… é…ç½®æ„å»ºå®Œæˆ")
    except Exception as e:
        _update_step_error(f"âš ï¸ é…ç½®æ„å»ºå¤±è´¥ï¼š{str(e)}")
        raise
    
    logger.info(f"ä½¿ç”¨é…ç½®: {config}")
    logger.info(f"åˆ†æå¸ˆåˆ—è¡¨: {analysts}")
    logger.info(f"è‚¡ç¥¨ä»£ç : {stock_symbol}")
    logger.info(f"åˆ†ææ—¥æœŸ: {analysis_date}")
    
    # ========== Step 6: æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç  ==========
    step_name = "symbol_formatting"
    _update_step_start("ğŸ“ å¼€å§‹æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç ...")
    formatted_symbol = format_stock_symbol(stock_symbol, market_type)
    
    market_icons = {"Aè‚¡": "ğŸ‡¨ğŸ‡³", "æ¸¯è‚¡": "ğŸ‡­ğŸ‡°", "ç¾è‚¡": "ğŸ‡ºğŸ‡¸"}
    market_icon = market_icons.get(market_type, "ğŸ“Š")
    _update_step_success(f"âœ… {market_icon} è‚¡ç¥¨ä»£ç æ ¼å¼åŒ–å®Œæˆ: {formatted_symbol}")
    
    # ========== Step 7: åˆå§‹åŒ–åˆ†æå¼•æ“ ==========
    step_name = "graph_initialization"
    _update_step_start("ğŸ—ï¸ å¼€å§‹åˆå§‹åŒ–åˆ†æå¼•æ“...")
    
    if not check_task_control(analysis_id, async_tracker):
        error_msg = 'âš ï¸ ä»»åŠ¡å·²è¢«åœæ­¢'
        _update_step_error(error_msg)
        return False, None, error_msg
    
    try:
        from tradingagents.graph.trading_graph import TradingAgentsGraph
        graph = TradingAgentsGraph(analysts, config=config, debug=False)
        _update_step_success("âœ… åˆ†æå¼•æ“åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        _update_step_error(f"âš ï¸ åˆ†æå¼•æ“åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
        raise

    # ========== Step 8: æ­¥éª¤è¾“å‡ºç›®å½•å‡†å¤‡ ==========
    step_name = "step_output_directory"
    _update_step_start("ğŸ“ å‡†å¤‡æ­¥éª¤è¾“å‡ºç›®å½•...")
    step_output_base_dir = prepare_step_output_directory(
        formatted_symbol=formatted_symbol,
        analysis_date=analysis_date,
        analysis_id=analysis_id,
        async_tracker=async_tracker,
        analysis_start_time=analysis_start_time
    )
    _update_step_success(f"âœ… æ­¥éª¤è¾“å‡ºç›®å½•å·²å‡†å¤‡: {step_output_base_dir}") 

    # è¿”å›å‡†å¤‡ç»“æœ
    preparation_result_dict = {
        'config': config,
        'formatted_symbol': formatted_symbol,
        'graph': graph,
        'session_id': analysis_id,
        'analysis_start_time': analysis_start_time,
        'preparation_result': preparation_result
    }
    
    return True, preparation_result_dict, None


def save_analysis_results(
    analysis_id: str,
    results: Dict[str, Any]
) -> tuple[bool, Dict[str, str]]:
    """
    åå¤„ç†æ­¥éª¤3: ä¿å­˜åˆ†æç»“æœ
    
    å¤„ç†æ­¥éª¤åŒ…æ‹¬ï¼š
    - æ ¼å¼åŒ–åˆ†æç»“æœ
    - ä¿å­˜åˆ†æ¨¡å—æŠ¥å‘Šåˆ°æœ¬åœ°ç›®å½•
    - ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°MongoDB
    
    Args:
        results: åˆ†æç»“æœå­—å…¸
        analysis_id: åˆ†æIDï¼ˆå¿…é€‰ï¼‰
        
    Returns:
        (æ˜¯å¦æˆåŠŸ, ä¿å­˜çš„æ–‡ä»¶è·¯å¾„å­—å…¸)
        æ–‡ä»¶è·¯å¾„å­—å…¸åŒ…å«å„æ¨¡å—æŠ¥å‘Šçš„æœ¬åœ°ä¿å­˜è·¯å¾„
    """
    from tradingagents.tasks import get_task_manager

    task_manager = get_task_manager()

    # ä»å†…éƒ¨è·å– stock_symbolï¼šä¼˜å…ˆä» task_manager è·å–ï¼Œå…¶æ¬¡ä» results è·å–
    stock_symbol = None
    if analysis_id and task_manager:
        task_status = task_manager.get_task_status(analysis_id)
        if task_status:
            params = task_status.get('params', {})
            stock_symbol = params.get('stock_symbol')
    
    # å¦‚æœä»æœªè·å–åˆ°ï¼Œä» results ä¸­è·å–
    if stock_symbol is None:
        stock_symbol = results.get('stock_symbol', 'UNKNOWN')
    
    saved_files = {}
    
    try:
        from .report_exporter import save_analysis_report, save_modular_reports_to_results_dir
        from tradingagents.utils.analysis_runner import format_analysis_results
        
        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = format_analysis_results(results)
        
        # 1. ä¿å­˜åˆ†æ¨¡å—æŠ¥å‘Šåˆ°æœ¬åœ°ç›®å½•
        logger.info(f"ğŸ“ [æœ¬åœ°ä¿å­˜] å¼€å§‹ä¿å­˜åˆ†æ¨¡å—æŠ¥å‘Šåˆ°æœ¬åœ°ç›®å½•")
        local_files = save_modular_reports_to_results_dir(
            formatted_results, stock_symbol, analysis_id=analysis_id
        )
        
        if local_files:
            logger.info(f"âœ… [æœ¬åœ°ä¿å­˜] å·²ä¿å­˜ {len(local_files)} ä¸ªæœ¬åœ°æŠ¥å‘Šæ–‡ä»¶")
            saved_files.update(local_files)
            for module, path in local_files.items():
                logger.info(f"  - {module}: {path}")
        else:
            logger.warning(f"âš ï¸ [æœ¬åœ°ä¿å­˜] æœ¬åœ°æŠ¥å‘Šæ–‡ä»¶ä¿å­˜å¤±è´¥")
        
        # 2. ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°MongoDB
        logger.info(f"ğŸ—„ï¸ [MongoDBä¿å­˜] å¼€å§‹ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°MongoDB")
        save_success = save_analysis_report(
            stock_symbol=stock_symbol,
            analysis_results=formatted_results,
            analysis_id=analysis_id
        )
        
        if save_success:
            logger.info(f"âœ… [MongoDBä¿å­˜] åˆ†ææŠ¥å‘Šå·²æˆåŠŸä¿å­˜åˆ°MongoDB")
        else:
            logger.warning(f"âš ï¸ [MongoDBä¿å­˜] MongoDBæŠ¥å‘Šä¿å­˜å¤±è´¥")

        return save_success or bool(local_files), saved_files
        
    except Exception as save_error:
        logger.error(f"âŒ [æŠ¥å‘Šä¿å­˜] ä¿å­˜åˆ†ææŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {str(save_error)}")
        return False, saved_files


# ========== å°è£…çš„æ­¥éª¤å‡½æ•° ==========

def log_analysis_start(analysis_id: str) -> tuple[Any, float]:
    """
    æ­¥éª¤1: è®°å½•åˆ†æå¼€å§‹æ—¥å¿—
    
    Args:
        analysis_id: åˆ†æIDï¼ˆå¿…é€‰ï¼‰
        
    Returns:
        (logger_manager, analysis_start_time)
    """
    from tradingagents.utils.logging_manager import get_logger_manager
    from tradingagents.tasks import get_task_manager
    import time
    
    logger_manager = get_logger_manager()
    analysis_start_time = time.time()
    
    # å°† analysis_start_time ä¿å­˜åˆ°ä»»åŠ¡çŠ¶æ€ä¸­
    task_manager = get_task_manager()
    if task_manager:
        try:
            state_machine = task_manager._get_task_state_machine(analysis_id)
            state_machine.update_state({'progress': {'analysis_start_time': analysis_start_time}})
        except Exception as e:
            logger.warning(f"âš ï¸ [åˆ†æå¯åŠ¨] ä¿å­˜analysis_start_timeåˆ°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
    
    return logger_manager, analysis_start_time


def prepare_step_output_directory(
    formatted_symbol: str,
    analysis_date: str,
    analysis_id: Optional[str] = None,
    async_tracker: Optional[Any] = None,
    analysis_start_time: Optional[float] = None
) -> Path:
    """
    æ­¥éª¤8: æ­¥éª¤è¾“å‡ºç›®å½•å‡†å¤‡
    
    Args:
        formatted_symbol: æ ¼å¼åŒ–åçš„è‚¡ç¥¨ä»£ç 
        analysis_date: åˆ†ææ—¥æœŸ
        analysis_id: åˆ†æID
        async_tracker: å¼‚æ­¥è¿›åº¦è·Ÿè¸ªå™¨
        analysis_start_time: åˆ†æå¼€å§‹æ—¶é—´
        
    Returns:
        æ­¥éª¤è¾“å‡ºç›®å½•è·¯å¾„
    """
    from pathlib import Path
    
    step_output_base_dir = Path("eval_results") / formatted_symbol / "TradingAgentsStrategy_logs" / "step_outputs" / analysis_date
    step_output_base_dir.mkdir(parents=True, exist_ok=True)

    return step_output_base_dir


def execute_analysis(
    graph: Any,
    formatted_symbol: str,
    analysis_date: str,
    analysis_id: Optional[str],
    session_id: str,
    update_progress: Optional[Callable] = None,
    async_tracker: Optional[Any] = None,
    analysis_start_time: Optional[float] = None,
    check_task_control: Optional[Callable] = None
) -> tuple[Any, Any]:
    """
    æ­¥éª¤9: æ‰§è¡Œåˆ†æ
    
    Args:
        graph: TradingAgentsGraphå®ä¾‹
        formatted_symbol: æ ¼å¼åŒ–åçš„è‚¡ç¥¨ä»£ç 
        analysis_date: åˆ†ææ—¥æœŸ
        analysis_id: åˆ†æID
        session_id: ä¼šè¯ID
        update_progress: è¿›åº¦å›è°ƒå‡½æ•°
        async_tracker: å¼‚æ­¥è¿›åº¦è·Ÿè¸ªå™¨
        analysis_start_time: åˆ†æå¼€å§‹æ—¶é—´
        check_task_control: ä»»åŠ¡æ§åˆ¶æ£€æŸ¥å‡½æ•°
        
    Returns:
        (state, decision)
    """
    from .message_utils import publish_progress_message, get_step_info, get_message_producer
    
    if update_progress:
        update_progress(f"ğŸ“Š å¼€å§‹åˆ†æ {formatted_symbol} è‚¡ç¥¨ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´...")
    
    # å‘å¸ƒæ­¥éª¤9å¼€å§‹æ¶ˆæ¯
    message_producer = get_message_producer()
    current_step, total_steps = get_step_info(async_tracker, 8, 12)
    
    publish_progress_message(
        analysis_id=analysis_id,
        current_step=current_step,
        total_steps=total_steps,
        step_name="ğŸ“Š æ‰§è¡Œåˆ†æ",
        step_description="å¼€å§‹å¤šæ™ºèƒ½ä½“åˆ†ææ‰§è¡Œ",
        last_message=f"ğŸ“Š å¼€å§‹åˆ†æ {formatted_symbol} è‚¡ç¥¨",
        module_name="analysis_execution",
        node_status=NodeStatus.START.value,
        async_tracker=async_tracker,
        analysis_start_time=analysis_start_time,
        message_producer=message_producer
    )
    
    # æ£€æŸ¥ä»»åŠ¡æ§åˆ¶
    if check_task_control and not check_task_control():
        raise Exception('ä»»åŠ¡å·²è¢«åœæ­¢')
    
    logger.debug(f"ğŸ” [RUNNER DEBUG] ===== è°ƒç”¨graph.propagate =====")
    logger.debug(f"ğŸ” [RUNNER DEBUG] ä¼ é€’ç»™graph.propagateçš„å‚æ•°:")
    logger.debug(f"ğŸ” [RUNNER DEBUG]   symbol: '{formatted_symbol}'")
    logger.debug(f"ğŸ” [RUNNER DEBUG]   date: '{analysis_date}'")
    logger.debug(f"ğŸ” [RUNNER DEBUG]   analysis_id: '{analysis_id}'")
    logger.debug(f"ğŸ” [RUNNER DEBUG]   session_id: '{session_id}'")
    
    state, decision = graph.propagate(formatted_symbol, analysis_date, analysis_id=analysis_id, session_id=session_id)
    
    # å†æ¬¡æ£€æŸ¥ä»»åŠ¡æ§åˆ¶
    if check_task_control and not check_task_control():
        logger.warning(f"âš ï¸ [ä»»åŠ¡æ§åˆ¶] åˆ†æå®Œæˆåæ£€æµ‹åˆ°åœæ­¢ä¿¡å·")
        raise Exception('ä»»åŠ¡å·²è¢«åœæ­¢ï¼ˆåˆ†æå·²å®Œæˆï¼‰')
    
    return state, decision


def process_analysis_results(
    analysis_id: str,
    state: Any,
    decision: Any
) -> Dict[str, Any]:
    """
    åå¤„ç†æ­¥éª¤1: å¤„ç†åˆ†æç»“æœ
    
    å¤„ç†æ­¥éª¤åŒ…æ‹¬ï¼š
    - æå–é£é™©è¯„ä¼°æ•°æ®
    - è®°å½•Tokenä½¿ç”¨æƒ…å†µ
    - æ„å»ºå®Œæ•´çš„ç»“æœå­—å…¸
    
    Args:
        analysis_id: åˆ†æIDï¼ˆå¿…é€‰ï¼‰
        state: åˆ†æçŠ¶æ€
        decision: åˆ†æå†³ç­–
        
    Returns:
        å¤„ç†åçš„å®Œæ•´ç»“æœå­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦çš„å±æ€§
    """
    # è·å–å¹¶éªŒè¯ task_managerã€task_statusã€paramsã€extra_configï¼Œå¦‚æœæ— æ•ˆåˆ™æŠ›å‡ºå¼‚å¸¸
    task_manager = get_task_manager()
    
    task_status = task_manager.get_task_status(analysis_id)
    params = task_status.get('params') if task_status else None
    extra_config = params.get('extra_config') if params else None
    
    if not task_status or not params or not extra_config:
        raise ValueError(f"Task status data is abnormal for analysis_id: {analysis_id}")

    # å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
    def extract_risk_assessment(state):
        """ä»åˆ†æçŠ¶æ€ä¸­æå–é£é™©è¯„ä¼°æ•°æ®ï¼ˆå»¶è¿Ÿå¯¼å…¥ç‰ˆæœ¬ï¼‰"""
        try:
            from tradingagents.utils.analysis_runner import extract_risk_assessment as _extract
            return _extract(state)
        except ImportError:
            # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œè¿”å›None
            return None
    
    # æå–é£é™©è¯„ä¼°æ•°æ®
    risk_assessment = extract_risk_assessment(state)
    if risk_assessment:
        state['risk_assessment'] = risk_assessment
    
    # æ£€æŸ¥ Token è·Ÿè¸ªæ˜¯å¦å¯ç”¨
    token_tracking_enabled = False
    try:
        from tradingagents.config.config_manager import token_tracker
        token_tracking_enabled = True
    except ImportError:
        pass
    
    # ç›´æ¥å¯¹ results è¿›è¡Œèµ‹å€¼ï¼Œä» params å’Œ extra_config ä¸­è·å–æ‰€æœ‰éœ€è¦çš„å€¼
    results = {}
    results['stock_symbol'] = params.get('stock_symbol', 'UNKNOWN')
    results['analysis_date'] = params.get('analysis_date') or params.get('date', '')
    results['analysts'] = params.get('analysts', [])
    results['research_depth'] = params.get('research_depth', 2)
    results['llm_provider'] = extra_config.get('llm_provider', 'dashscope')
    results['llm_model'] = extra_config.get('llm_model', 'qwen-max')
    results['state'] = state
    results['decision'] = decision
    results['success'] = True
    results['error'] = None
    results['session_id'] = params.get('session_id') or analysis_id
    
    # è®°å½•Tokenä½¿ç”¨
    track_token_usage(results, params)
    
    return results


def log_analysis_completion(
    analysis_id: str
) -> float:
    """
    åå¤„ç†æ­¥éª¤2: è®°å½•å®Œæˆæ—¥å¿—
    
    å¤„ç†æ­¥éª¤åŒ…æ‹¬ï¼š
    - è®¡ç®—åˆ†ææŒç»­æ—¶é—´
    - è·å–Tokenä½¿ç”¨æ€»æˆæœ¬
    - è®°å½•åˆ†æå®Œæˆæ—¥å¿—
    - ä¿å­˜åˆ†æå®Œæˆä¿¡æ¯åˆ°æ•°æ®åº“
    
    Args:
        analysis_id: åˆ†æIDï¼ˆå¿…é€‰ï¼‰
        
    Returns:
        æ€»æˆæœ¬ï¼ˆå…ƒï¼‰ï¼Œå¦‚æœæ— æ³•è·Ÿè¸ªåˆ™è¿”å›0.0
    """
    import time
    
    logger_manager = get_logger_manager()
    task_manager = get_task_manager()
    
    task_status = task_manager.get_task_status(analysis_id)
    params = task_status.get('params', {})
    progress = task_status.get('progress', {})
    # è‚¡ç¥¨ä»£ç 
    stock_symbol = params.get('stock_symbol')
    # ä¼šè¯ID
    session_id = params.get('session_id') or analysis_id
    # åˆ†æå¼€å§‹æ—¶é—´
    analysis_start_time = progress.get('analysis_start_time')
        
    analysis_duration = time.time() - analysis_start_time
    
    total_cost = 0.0
    try:
        from tradingagents.config.config_manager import token_tracker
        total_cost = token_tracker.get_session_cost(session_id)
    except:
        pass
    
    logger_manager.log_analysis_complete(
        logger, stock_symbol, "comprehensive_analysis", session_id,
        analysis_duration, total_cost
    )
    
    return total_cost


def post_process_analysis_steps(
    analysis_id: str,
    state: Dict[str, Any],
    decision: Any
) -> Dict[str, Any]:
    """
    åå¤„ç†æ­¥éª¤ï¼šæ‰§è¡Œæ‰€æœ‰åˆ†æåçš„å¤„ç†å·¥ä½œ
    
    åå¤„ç†æ­¥éª¤åŒ…æ‹¬ï¼š
    - åå¤„ç†æ­¥éª¤1: ğŸ“Š å¤„ç†åˆ†æç»“æœ (process_analysis_results)
    - åå¤„ç†æ­¥éª¤2: âœ… è®°å½•å®Œæˆæ—¥å¿— (log_analysis_completion)
    - åå¤„ç†æ­¥éª¤3: ğŸ’¾ ä¿å­˜åˆ†æç»“æœ (save_analysis_results)
    
    Args:
        analysis_id: åˆ†æID
        state: åˆ†æçŠ¶æ€
        decision: åˆ†æå†³ç­–

    Returns:
        æœ€ç»ˆçš„åˆ†æç»“æœå­—å…¸
    """
    # è·å– task_manager
    task_manager = get_task_manager()
    
    # éªŒè¯ task_manager å’Œ analysis_idï¼ˆæå‰éªŒè¯ï¼Œæ— æ•ˆåˆ™æŠ›å‡ºå¼‚å¸¸ï¼‰
    if not task_manager or not analysis_id:
        raise ValueError(f"Task manager or analysis_id is not available: analysis_id={analysis_id}")
    
    # åˆå§‹åŒ– step_name å˜é‡
    step_name = ""
    
    def _update_step_start(message: str):
        task_manager.update_task_progress(analysis_id, step_name, message, 'start')

    def _update_step_success(message: str):
        task_manager.update_task_progress(analysis_id, step_name, message, 'success')
    
    def _update_step_error(message: str):
        task_manager.update_task_progress(analysis_id, step_name, message, 'error')

    # ========== åå¤„ç†æ­¥éª¤1: å¤„ç†åˆ†æç»“æœ ==========
    step_name = "result_processing"
    _update_step_start("ğŸ“Š å¼€å§‹å¤„ç†åˆ†æç»“æœ...")
    try:
        results = process_analysis_results(analysis_id, state, decision)
        _update_step_success("âœ… åˆ†æç»“æœå¤„ç†å®Œæˆ")
    except Exception as e:
        error_msg = f"âš ï¸ åˆ†æç»“æœå¤„ç†å¤±è´¥ï¼š{str(e)}"
        _update_step_error(error_msg)
        raise

    # ========== åå¤„ç†æ­¥éª¤2: è®°å½•å®Œæˆæ—¥å¿— ==========
    step_name = "completion_logging"
    _update_step_start("âœ… å¼€å§‹è®°å½•åˆ†æç»“æŸæ—¥å¿—ï¼Œå¹¶è®¡ç®—æœ¬æ¬¡åˆ†æä»»åŠ¡æ€»æˆæœ¬...")
    try:
        log_analysis_completion(analysis_id=analysis_id)
        _update_step_success("âœ… å®Œæˆåˆ†æä»»åŠ¡ç»“æŸæ—¥å¿—è®°å½•å’Œæ€»æˆæœ¬è®¡ç®—ï¼Œå¹¶ä¿å­˜åˆ°æ•°æ®åº“")
    except Exception as e:
        error_msg = f"âš ï¸ å®Œæˆæ—¥å¿—è®°å½•å¤±è´¥ï¼š{str(e)}"
        _update_step_error(error_msg)
        raise

    # ========== åå¤„ç†æ­¥éª¤3: ä¿å­˜åˆ†æç»“æœ ==========
    step_name = "save_results"
    _update_step_start("ğŸ’¾ å¼€å§‹ä¿å­˜åˆ†æç»“æœ...")
    try:
        save_analysis_results(analysis_id, results)
        _update_step_success("âœ… åˆ†æç»“æœä¿å­˜å®Œæˆ")
    except Exception as e:
        error_msg = f"âš ï¸ åˆ†æç»“æœä¿å­˜å¤±è´¥ï¼š{str(e)}"
        _update_step_error(error_msg)
        raise

    return results
