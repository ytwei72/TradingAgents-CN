"""
ç¼“å­˜ç»“æœå¤ç”¨è¾…åŠ©å·¥å…·
æä¾›åŸºäºæ•°æ®åº“ç¼“å­˜çš„ç»“æœå¤ç”¨åŠŸèƒ½ï¼Œå½“åˆ†æä»»åŠ¡å‚æ•°ç›¸åŒæ—¶è‡ªåŠ¨ä»ç¼“å­˜ä¸­è¯»å–ç»“æœ
"""

import os
import time
import random
from typing import Dict, Any, Optional

from tradingagents.utils.logging_manager import get_logger
logger = get_logger('tools')  # ä½¿ç”¨toolsæ—¥å¿—å™¨ï¼Œä¸æ­£å¸¸èŠ‚ç‚¹æ‰§è¡Œä¿æŒä¸€è‡´ï¼Œä¾¿äºProgressLogHandlerç»Ÿä¸€æ•è·

from tradingagents.messaging.config import get_message_producer, is_message_mode_enabled
from tradingagents.messaging.decorators.message_decorators import _publish_step_message
from tradingagents.messaging.business.messages import NodeStatus

# å…¨å±€å˜é‡å­˜å‚¨graphå®ä¾‹ï¼ˆç”¨äºè®¿é—®ç»“æœå¤ç”¨åŠŸèƒ½ï¼‰
_graph_instance = None


def set_graph_instance(graph_instance):
    """è®¾ç½®graphå®ä¾‹ï¼Œä»¥ä¾¿èŠ‚ç‚¹å¯ä»¥è®¿é—®ç»“æœå¤ç”¨åŠŸèƒ½"""
    global _graph_instance
    _graph_instance = graph_instance


def check_and_load_cached_result(node_name: str, state: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """æ£€æŸ¥å¹¶åŠ è½½ç¼“å­˜çš„èŠ‚ç‚¹ç»“æœï¼ˆåŸºäºå‚æ•°åŒ¹é…çš„ç»“æœå¤ç”¨ï¼‰

    å½“åˆ†æä»»åŠ¡çš„å‚æ•°ï¼ˆè‚¡ç¥¨ä»£ç ã€åˆ†ææ—¥æœŸã€ç ”ç©¶æ·±åº¦ã€åˆ†æå¸ˆå›¢é˜Ÿï¼‰éƒ½ç›¸åŒæ—¶ï¼Œ
    ä»æ•°æ®åº“ç¼“å­˜ä¸­è¯»å–å†å²ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—ã€‚
    """
    global _graph_instance

    if not _graph_instance:
        return None

    # è·å–è‚¡ç¥¨ä»£ç å’Œäº¤æ˜“æ—¥æœŸ
    ticker = state.get('company_of_interest', '')
    trade_date = state.get('trade_date', '')

    if not ticker or not trade_date:
        logger.debug("ğŸ” [ç¼“å­˜æŸ¥è¯¢] æ— æ³•è·å–è‚¡ç¥¨ä»£ç æˆ–æ—¥æœŸï¼Œè·³è¿‡ç¼“å­˜æŸ¥è¯¢")
        return None

    # ä»graphå®ä¾‹ä¸­è·å–åˆ†æå‚æ•°ï¼ˆç”¨äºåŒ¹é…ç¼“å­˜ï¼‰
    research_depth = getattr(_graph_instance, 'research_depth', None)
    analysts = getattr(_graph_instance, 'selected_analysts', None)
    market_type = getattr(_graph_instance, 'market_type', None)

    cache_reuse_config: Optional[Dict[str, bool]] = None
    cache_reuse_sleep_min: Optional[float] = None
    cache_reuse_sleep_max: Optional[float] = None

    # æå–åˆ†æIDï¼ˆç”¨äºä»ä»»åŠ¡çŠ¶æ€è¯»å–é…ç½®åŠæ¶ˆæ¯æœºåˆ¶ï¼‰
    analysis_id = state.get('analysis_id') or state.get('session_id')

    # 1. ä¼˜å…ˆä»ä»»åŠ¡çŠ¶æ€ä¸­è¯»å–ç»“æœå¤ç”¨é…ç½®
    if analysis_id:
        try:
            from tradingagents.tasks import get_task_manager
            task_manager = get_task_manager()
            if task_manager:
                task_status = task_manager.get_task_status(analysis_id)
                if task_status:
                    cfg = task_status.get('cache_reuse_config') or {}
                    mode = cfg.get('cache_reuse_mode')
                    sleep_min = cfg.get('cache_reuse_sleep_min')
                    sleep_max = cfg.get('cache_reuse_sleep_max')
                    if mode is not None:
                        cache_reuse_config, cache_reuse_sleep_min, cache_reuse_sleep_max = _load_cache_reuse_from_values(
                            mode, sleep_min, sleep_max
                        )
                        logger.debug(f"âœ… [ç»“æœå¤ç”¨é…ç½®] ä»ä»»åŠ¡çŠ¶æ€è¯»å–: {cache_reuse_config}")
        except Exception as e:
            logger.debug(f"âš ï¸ [ç»“æœå¤ç”¨é…ç½®] ä»ä»»åŠ¡çŠ¶æ€è¯»å–å¤±è´¥ï¼Œå°†å›é€€åˆ°ç¯å¢ƒå˜é‡: {e}")

    # 2. å¦‚æœä»»åŠ¡ä¸­æ²¡æœ‰é…ç½®ï¼Œåˆ™ä»ç¯å¢ƒå˜é‡åŠ è½½ï¼ˆå…¨å±€é»˜è®¤ï¼‰
    if cache_reuse_config is None:
        cache_reuse_config, cache_reuse_sleep_min, cache_reuse_sleep_max = _load_cache_reuse_from_env()

    # å¦‚æœæ¶ˆæ¯æ¨¡å¼å¯ç”¨ï¼Œå‘é€æ¨¡å—å¼€å§‹æ¶ˆæ¯
    if is_message_mode_enabled():
        producer = get_message_producer()
        if producer and analysis_id:
            _publish_step_message(
                producer=producer,
                analysis_id=str(analysis_id),
                module_name=node_name,
                node_status=NodeStatus.START.value
            )

    # è®°å½•æ¨¡å—å¼€å§‹ï¼ˆç”¨äºè¿›åº¦è¿½è¸ªï¼‰
    logger.info(f"ğŸ“Š [æ¨¡å—å¼€å§‹] {node_name} - è‚¡ç¥¨: {ticker}")
    logger.info(f"ğŸ” [ç¼“å­˜æŸ¥è¯¢] æŸ¥è¯¢ç¼“å­˜ç»“æœ - è‚¡ç¥¨: {ticker}, æ—¥æœŸ: {trade_date}, ç ”ç©¶æ·±åº¦: {research_depth}, åˆ†æå¸ˆ: {analysts}")

    # å°è¯•ä»æ•°æ®åº“ç¼“å­˜ä¸­åŠ è½½å†å²è¾“å‡º
    cached_state = _load_cached_step_output(
        node_name=node_name,
        ticker=ticker,
        trade_date=trade_date,
        research_depth=research_depth,
        analysts=analysts,
        market_type=market_type,
        current_state=state,
        cache_reuse_config=cache_reuse_config
    )

    # è®°å½•å¼€å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—è€—æ—¶ï¼‰
    start_time = time.time()

    if cached_state:
        # åˆå¹¶ç¼“å­˜çŠ¶æ€åˆ°å½“å‰çŠ¶æ€ï¼ˆä¿ç•™å½“å‰çŠ¶æ€çš„åŸºç¡€ä¿¡æ¯ï¼‰
        merged_state = state.copy()
        # ä¿å­˜analysis_idå’Œsession_idï¼Œé¿å…è¢«ç¼“å­˜æ•°æ®è¦†ç›–
        preserved_analysis_id = state.get('analysis_id')
        preserved_session_id = state.get('session_id')
        merged_state.update(cached_state)
        # æ¢å¤analysis_idå’Œsession_id
        if preserved_analysis_id is not None:
            merged_state['analysis_id'] = preserved_analysis_id
        if preserved_session_id is not None:
            merged_state['session_id'] = preserved_session_id

        # å¯¹äºç ”ç©¶å‘˜èŠ‚ç‚¹ï¼Œæ›´æ–°è®¡æ•°
        if node_name in ['bull_researcher', 'bear_researcher']:
            if 'investment_debate_state' in merged_state and isinstance(merged_state['investment_debate_state'], dict):
                current_count = merged_state['investment_debate_state'].get('count', 0)
                merged_state['investment_debate_state']['count'] = current_count + 1

        # å¯¹äºé£é™©åˆ†æå¸ˆèŠ‚ç‚¹ï¼Œæ›´æ–°è®¡æ•°
        if node_name in ['risky_analyst', 'safe_analyst', 'neutral_analyst']:
            if 'risk_debate_state' in merged_state and isinstance(merged_state['risk_debate_state'], dict):
                current_count = merged_state['risk_debate_state'].get('count', 0)
                merged_state['risk_debate_state']['count'] = current_count + 1

        # æ¨¡æ‹ŸçŸ­æš‚å»¶è¿Ÿï¼Œæ¨¡æ‹ŸçœŸå®æ‰§è¡Œ
        sleep_min = cache_reuse_sleep_min if cache_reuse_sleep_min is not None else 2.0
        sleep_max = cache_reuse_sleep_max if cache_reuse_sleep_max is not None else 10.0
        sleep_time = random.uniform(sleep_min, sleep_max)
        logger.info(f"âœ… [ç¼“å­˜å‘½ä¸­] èŠ‚ç‚¹ {node_name} ä½¿ç”¨ç¼“å­˜ç»“æœï¼Œæ¨¡æ‹Ÿå»¶è¿Ÿ {sleep_time:.2f} ç§’")

        time.sleep(sleep_time)
        duration = time.time() - start_time

        # å¦‚æœæ¶ˆæ¯æ¨¡å¼å¯ç”¨ï¼Œå‘é€æ¨¡å—å®Œæˆæ¶ˆæ¯
        if is_message_mode_enabled():
            producer = get_message_producer()
            if producer and analysis_id:
                _publish_step_message(
                    producer=producer,
                    analysis_id=str(analysis_id),
                    module_name=node_name,
                    node_status=NodeStatus.COMPLETE.value,
                    duration=duration
                )

        # è®°å½•æ¨¡å—å®Œæˆï¼ˆç”¨äºè¿›åº¦è¿½è¸ªï¼‰
        logger.info(f"ğŸ“Š [æ¨¡å—å®Œæˆ] {node_name} - ç¼“å­˜å¤ç”¨å®Œæˆ - è‚¡ç¥¨: {ticker}, è€—æ—¶: {duration:.2f}s")

        return merged_state
    else:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç¼“å­˜æ•°æ®ï¼Œç»§ç»­æ­£å¸¸æ‰§è¡Œ
        duration = time.time() - start_time
        logger.debug(f"ğŸ” [ç¼“å­˜æœªå‘½ä¸­] èŠ‚ç‚¹ {node_name} æœªæ‰¾åˆ°åŒ¹é…çš„ç¼“å­˜ç»“æœï¼Œä½¿ç”¨æ­£å¸¸æ‰§è¡Œæ¨¡å¼")
        return None


def _load_cached_step_output(
    node_name: str,
    ticker: str,
    trade_date: str,
    research_depth: Optional[int],
    analysts: Optional[list],
    market_type: Optional[str],
    current_state: Optional[Dict[str, Any]] = None,
    cache_reuse_config: Optional[Dict[str, bool]] = None
) -> Optional[Dict[str, Any]]:
    """ä»æ•°æ®åº“ç¼“å­˜ä¸­åŠ è½½æŒ‡å®šèŠ‚ç‚¹çš„å†å²è¾“å‡º"""
    global _graph_instance

    if not _graph_instance:
        return None

    # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨ç»“æœå¤ç”¨ï¼ˆåŸºäºé…ç½®ï¼‰
    should_use_cache_reuse = False
    if cache_reuse_config:
        if cache_reuse_config.get('all', False):
            should_use_cache_reuse = True
        else:
            should_use_cache_reuse = cache_reuse_config.get(node_name, False)

    if not should_use_cache_reuse:
        logger.debug(f"ğŸ” [ç»“æœå¤ç”¨] èŠ‚ç‚¹ {node_name} æœªå¯ç”¨ç»“æœå¤ç”¨ï¼Œè·³è¿‡ç¼“å­˜æŸ¥è¯¢")
        return None

    # ä¼˜å…ˆä»MongoDBè¯»å–ç¼“å­˜
    if _graph_instance.steps_status_manager.is_connected():
        try:
            doc = _graph_instance.steps_status_manager.find_cached_step_status(
                ticker=ticker,
                trade_date=trade_date,
                node_name=node_name,
            )

            if doc:
                if _graph_instance._match_node_output(node_name, doc):
                    logger.info(f"âœ… [ç¼“å­˜å‘½ä¸­] ä»MongoDBæ‰¾åˆ°åŒ¹é…çš„ç¼“å­˜ç»“æœ: {node_name} (è‚¡ç¥¨: {ticker}, æ—¥æœŸ: {trade_date})")
                    return _graph_instance._convert_historical_to_state(doc, node_name, current_state)
                else:
                    logger.debug(f"ğŸ” [ç¼“å­˜æŸ¥è¯¢] MongoDBä¸­æ‰¾åˆ°è®°å½•ä½†èŠ‚ç‚¹ä¸åŒ¹é…: {node_name}")
            else:
                logger.debug(f"ğŸ” [ç¼“å­˜æŸ¥è¯¢] MongoDBä¸­æœªæ‰¾åˆ°åŒ¹é…çš„ç¼“å­˜è®°å½•: {ticker} - {trade_date}")
        except Exception as e:
            logger.warning(f"âš ï¸ [ç¼“å­˜æŸ¥è¯¢] ä»MongoDBè¯»å–å¤±è´¥: {e}")

    logger.debug(f"ğŸ” [ç¼“å­˜æŸ¥è¯¢] æœªæ‰¾åˆ°èŠ‚ç‚¹ {node_name} çš„ç¼“å­˜ç»“æœ")
    return None


def create_cache_reuse_wrapper(node_func, node_name: str):
    """åˆ›å»ºèŠ‚ç‚¹åŒ…è£…å™¨ï¼Œè‡ªåŠ¨æ·»åŠ ç¼“å­˜ç»“æœå¤ç”¨æ£€æŸ¥"""

    def wrapped_node(state: Dict[str, Any]) -> Dict[str, Any]:
        cached_result = check_and_load_cached_result(node_name, state)
        if cached_result is not None:
            return cached_result
        return node_func(state)

    return wrapped_node


def _load_cache_reuse_from_values(
    mode_value: Any,
    sleep_min_value: Any,
    sleep_max_value: Any,
) -> (Dict[str, bool], float, float):
    """ä»ç»™å®šçš„å€¼æ„å»ºç»“æœå¤ç”¨é…ç½®ï¼ˆä¾›ä»»åŠ¡å‚æ•°ä½¿ç”¨ï¼‰"""
    mode_str = str(mode_value).strip().lower() if mode_value is not None else "false"

    # è§£ææ¨¡å¼
    if mode_str in ("false", ""):
        config: Dict[str, bool] = {}
    elif mode_str == "true":
        config = {"all": True}
    else:
        node_list = [node.strip() for node in mode_str.split(",") if node.strip()]
        config = {}
        node_mapping = {
            "market": "market_analyst",
            "market_analyst": "market_analyst",
            "fundamentals": "fundamentals_analyst",
            "fundamentals_analyst": "fundamentals_analyst",
            "news": "news_analyst",
            "news_analyst": "news_analyst",
            "social": "social_media_analyst",
            "social_media_analyst": "social_media_analyst",
            "bull": "bull_researcher",
            "bull_researcher": "bull_researcher",
            "bear": "bear_researcher",
            "bear_researcher": "bear_researcher",
            "research_manager": "research_manager",
            "trader": "trader",
            "risky": "risky_analyst",
            "risky_analyst": "risky_analyst",
            "safe": "safe_analyst",
            "safe_analyst": "safe_analyst",
            "neutral": "neutral_analyst",
            "neutral_analyst": "neutral_analyst",
            "risk_manager": "risk_manager",
            "risk_judge": "risk_manager",
        }
        for node in node_list:
            normalized_node = node_mapping.get(node, node)
            config[normalized_node] = True

    # è§£æ sleep é…ç½®
    try:
        sleep_min = float(sleep_min_value) if sleep_min_value is not None else 2.0
    except Exception:
        sleep_min = 2.0
    try:
        sleep_max = float(sleep_max_value) if sleep_max_value is not None else 10.0
    except Exception:
        sleep_max = 10.0

    return config, sleep_min, sleep_max


def _load_cache_reuse_from_env() -> (Dict[str, bool], float, float):
    """ä»ç¯å¢ƒå˜é‡åŠ è½½ç»“æœå¤ç”¨é…ç½®ï¼ˆä½œä¸ºå…¨å±€é»˜è®¤ï¼‰"""
    mode_env = os.getenv("CACHE_REUSE_MODE", "false")
    sleep_min_env = os.getenv("CACHE_REUSE_SLEEP_MIN", "2")
    sleep_max_env = os.getenv("CACHE_REUSE_SLEEP_MAX", "10")

    return _load_cache_reuse_from_values(mode_env, sleep_min_env, sleep_max_env)


