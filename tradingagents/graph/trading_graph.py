# TradingAgents/graph/trading_graph.py

import os
from pathlib import Path
import json
from datetime import date, datetime
from typing import Dict, Any, Tuple, List, Optional
import time
import random

from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI
from tradingagents.llm_adapters import ChatDashScope, ChatDashScopeOpenAI, ChatGoogleOpenAI

from langgraph.prebuilt import ToolNode

from tradingagents.agents import *
from tradingagents.default_config import DEFAULT_CONFIG
from tradingagents.agents.utils.memory import FinancialSituationMemory

# å¯¼å…¥ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
from tradingagents.utils.logging_init import get_logger

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('agents')
from tradingagents.agents.utils.agent_states import (
    AgentState,
    InvestDebateState,
    RiskDebateState,
)
from tradingagents.dataflows.interface import set_config

from .conditional_logic import ConditionalLogic
from .setup import GraphSetup
from .propagation import Propagator
from .reflection import Reflector
from .signal_processing import SignalProcessor


class TradingAgentsGraph:
    """Main class that orchestrates the trading agents framework."""

    def __init__(
        self,
        selected_analysts=["market", "social", "news", "fundamentals"],
        debug=False,
        config: Dict[str, Any] = None,
    ):
        """Initialize the trading agents graph and components.

        Args:
            selected_analysts: List of analyst types to include
            debug: Whether to run in debug mode
            config: Configuration dictionary. If None, uses default config
        """
        self.debug = debug
        self.config = config or DEFAULT_CONFIG

        # Update the interface's config
        set_config(self.config)

        # Create necessary directories
        os.makedirs(
            os.path.join(self.config["project_dir"], "dataflows/data_cache"),
            exist_ok=True,
        )

        # Initialize LLMs
        if self.config["llm_provider"].lower() == "openai":
            self.deep_thinking_llm = ChatOpenAI(model=self.config["deep_think_llm"], base_url=self.config["backend_url"])
            self.quick_thinking_llm = ChatOpenAI(model=self.config["quick_think_llm"], base_url=self.config["backend_url"])
        elif self.config["llm_provider"] == "siliconflow":
            # SiliconFlowæ”¯æŒï¼šä½¿ç”¨OpenAIå…¼å®¹API
            siliconflow_api_key = os.getenv('SILICONFLOW_API_KEY')
            if not siliconflow_api_key:
                raise ValueError("ä½¿ç”¨SiliconFlowéœ€è¦è®¾ç½®SILICONFLOW_API_KEYç¯å¢ƒå˜é‡")

            logger.info(f"ğŸŒ [SiliconFlow] ä½¿ç”¨APIå¯†é’¥: {siliconflow_api_key[:20]}...")

            self.deep_thinking_llm = ChatOpenAI(
                model=self.config["deep_think_llm"],
                base_url=self.config["backend_url"],
                api_key=siliconflow_api_key,
                temperature=0.1,
                max_tokens=2000
            )
            self.quick_thinking_llm = ChatOpenAI(
                model=self.config["quick_think_llm"],
                base_url=self.config["backend_url"],
                api_key=siliconflow_api_key,
                temperature=0.1,
                max_tokens=2000
            )
        elif self.config["llm_provider"] == "openrouter":
            # OpenRouteræ”¯æŒï¼šä¼˜å…ˆä½¿ç”¨OPENROUTER_API_KEYï¼Œå¦åˆ™ä½¿ç”¨OPENAI_API_KEY
            openrouter_api_key = os.getenv('OPENROUTER_API_KEY') or os.getenv('OPENAI_API_KEY')
            if not openrouter_api_key:
                raise ValueError("ä½¿ç”¨OpenRouteréœ€è¦è®¾ç½®OPENROUTER_API_KEYæˆ–OPENAI_API_KEYç¯å¢ƒå˜é‡")

            logger.info(f"ğŸŒ [OpenRouter] ä½¿ç”¨APIå¯†é’¥: {openrouter_api_key[:20]}...")

            self.deep_thinking_llm = ChatOpenAI(
                model=self.config["deep_think_llm"],
                base_url=self.config["backend_url"],
                api_key=openrouter_api_key
            )
            self.quick_thinking_llm = ChatOpenAI(
                model=self.config["quick_think_llm"],
                base_url=self.config["backend_url"],
                api_key=openrouter_api_key
            )
        elif self.config["llm_provider"] == "ollama":
            self.deep_thinking_llm = ChatOpenAI(model=self.config["deep_think_llm"], base_url=self.config["backend_url"])
            self.quick_thinking_llm = ChatOpenAI(model=self.config["quick_think_llm"], base_url=self.config["backend_url"])
        elif self.config["llm_provider"].lower() == "anthropic":
            self.deep_thinking_llm = ChatAnthropic(model=self.config["deep_think_llm"], base_url=self.config["backend_url"])
            self.quick_thinking_llm = ChatAnthropic(model=self.config["quick_think_llm"], base_url=self.config["backend_url"])
        elif self.config["llm_provider"].lower() == "google":
            # ä½¿ç”¨ Google OpenAI å…¼å®¹é€‚é…å™¨ï¼Œè§£å†³å·¥å…·è°ƒç”¨æ ¼å¼ä¸åŒ¹é…é—®é¢˜
            logger.info(f"ğŸ”§ ä½¿ç”¨Google AI OpenAI å…¼å®¹é€‚é…å™¨ (è§£å†³å·¥å…·è°ƒç”¨é—®é¢˜)")
            google_api_key = os.getenv('GOOGLE_API_KEY')
            if not google_api_key:
                raise ValueError("ä½¿ç”¨Google AIéœ€è¦è®¾ç½®GOOGLE_API_KEYç¯å¢ƒå˜é‡")
            
            self.deep_thinking_llm = ChatGoogleOpenAI(
                model=self.config["deep_think_llm"],
                google_api_key=google_api_key,
                temperature=0.1,
                max_tokens=2000
            )
            self.quick_thinking_llm = ChatGoogleOpenAI(
                model=self.config["quick_think_llm"],
                google_api_key=google_api_key,
                temperature=0.1,
                max_tokens=2000,
                transport="rest"
            )
            
            logger.info(f"âœ… [Google AI] å·²å¯ç”¨ä¼˜åŒ–çš„å·¥å…·è°ƒç”¨å’Œå†…å®¹æ ¼å¼å¤„ç†")
        elif (self.config["llm_provider"].lower() == "dashscope" or
              self.config["llm_provider"].lower() == "alibaba" or
              "dashscope" in self.config["llm_provider"].lower() or
              "é˜¿é‡Œç™¾ç‚¼" in self.config["llm_provider"]):
            # ä½¿ç”¨ OpenAI å…¼å®¹é€‚é…å™¨ï¼Œæ”¯æŒåŸç”Ÿ Function Calling
            logger.info(f"ğŸ”§ ä½¿ç”¨é˜¿é‡Œç™¾ç‚¼ OpenAI å…¼å®¹é€‚é…å™¨ (æ”¯æŒåŸç”Ÿå·¥å…·è°ƒç”¨)")
            self.deep_thinking_llm = ChatDashScopeOpenAI(
                model=self.config["deep_think_llm"],
                temperature=0.1,
                max_tokens=2000
            )
            self.quick_thinking_llm = ChatDashScopeOpenAI(
                model=self.config["quick_think_llm"],
                temperature=0.1,
                max_tokens=2000
            )
        elif (self.config["llm_provider"].lower() == "deepseek" or
              "deepseek" in self.config["llm_provider"].lower()):
            # DeepSeek V3é…ç½® - ä½¿ç”¨æ”¯æŒtokenç»Ÿè®¡çš„é€‚é…å™¨
            from tradingagents.llm_adapters.deepseek_adapter import ChatDeepSeek


            deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')
            if not deepseek_api_key:
                raise ValueError("ä½¿ç”¨DeepSeekéœ€è¦è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡")

            deepseek_base_url = os.getenv('DEEPSEEK_BASE_URL', 'https://api.deepseek.com')

            # ä½¿ç”¨æ”¯æŒtokenç»Ÿè®¡çš„DeepSeeké€‚é…å™¨
            self.deep_thinking_llm = ChatDeepSeek(
                model=self.config["deep_think_llm"],
                api_key=deepseek_api_key,
                base_url=deepseek_base_url,
                temperature=0.1,
                max_tokens=2000
            )
            self.quick_thinking_llm = ChatDeepSeek(
                model=self.config["quick_think_llm"],
                api_key=deepseek_api_key,
                base_url=deepseek_base_url,
                temperature=0.1,
                max_tokens=2000
                )

            logger.info(f"âœ… [DeepSeek] å·²å¯ç”¨tokenç»Ÿè®¡åŠŸèƒ½")
        elif self.config["llm_provider"].lower() == "custom_openai":
            # è‡ªå®šä¹‰OpenAIç«¯ç‚¹é…ç½®
            from tradingagents.llm_adapters.openai_compatible_base import create_openai_compatible_llm
            
            custom_api_key = os.getenv('CUSTOM_OPENAI_API_KEY')
            if not custom_api_key:
                raise ValueError("ä½¿ç”¨è‡ªå®šä¹‰OpenAIç«¯ç‚¹éœ€è¦è®¾ç½®CUSTOM_OPENAI_API_KEYç¯å¢ƒå˜é‡")
            
            custom_base_url = self.config.get("custom_openai_base_url", "https://api.openai.com/v1")
            
            logger.info(f"ğŸ”§ [è‡ªå®šä¹‰OpenAI] ä½¿ç”¨ç«¯ç‚¹: {custom_base_url}")
            
            # ä½¿ç”¨OpenAIå…¼å®¹é€‚é…å™¨åˆ›å»ºLLMå®ä¾‹
            self.deep_thinking_llm = create_openai_compatible_llm(
                provider="custom_openai",
                model=self.config["deep_think_llm"],
                base_url=custom_base_url,
                temperature=0.1,
                max_tokens=2000
            )
            self.quick_thinking_llm = create_openai_compatible_llm(
                provider="custom_openai",
                model=self.config["quick_think_llm"],
                base_url=custom_base_url,
                temperature=0.1,
                max_tokens=2000
            )
            
            logger.info(f"âœ… [è‡ªå®šä¹‰OpenAI] å·²é…ç½®è‡ªå®šä¹‰ç«¯ç‚¹: {custom_base_url}")
        elif self.config["llm_provider"].lower() == "qianfan":
            # ç™¾åº¦åƒå¸†ï¼ˆæ–‡å¿ƒä¸€è¨€ï¼‰é…ç½® - ç»Ÿä¸€ç”±é€‚é…å™¨å†…éƒ¨è¯»å–ä¸æ ¡éªŒ QIANFAN_API_KEY
            from tradingagents.llm_adapters.openai_compatible_base import create_openai_compatible_llm
            
            # ä½¿ç”¨OpenAIå…¼å®¹é€‚é…å™¨åˆ›å»ºLLMå®ä¾‹ï¼ˆåŸºç±»ä¼šä½¿ç”¨åƒå¸†é»˜è®¤base_urlå¹¶è´Ÿè´£å¯†é’¥æ ¡éªŒï¼‰
            self.deep_thinking_llm = create_openai_compatible_llm(
                provider="qianfan",
                model=self.config["deep_think_llm"],
                temperature=0.1,
                max_tokens=2000
            )
            self.quick_thinking_llm = create_openai_compatible_llm(
                provider="qianfan",
                model=self.config["quick_think_llm"],
                temperature=0.1,
                max_tokens=2000
            )
            logger.info("âœ… [åƒå¸†] æ–‡å¿ƒä¸€è¨€é€‚é…å™¨å·²é…ç½®æˆåŠŸ")
        else:
            raise ValueError(f"Unsupported LLM provider: {self.config['llm_provider']}")
        
        self.toolkit = Toolkit(config=self.config)

        # Initialize memories (å¦‚æœå¯ç”¨)
        memory_enabled = self.config.get("memory_enabled", True)
        if memory_enabled:
            # ä½¿ç”¨å•ä¾‹ChromaDBç®¡ç†å™¨ï¼Œé¿å…å¹¶å‘åˆ›å»ºå†²çª
            self.bull_memory = FinancialSituationMemory("bull_memory", self.config)
            self.bear_memory = FinancialSituationMemory("bear_memory", self.config)
            self.trader_memory = FinancialSituationMemory("trader_memory", self.config)
            self.invest_judge_memory = FinancialSituationMemory("invest_judge_memory", self.config)
            self.risk_manager_memory = FinancialSituationMemory("risk_manager_memory", self.config)
        else:
            # åˆ›å»ºç©ºçš„å†…å­˜å¯¹è±¡
            self.bull_memory = None
            self.bear_memory = None
            self.trader_memory = None
            self.invest_judge_memory = None
            self.risk_manager_memory = None

        # Create tool nodes
        self.tool_nodes = self._create_tool_nodes()

        # Initialize components
        # ä»configè¯»å–è¾©è®ºå’Œé£é™©è®¨è®ºçš„è½®æ•°é…ç½®
        max_debate_rounds = self.config.get("max_debate_rounds", 1)
        max_risk_discuss_rounds = self.config.get("max_risk_discuss_rounds", 1)
        self.conditional_logic = ConditionalLogic(
            max_debate_rounds=max_debate_rounds,
            max_risk_discuss_rounds=max_risk_discuss_rounds
        )
        self.graph_setup = GraphSetup(
            self.quick_thinking_llm,
            self.deep_thinking_llm,
            self.toolkit,
            self.tool_nodes,
            self.bull_memory,
            self.bear_memory,
            self.trader_memory,
            self.invest_judge_memory,
            self.risk_manager_memory,
            self.conditional_logic,
            self.config,
            getattr(self, 'react_llm', None),
        )

        self.propagator = Propagator()
        self.reflector = Reflector(self.quick_thinking_llm)
        self.signal_processor = SignalProcessor(self.quick_thinking_llm)

        # State tracking
        self.curr_state = None
        self.ticker = None
        self.log_states_dict = {}  # date to full state dict
        
        # Step-by-step output tracking (å†…å­˜ä¿å­˜)
        self.step_traces = []  # List of all chunks during execution
        self.enable_step_tracking = self.config.get("enable_step_tracking", True)  # é»˜è®¤å¯ç”¨
        
        # æ¨¡æ‹Ÿæ¨¡å¼é…ç½®
        self.mock_mode_config = self._load_mock_mode_config()
        # ä»ç¯å¢ƒå˜é‡è¯»å–sleepæ—¶é—´é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
        self.mock_sleep_min = float(os.getenv('MOCK_SLEEP_MIN', '2'))  # é»˜è®¤2ç§’
        self.mock_sleep_max = float(os.getenv('MOCK_SLEEP_MAX', '10'))  # é»˜è®¤10ç§’
        
        # MongoDBæ­¥éª¤çŠ¶æ€ç®¡ç†å™¨ï¼ˆç”¨äºå­˜å‚¨å’Œè¯»å–æ­¥éª¤çŠ¶æ€ï¼‰
        from tradingagents.utils.mongodb_steps_status_manager import mongodb_steps_status_manager
        self.steps_status_manager = mongodb_steps_status_manager

        # Set up the graph
        self.graph = self.graph_setup.setup_graph(selected_analysts)
        
        # è®¾ç½®graphå®ä¾‹åˆ°æ¨¡æ‹Ÿæ¨¡å¼è¾…åŠ©å·¥å…·ä¸­
        from .mock_mode_helper import set_graph_instance
        set_graph_instance(self)

    def _create_tool_nodes(self) -> Dict[str, ToolNode]:
        """Create tool nodes for different data sources."""
        return {
            "market": ToolNode(
                [
                    # ç»Ÿä¸€å·¥å…·
                    self.toolkit.get_stock_market_data_unified,
                    # online tools
                    self.toolkit.get_YFin_data_online,
                    self.toolkit.get_stockstats_indicators_report_online,
                    # offline tools
                    self.toolkit.get_YFin_data,
                    self.toolkit.get_stockstats_indicators_report,
                ]
            ),
            "social": ToolNode(
                [
                    # online tools
                    self.toolkit.get_stock_news_openai,
                    # offline tools
                    self.toolkit.get_reddit_stock_info,
                ]
            ),
            "news": ToolNode(
                [
                    # online tools
                    self.toolkit.get_global_news_openai,
                    self.toolkit.get_google_news,
                    # offline tools
                    self.toolkit.get_finnhub_news,
                    self.toolkit.get_reddit_news,
                ]
            ),
            "fundamentals": ToolNode(
                [
                    # ç»Ÿä¸€å·¥å…·
                    self.toolkit.get_stock_fundamentals_unified,
                    # offline tools
                    self.toolkit.get_finnhub_company_insider_sentiment,
                    self.toolkit.get_finnhub_company_insider_transactions,
                    self.toolkit.get_simfin_balance_sheet,
                    self.toolkit.get_simfin_cashflow,
                    self.toolkit.get_simfin_income_stmt,
                ]
            ),
        }

    def propagate(self, company_name, trade_date, analysis_id=None, session_id=None):
        """Run the trading agents graph for a company on a specific date."""
        
        # æ·»åŠ è¯¦ç»†çš„æ¥æ”¶æ—¥å¿—
        logger.debug(f"ğŸ” [GRAPH DEBUG] ===== TradingAgentsGraph.propagate æ¥æ”¶å‚æ•° =====")
        logger.debug(f"ğŸ” [GRAPH DEBUG] æ¥æ”¶åˆ°çš„company_name: '{company_name}' (ç±»å‹: {type(company_name)})")
        logger.debug(f"ğŸ” [GRAPH DEBUG] æ¥æ”¶åˆ°çš„trade_date: '{trade_date}' (ç±»å‹: {type(trade_date)})")
        logger.debug(f"ğŸ” [GRAPH DEBUG] æ¥æ”¶åˆ°çš„analysis_id: '{analysis_id}' (ç±»å‹: {type(analysis_id)})")
        logger.debug(f"ğŸ” [GRAPH DEBUG] æ¥æ”¶åˆ°çš„session_id: '{session_id}' (ç±»å‹: {type(session_id)})")

        self.ticker = company_name
        logger.debug(f"ğŸ” [GRAPH DEBUG] è®¾ç½®self.ticker: '{self.ticker}'")

        # Initialize state
        logger.debug(f"ğŸ” [GRAPH DEBUG] åˆ›å»ºåˆå§‹çŠ¶æ€ï¼Œä¼ é€’å‚æ•°: company_name='{company_name}', trade_date='{trade_date}', analysis_id='{analysis_id}', session_id='{session_id}'")
        init_agent_state = self.propagator.create_initial_state(
            company_name, trade_date, analysis_id=analysis_id, session_id=session_id
        )
        logger.debug(f"ğŸ” [GRAPH DEBUG] åˆå§‹çŠ¶æ€ä¸­çš„company_of_interest: '{init_agent_state.get('company_of_interest', 'NOT_FOUND')}'")
        logger.debug(f"ğŸ” [GRAPH DEBUG] åˆå§‹çŠ¶æ€ä¸­çš„trade_date: '{init_agent_state.get('trade_date', 'NOT_FOUND')}'")
        logger.debug(f"ğŸ” [GRAPH DEBUG] åˆå§‹çŠ¶æ€ä¸­çš„analysis_id: '{init_agent_state.get('analysis_id', 'NOT_FOUND')}'")
        logger.debug(f"ğŸ” [GRAPH DEBUG] åˆå§‹çŠ¶æ€ä¸­çš„session_id: '{init_agent_state.get('session_id', 'NOT_FOUND')}'")
        args = self.propagator.get_graph_args()

        # æ¸…ç©ºä¹‹å‰çš„æ­¥éª¤è¿½è¸ª
        self.step_traces = []

        # åˆ›å»ºæ­¥éª¤è¾“å‡ºä¿å­˜ç›®å½•
        step_output_dir = self._prepare_step_output_directory(trade_date)

        # ä½¿ç”¨streamæ¨¡å¼æ”¶é›†æ‰€æœ‰æ­¥éª¤ï¼ˆæ— è®ºdebugæ¨¡å¼ä¸å¦ï¼‰
        trace = []
        step_count = 0
        
        logger.info(f"ğŸ“Š [æ­¥éª¤è¿½è¸ª] å¼€å§‹æ”¶é›†æ¯æ­¥è¾“å‡ºï¼Œä¿å­˜ç›®å½•: {step_output_dir}")
        
        for chunk in self.graph.stream(init_agent_state, **args):
            step_count += 1
            
            # æ£€æŸ¥ä»»åŠ¡æ§åˆ¶ä¿¡å·ï¼ˆæš‚åœ/åœæ­¢ï¼‰
            if analysis_id:
                from tradingagents.tasks import get_task_manager
                from tradingagents.exceptions import TaskControlStoppedException
                task_manager = get_task_manager()
                
                # æ£€æŸ¥åœæ­¢ä¿¡å·
                if task_manager.should_stop(analysis_id):
                    logger.info(f"â¹ï¸ [ä»»åŠ¡æ§åˆ¶] æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œä¸­æ–­åˆ†æ: {analysis_id}")
                    raise TaskControlStoppedException(f"ä»»åŠ¡å·²è¢«åœæ­¢: {analysis_id}")
                
                # æ£€æŸ¥æš‚åœä¿¡å·å¹¶ç­‰å¾…
                if task_manager.should_pause(analysis_id):
                    logger.info(f"â¸ï¸ [ä»»åŠ¡æ§åˆ¶] æ”¶åˆ°æš‚åœä¿¡å·ï¼Œç­‰å¾…æ¢å¤: {analysis_id}")
                    task_manager.wait_if_paused(analysis_id)
                    
                    # æ¢å¤åå†æ¬¡æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢
                    if task_manager.should_stop(analysis_id):
                        logger.info(f"â¹ï¸ [ä»»åŠ¡æ§åˆ¶] æš‚åœæœŸé—´æ”¶åˆ°åœæ­¢ä¿¡å·: {analysis_id}")
                        raise TaskControlStoppedException(f"ä»»åŠ¡å·²è¢«åœæ­¢: {analysis_id}")
                    logger.info(f"â–¶ï¸ [ä»»åŠ¡æ§åˆ¶] ä»»åŠ¡æ¢å¤æ‰§è¡Œ: {analysis_id}")
            
            # åºåˆ—åŒ–chunkä»¥ä¾¿ä¿å­˜
            serialized_chunk = self._serialize_chunk(chunk, step_count)
            
            # ä¿å­˜åˆ°å†…å­˜
            trace.append(chunk)
            self.step_traces.append(serialized_chunk)
            
            # ä¿å­˜æ¯ä¸ªchunkåˆ°æ–‡ä»¶
            if self.enable_step_tracking:
                self._save_chunk_to_file(serialized_chunk, step_count, step_output_dir)
            
            # Debugæ¨¡å¼ä¸‹æ‰“å°
            if self.debug and len(chunk.get("messages", [])) > 0:
                chunk["messages"][-1].pretty_print()
            
            logger.debug(f"ğŸ“ [æ­¥éª¤è¿½è¸ª] å·²ä¿å­˜æ­¥éª¤ {step_count}")

        # è·å–æœ€ç»ˆçŠ¶æ€
        final_state = trace[-1] if trace else self.graph.invoke(init_agent_state, **args)
        
        # ä¿å­˜æ‰€æœ‰æ­¥éª¤çš„æ±‡æ€»æ–‡ä»¶
        if self.enable_step_tracking:
            self._save_steps_summary(trace, step_output_dir)
        
        logger.info(f"âœ… [æ­¥éª¤è¿½è¸ª] å®Œæˆï¼Œå…±æ”¶é›† {step_count} ä¸ªæ­¥éª¤")

        # Store current state for reflection
        self.curr_state = final_state

        # Log state
        self._log_state(trade_date, final_state)

        # Return decision and processed signal
        return final_state, self.process_signal(final_state["final_trade_decision"], company_name, analysis_id=analysis_id)

    def _load_mock_mode_config(self) -> Dict[str, bool]:
        """åŠ è½½æ¨¡æ‹Ÿæ¨¡å¼é…ç½®ï¼Œæ”¯æŒèŠ‚ç‚¹çº§åˆ«çš„é…ç½®
        
        æ”¯æŒçš„é…ç½®æ ¼å¼ï¼š
        - MOCK_ANALYSIS_MODE=true: æ‰€æœ‰èŠ‚ç‚¹å¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼
        - MOCK_ANALYSIS_MODE=false: æ‰€æœ‰èŠ‚ç‚¹ç¦ç”¨æ¨¡æ‹Ÿæ¨¡å¼
        - MOCK_ANALYSIS_MODE=market,news: åªå¯¹marketå’ŒnewsèŠ‚ç‚¹å¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼
        - MOCK_ANALYSIS_MODE=market_analyst,bull_researcher: æ”¯æŒèŠ‚ç‚¹åç§°
        """
        mock_config = os.getenv('MOCK_ANALYSIS_MODE', 'false').strip().lower()
        
        # å¦‚æœé…ç½®ä¸ºfalseï¼Œæ‰€æœ‰èŠ‚ç‚¹éƒ½ä¸å¯ç”¨
        if mock_config == 'false' or mock_config == '':
            return {}
        
        # å¦‚æœé…ç½®ä¸ºtrueï¼Œæ‰€æœ‰èŠ‚ç‚¹éƒ½å¯ç”¨
        if mock_config == 'true':
            return {'all': True}
        
        # è§£æèŠ‚ç‚¹åˆ—è¡¨
        node_list = [node.strip() for node in mock_config.split(',')]
        config = {}
        
        # èŠ‚ç‚¹åç§°æ˜ å°„ï¼ˆæ”¯æŒå¤šç§å‘½åæ–¹å¼ï¼‰
        node_mapping = {
            'market': 'market_analyst',
            'market_analyst': 'market_analyst',
            'fundamentals': 'fundamentals_analyst',
            'fundamentals_analyst': 'fundamentals_analyst',
            'news': 'news_analyst',
            'news_analyst': 'news_analyst',
            'social': 'social_media_analyst',
            'social_media_analyst': 'social_media_analyst',
            'bull': 'bull_researcher',
            'bull_researcher': 'bull_researcher',
            'bear': 'bear_researcher',
            'bear_researcher': 'bear_researcher',
            'research_manager': 'research_manager',
            'trader': 'trader',
            'risky': 'risky_analyst',
            'risky_analyst': 'risky_analyst',
            'safe': 'safe_analyst',
            'safe_analyst': 'safe_analyst',
            'neutral': 'neutral_analyst',
            'neutral_analyst': 'neutral_analyst',
            'risk_manager': 'risk_manager',
            'risk_judge': 'risk_manager',
        }
        
        for node in node_list:
            normalized_node = node_mapping.get(node, node)
            config[normalized_node] = True
        
        logger.info(f"ğŸ­ [æ¨¡æ‹Ÿæ¨¡å¼é…ç½®] å·²åŠ è½½: {config}")
        return config
    
    def _should_use_mock_mode(self, node_name: str) -> bool:
        """æ£€æŸ¥æŸä¸ªèŠ‚ç‚¹æ˜¯å¦åº”è¯¥ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
        
        Args:
            node_name: èŠ‚ç‚¹åç§°ï¼Œå¦‚ 'market_analyst', 'bull_researcher' ç­‰
            
        Returns:
            å¦‚æœåº”è¯¥ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        if not self.mock_mode_config:
            return False
        
        # å¦‚æœé…ç½®äº†'all'ï¼Œæ‰€æœ‰èŠ‚ç‚¹éƒ½å¯ç”¨
        if self.mock_mode_config.get('all', False):
            return True
        
        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åœ¨é…ç½®åˆ—è¡¨ä¸­
        return self.mock_mode_config.get(node_name, False)
    
    def _load_historical_step_output(self, node_name: str, ticker: str, trade_date: str, current_state: Optional[Dict[str, Any]] = None) -> Optional[Dict[str, Any]]:
        """ä»MongoDBçš„analysis_steps_statusé›†åˆä¸­åŠ è½½æŒ‡å®šèŠ‚ç‚¹çš„å†å²è¾“å‡º
        
        Args:
            node_name: èŠ‚ç‚¹åç§°
            ticker: è‚¡ç¥¨ä»£ç 
            trade_date: äº¤æ˜“æ—¥æœŸ
            current_state: å½“å‰çŠ¶æ€å­—å…¸ï¼Œç”¨äºè·å–countå€¼
            
        Returns:
            å¦‚æœæ‰¾åˆ°å†å²è¾“å‡ºåˆ™è¿”å›çŠ¶æ€å­—å…¸ï¼Œå¦åˆ™è¿”å›None
        """
        # ä¼˜å…ˆä»MongoDBè¯»å–
        if self.steps_status_manager.is_connected():
            try:
                doc = self.steps_status_manager.load_step_status(ticker, trade_date)
                
                if doc:
                    # æŸ¥æ‰¾åŒ¹é…çš„èŠ‚ç‚¹è¾“å‡º
                    # ç”±äºMongoDBä¸­å­˜å‚¨çš„æ˜¯å•ä¸ªæ­¥éª¤æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨è¯¥æ–‡æ¡£
                    # æ£€æŸ¥æ˜¯å¦åŒ¹é…å½“å‰èŠ‚ç‚¹
                    if self._match_node_output(node_name, "", doc):
                        logger.info(f"ğŸ­ [æ¨¡æ‹Ÿæ¨¡å¼] ä»MongoDBæ‰¾åˆ°å†å²è¾“å‡º: {node_name} (è‚¡ç¥¨: {ticker}, æ—¥æœŸ: {trade_date})")
                        return self._convert_historical_to_state(doc, node_name, current_state)
                    else:
                        logger.debug(f"ğŸ” [æ¨¡æ‹Ÿæ¨¡å¼] MongoDBä¸­æ‰¾åˆ°è®°å½•ä½†èŠ‚ç‚¹ä¸åŒ¹é…: {node_name}")
                else:
                    logger.debug(f"ğŸ” [æ¨¡æ‹Ÿæ¨¡å¼] MongoDBä¸­æœªæ‰¾åˆ°è®°å½•: {ticker} - {trade_date}")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ [æ¨¡æ‹Ÿæ¨¡å¼] ä»MongoDBè¯»å–å¤±è´¥: {e}ï¼Œå°è¯•ä»æ–‡ä»¶ç³»ç»Ÿè¯»å–")
        
        # å¦‚æœMongoDBè¯»å–å¤±è´¥ï¼Œå›é€€åˆ°æ–‡ä»¶ç³»ç»Ÿ
        # æŸ¥æ‰¾å†å²æ­¥éª¤æ–‡ä»¶
        step_output_dir = Path(f"eval_results/{ticker}/TradingAgentsStrategy_logs/step_outputs")
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„æ—¥æœŸæ ¼å¼
        possible_dates = [
            trade_date,
            trade_date.replace('-', ''),
            str(datetime.strptime(trade_date, '%Y-%m-%d').strftime('%Y%m%d')) if '-' in trade_date else None
        ]
        
        for date_str in possible_dates:
            if not date_str:
                continue
            
            date_dir = step_output_dir / date_str
            
            # æ£€æŸ¥all_steps.jsonæ–‡ä»¶
            all_steps_file = date_dir / "all_steps.json"
            if all_steps_file.exists():
                try:
                    with open(all_steps_file, 'r', encoding='utf-8') as f:
                        all_steps = json.load(f)
                    
                    # æŸ¥æ‰¾åŒ¹é…çš„èŠ‚ç‚¹è¾“å‡ºï¼ˆæ‰¾åˆ°æœ€åŒ¹é…çš„æ­¥éª¤ï¼‰
                    best_match = None
                    best_match_score = 0
                    
                    for step in all_steps:
                        # æ£€æŸ¥æ¶ˆæ¯å†…å®¹ä¸­æ˜¯å¦åŒ…å«èŠ‚ç‚¹æ ‡è¯†
                        messages = step.get('messages', [])
                        match_score = 0
                        
                        for msg in messages:
                            content = str(msg.get('content', ''))
                            # æ ¹æ®èŠ‚ç‚¹åç§°å’Œå†…å®¹ç‰¹å¾åŒ¹é…ï¼Œè®¡ç®—åŒ¹é…åˆ†æ•°
                            if self._match_node_output(node_name, content, step):
                                # è®¡ç®—åŒ¹é…åˆ†æ•°ï¼ˆå…³é”®è¯åŒ¹é…æ•°é‡ï¼‰
                                match_score = self._calculate_match_score(node_name, content, step)
                                if match_score > best_match_score:
                                    best_match = step
                                    best_match_score = match_score
                    
                    if best_match:
                        logger.info(f"ğŸ­ [æ¨¡æ‹Ÿæ¨¡å¼] ä»æ–‡ä»¶ç³»ç»Ÿæ‰¾åˆ°å†å²è¾“å‡º: {node_name} (æ­¥éª¤ {best_match.get('step_number', '?')}, åŒ¹é…åˆ†æ•°: {best_match_score})")
                        return self._convert_historical_to_state(best_match, node_name, current_state)
                except Exception as e:
                    logger.debug(f"ğŸ” [æ¨¡æ‹Ÿæ¨¡å¼] è¯»å–å†å²æ–‡ä»¶å¤±è´¥: {e}")
                    continue
        
        logger.warning(f"âš ï¸ [æ¨¡æ‹Ÿæ¨¡å¼] æœªæ‰¾åˆ°èŠ‚ç‚¹ {node_name} çš„å†å²è¾“å‡º")
        return None
    
    def _match_node_output(self, node_name: str, content: str, step: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ­¥éª¤æ˜¯å¦åŒ¹é…æŒ‡å®šçš„èŠ‚ç‚¹
        
        Args:
            node_name: èŠ‚ç‚¹åç§°
            content: æ¶ˆæ¯å†…å®¹
            step: æ­¥éª¤æ•°æ®
            
        Returns:
            å¦‚æœåŒ¹é…è¿”å›True
        """
        # ç‰¹æ®Šå¤„ç†ï¼šrisk_managerèŠ‚ç‚¹ï¼Œä¼˜å…ˆæ£€æŸ¥å…¶ç‰¹å®šè¾“å‡ºå­—æ®µ
        if node_name == 'risk_manager':
            # risk_managerçš„ä¸»è¦è¾“å‡ºå­—æ®µæ˜¯risk_debate_state.judge_decisionå’Œfinal_trade_decision
            risk_debate_state = step.get('risk_debate_state', {})
            if isinstance(risk_debate_state, dict):
                judge_decision = risk_debate_state.get('judge_decision', '')
                if judge_decision and len(str(judge_decision).strip()) > 0:
                    return True
            
            # æ£€æŸ¥final_trade_decisionå­—æ®µï¼ˆrisk_managerçš„è¾“å‡ºï¼‰
            final_decision = step.get('final_trade_decision', '')
            if final_decision and len(str(final_decision).strip()) > 0:
                # è¿›ä¸€æ­¥ç¡®è®¤ï¼šfinal_trade_decisioné€šå¸¸åŒ…å«é£é™©è¯„çº§ä¿¡æ¯
                final_decision_str = str(final_decision).lower()
                if any(keyword in final_decision_str for keyword in ['é£é™©', 'risk', 'é£é™©è¯„çº§', 'é£é™©ç­‰çº§']):
                    return True
        
        # èŠ‚ç‚¹åç§°åˆ°å…³é”®è¯çš„æ˜ å°„
        node_keywords = {
            'market_analyst': ['å¸‚åœº', 'æŠ€æœ¯', 'ä»·æ ¼', 'market', 'æŠ€æœ¯åˆ†æ', 'æŠ€æœ¯æŒ‡æ ‡'],
            'fundamentals_analyst': ['åŸºæœ¬é¢', 'è´¢åŠ¡', 'fundamental', 'è´¢åŠ¡æŒ‡æ ‡', 'è´¢åŠ¡æŠ¥è¡¨'],
            'news_analyst': ['æ–°é—»', 'news', 'äº‹ä»¶', 'æ–°é—»äº‹ä»¶'],
            'social_media_analyst': ['ç¤¾äº¤', 'æƒ…ç»ª', 'sentiment', 'ç¤¾äº¤åª’ä½“'],
            'bull_researcher': ['çœ‹æ¶¨', 'bull', 'å¤šå¤´', 'ä¹è§‚'],
            'bear_researcher': ['çœ‹è·Œ', 'bear', 'ç©ºå¤´', 'æ‚²è§‚'],
            'research_manager': ['ç ”ç©¶ç»ç†', 'ç»¼åˆ', 'ç»¼åˆåˆ¤æ–­'],
            'trader': ['äº¤æ˜“', 'trader', 'äº¤æ˜“è®¡åˆ’', 'æŠ•èµ„å»ºè®®'],
            'risky_analyst': ['æ¿€è¿›', 'risky', 'é«˜é£é™©'],
            'safe_analyst': ['ä¿å®ˆ', 'safe', 'ä½é£é™©'],
            'neutral_analyst': ['ä¸­æ€§', 'neutral', 'å¹³è¡¡'],
            'risk_manager': ['é£é™©ç»ç†', 'é£é™©å†³ç­–', 'é£é™©è¯„çº§', 'é£é™©ç­‰çº§', 'risk_manager', 'risk judge'],
        }
        
        keywords = node_keywords.get(node_name, [])
        if not keywords:
            return False
        
        # æ£€æŸ¥å†…å®¹æˆ–å­—æ®µæ˜¯å¦åŒ…å«å…³é”®è¯
        content_lower = content.lower()
        for keyword in keywords:
            if keyword.lower() in content_lower:
                return True
        
        # æ£€æŸ¥æ­¥éª¤ä¸­çš„æŠ¥å‘Šå­—æ®µ
        report_fields = ['market_report', 'fundamentals_report', 'news_report', 
                        'sentiment_report', 'investment_plan', 'final_trade_decision']
        for field in report_fields:
            field_content = step.get(field, '')
            if field_content:
                for keyword in keywords:
                    if keyword.lower() in str(field_content).lower():
                        return True
        
        return False
    
    def _calculate_match_score(self, node_name: str, content: str, step: Dict[str, Any]) -> int:
        """è®¡ç®—åŒ¹é…åˆ†æ•°
        
        Args:
            node_name: èŠ‚ç‚¹åç§°
            content: æ¶ˆæ¯å†…å®¹
            step: æ­¥éª¤æ•°æ®
            
        Returns:
            åŒ¹é…åˆ†æ•°ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
        """
        score = 0
        
        # ç‰¹æ®Šå¤„ç†ï¼šrisk_managerèŠ‚ç‚¹ï¼Œä¼˜å…ˆæ£€æŸ¥å…¶ç‰¹å®šè¾“å‡ºå­—æ®µï¼ˆç»™äºˆé«˜åˆ†ï¼‰
        if node_name == 'risk_manager':
            risk_debate_state = step.get('risk_debate_state', {})
            if isinstance(risk_debate_state, dict):
                judge_decision = risk_debate_state.get('judge_decision', '')
                if judge_decision and len(str(judge_decision).strip()) > 0:
                    score += 10  # é«˜é£é™©ç‰¹å¾ï¼Œä¼˜å…ˆåŒ¹é…
            
            # final_trade_decisionæ˜¯risk_managerçš„ä¸»è¦è¾“å‡º
            final_decision = step.get('final_trade_decision', '')
            if final_decision and len(str(final_decision).strip()) > 0:
                final_decision_str = str(final_decision).lower()
                if any(keyword in final_decision_str for keyword in ['é£é™©', 'risk', 'é£é™©è¯„çº§', 'é£é™©ç­‰çº§']):
                    score += 10  # é«˜é£é™©ç‰¹å¾ï¼Œä¼˜å…ˆåŒ¹é…
        
        node_keywords = {
            'market_analyst': ['å¸‚åœº', 'æŠ€æœ¯', 'ä»·æ ¼', 'market', 'æŠ€æœ¯åˆ†æ', 'æŠ€æœ¯æŒ‡æ ‡'],
            'fundamentals_analyst': ['åŸºæœ¬é¢', 'è´¢åŠ¡', 'fundamental', 'è´¢åŠ¡æŒ‡æ ‡', 'è´¢åŠ¡æŠ¥è¡¨'],
            'news_analyst': ['æ–°é—»', 'news', 'äº‹ä»¶', 'æ–°é—»äº‹ä»¶'],
            'social_media_analyst': ['ç¤¾äº¤', 'æƒ…ç»ª', 'sentiment', 'ç¤¾äº¤åª’ä½“'],
            'bull_researcher': ['çœ‹æ¶¨', 'bull', 'å¤šå¤´', 'ä¹è§‚'],
            'bear_researcher': ['çœ‹è·Œ', 'bear', 'ç©ºå¤´', 'æ‚²è§‚'],
            'research_manager': ['ç ”ç©¶ç»ç†', 'ç»¼åˆ', 'ç»¼åˆåˆ¤æ–­'],
            'trader': ['äº¤æ˜“', 'trader', 'äº¤æ˜“è®¡åˆ’', 'æŠ•èµ„å»ºè®®'],
            'risky_analyst': ['æ¿€è¿›', 'risky', 'é«˜é£é™©'],
            'safe_analyst': ['ä¿å®ˆ', 'safe', 'ä½é£é™©'],
            'neutral_analyst': ['ä¸­æ€§', 'neutral', 'å¹³è¡¡'],
            'risk_manager': ['é£é™©ç»ç†', 'é£é™©å†³ç­–', 'é£é™©è¯„çº§', 'é£é™©ç­‰çº§', 'risk_manager', 'risk judge'],
        }
        
        keywords = node_keywords.get(node_name, [])
        content_lower = content.lower()
        
        # è®¡ç®—å…³é”®è¯åŒ¹é…æ•°é‡
        for keyword in keywords:
            if keyword.lower() in content_lower:
                score += 1
        
        # æ£€æŸ¥æŠ¥å‘Šå­—æ®µ
        report_fields = ['market_report', 'fundamentals_report', 'news_report', 
                        'sentiment_report', 'investment_plan', 'final_trade_decision']
        for field in report_fields:
            field_content = step.get(field, '')
            if field_content:
                for keyword in keywords:
                    if keyword.lower() in str(field_content).lower():
                        score += 1
        
        return score
    
    def _convert_historical_to_state(self, historical_step: Dict[str, Any], node_name: str, current_state: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """å°†å†å²æ­¥éª¤æ•°æ®è½¬æ¢ä¸ºçŠ¶æ€å­—å…¸
        
        Args:
            historical_step: å†å²æ­¥éª¤æ•°æ®
            node_name: èŠ‚ç‚¹åç§°
            current_state: å½“å‰çŠ¶æ€å­—å…¸ï¼Œç”¨äºè·å–countå€¼
            
        Returns:
            çŠ¶æ€å­—å…¸
        """
        # åˆ›å»ºåŸºç¡€çŠ¶æ€
        state = {
            'company_of_interest': historical_step.get('company_of_interest', ''),
            'trade_date': historical_step.get('trade_date', ''),
            'messages': []
        }
        
        # è½¬æ¢æ¶ˆæ¯
        for msg in historical_step.get('messages', []):
            if isinstance(msg, dict):
                msg_type = msg.get('type', '')
                content = msg.get('content', '')
                if msg_type == 'tuple':
                    state['messages'].append((msg.get('role', 'human'), content))
                else:
                    # åˆ›å»ºç®€å•çš„æ¶ˆæ¯å¯¹è±¡
                    from langchain_core.messages import AIMessage
                    state['messages'].append(AIMessage(content=content))
        
        # å¤åˆ¶æŠ¥å‘Šå­—æ®µ
        report_fields = ['market_report', 'fundamentals_report', 'news_report', 
                        'sentiment_report', 'investment_plan', 'trader_investment_plan',
                        'final_trade_decision']
        for field in report_fields:
            if field in historical_step:
                state[field] = historical_step[field]
        
        # å¤åˆ¶è¾©è®ºçŠ¶æ€
        # ä½¿ç”¨å½“å‰stateçš„countå€¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™è®¾ä¸º0
        if 'investment_debate_state' in historical_step:
            investment_state = historical_step['investment_debate_state'].copy() if isinstance(historical_step['investment_debate_state'], dict) else historical_step['investment_debate_state']
            if isinstance(investment_state, dict):
                # å¦‚æœå½“å‰stateä¸­æœ‰countå€¼ï¼Œä½¿ç”¨å½“å‰stateçš„countå€¼ï¼›å¦åˆ™è®¾ä¸º0
                if current_state and 'investment_debate_state' in current_state and isinstance(current_state['investment_debate_state'], dict):
                    current_count = current_state['investment_debate_state'].get('count')
                    if current_count is not None:
                        investment_state['count'] = current_count
                    else:
                        investment_state['count'] = 0
                else:
                    investment_state['count'] = 0
            state['investment_debate_state'] = investment_state
        
        if 'risk_debate_state' in historical_step:
            risk_state = historical_step['risk_debate_state'].copy() if isinstance(historical_step['risk_debate_state'], dict) else historical_step['risk_debate_state']
            if isinstance(risk_state, dict):
                # å¦‚æœå½“å‰stateä¸­æœ‰countå€¼ï¼Œä½¿ç”¨å½“å‰stateçš„countå€¼ï¼›å¦åˆ™è®¾ä¸º0
                if current_state and 'risk_debate_state' in current_state and isinstance(current_state['risk_debate_state'], dict):
                    current_count = current_state['risk_debate_state'].get('count')
                    if current_count is not None:
                        risk_state['count'] = current_count
                    else:
                        risk_state['count'] = 0
                else:
                    risk_state['count'] = 0
            state['risk_debate_state'] = risk_state
        
        return state
    
    def _prepare_step_output_directory(self, trade_date: str) -> Path:
        """å‡†å¤‡æ­¥éª¤è¾“å‡ºä¿å­˜ç›®å½•"""
        directory = Path(f"eval_results/{self.ticker}/TradingAgentsStrategy_logs/step_outputs/{trade_date}")
        directory.mkdir(parents=True, exist_ok=True)
        return directory
    
    def _serialize_chunk(self, chunk: Dict[str, Any], step_number: int) -> Dict[str, Any]:
        """åºåˆ—åŒ–chunkï¼Œå°†LangChainæ¶ˆæ¯å¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼"""
        serialized = {
            "step_number": step_number,
            "timestamp": datetime.now().isoformat(),
            "company_of_interest": chunk.get("company_of_interest", ""),
            "trade_date": chunk.get("trade_date", ""),
        }
        
        # åºåˆ—åŒ–æ¶ˆæ¯åˆ—è¡¨
        messages = []
        for msg in chunk.get("messages", []):
            if hasattr(msg, "content"):
                # LangChainæ¶ˆæ¯å¯¹è±¡
                msg_dict = {
                    "type": type(msg).__name__,
                    "content": str(msg.content) if msg.content else "",
                }
                # æ·»åŠ å·¥å…·è°ƒç”¨ä¿¡æ¯
                if hasattr(msg, "tool_calls") and msg.tool_calls:
                    msg_dict["tool_calls"] = []
                    for tool_call in msg.tool_calls:
                        if isinstance(tool_call, dict):
                            msg_dict["tool_calls"].append(tool_call)
                        else:
                            msg_dict["tool_calls"].append({
                                "name": getattr(tool_call, "name", ""),
                                "args": getattr(tool_call, "args", {}),
                                "id": getattr(tool_call, "id", "")
                            })
            elif isinstance(msg, tuple):
                # å…ƒç»„æ ¼å¼çš„æ¶ˆæ¯ (role, content)
                msg_dict = {
                    "type": "tuple",
                    "role": msg[0],
                    "content": str(msg[1]) if len(msg) > 1 else ""
                }
            else:
                # å…¶ä»–æ ¼å¼
                msg_dict = {
                    "type": type(msg).__name__,
                    "content": str(msg)
                }
            messages.append(msg_dict)
        
        serialized["messages"] = messages
        
        # ä¿å­˜æ‰€æœ‰æŠ¥å‘Šå­—æ®µ
        report_fields = [
            "market_report", "fundamentals_report", "sentiment_report", 
            "news_report", "investment_plan", "trader_investment_plan",
            "final_trade_decision"
        ]
        for field in report_fields:
            if field in chunk:
                serialized[field] = chunk[field]
        
        # ä¿å­˜è¾©è®ºçŠ¶æ€
        if "investment_debate_state" in chunk:
            debate_state = chunk["investment_debate_state"]
            serialized["investment_debate_state"] = {
                "bull_history": debate_state.get("bull_history", ""),
                "bear_history": debate_state.get("bear_history", ""),
                "history": debate_state.get("history", ""),
                "current_response": debate_state.get("current_response", ""),
                "judge_decision": debate_state.get("judge_decision", ""),
                "count": debate_state.get("count", 0)
            }
        
        if "risk_debate_state" in chunk:
            risk_state = chunk["risk_debate_state"]
            serialized["risk_debate_state"] = {
                "risky_history": risk_state.get("risky_history", ""),
                "safe_history": risk_state.get("safe_history", ""),
                "neutral_history": risk_state.get("neutral_history", ""),
                "history": risk_state.get("history", ""),
                "judge_decision": risk_state.get("judge_decision", ""),
                "count": risk_state.get("count", 0)
            }
        
        return serialized
    
    def _save_chunk_to_file(self, serialized_chunk: Dict[str, Any], step_number: int, output_dir: Path):
        """ä¿å­˜å•ä¸ªchunkåˆ°MongoDBå’Œ/æˆ–æ–‡ä»¶"""
        # ä¼˜å…ˆä¿å­˜åˆ°MongoDB
        if self.steps_status_manager.is_connected():
            try:
                success = self.steps_status_manager.save_step_status(serialized_chunk)
                if success:
                    ticker = serialized_chunk.get('company_of_interest', '')
                    trade_date = serialized_chunk.get('trade_date', '')
                    logger.debug(f"ğŸ’¾ [æ­¥éª¤ä¿å­˜] å·²ä¿å­˜æ­¥éª¤ {step_number} åˆ°MongoDB: {ticker} - {trade_date}")
                else:
                    logger.warning(f"âš ï¸ [æ­¥éª¤ä¿å­˜] ä¿å­˜åˆ°MongoDBå¤±è´¥ï¼Œå°†å°è¯•ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿ")
            except Exception as e:
                logger.warning(f"âš ï¸ [æ­¥éª¤ä¿å­˜] ä¿å­˜åˆ°MongoDBå¤±è´¥: {e}ï¼Œå°†å°è¯•ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿ")
        
        # åŒæ—¶ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿï¼ˆä½œä¸ºå¤‡ä»½ï¼‰
        filename = output_dir / f"step_{step_number:04d}.json"
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(serialized_chunk, f, ensure_ascii=False, indent=2)
            logger.debug(f"ğŸ’¾ [æ­¥éª¤ä¿å­˜] å·²ä¿å­˜æ­¥éª¤ {step_number} åˆ° {filename}")
        except Exception as e:
            logger.error(f"âŒ [æ­¥éª¤ä¿å­˜] ä¿å­˜æ­¥éª¤ {step_number} åˆ°æ–‡ä»¶å¤±è´¥: {e}")
    
    def _save_steps_summary(self, trace: List[Dict[str, Any]], output_dir: Path):
        """ä¿å­˜æ‰€æœ‰æ­¥éª¤çš„æ±‡æ€»æ–‡ä»¶"""
        summary = {
            "total_steps": len(trace),
            "company_of_interest": self.ticker,
            "trade_date": trace[0].get("trade_date", "") if trace else "",
            "generated_at": datetime.now().isoformat(),
            "steps_summary": []
        }
        
        for i, chunk in enumerate(trace, 1):
            step_info = {
                "step_number": i,
                "has_messages": len(chunk.get("messages", [])) > 0,
                "message_count": len(chunk.get("messages", [])),
                "updated_fields": []
            }
            
            # æ£€æµ‹å“ªäº›å­—æ®µè¢«æ›´æ–°äº†
            for field in ["market_report", "fundamentals_report", "sentiment_report", 
                         "news_report", "investment_plan", "trader_investment_plan",
                         "final_trade_decision"]:
                if field in chunk and chunk[field]:
                    step_info["updated_fields"].append(field)
            
            # æ£€æµ‹æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            tool_calls = []
            for msg in chunk.get("messages", []):
                if hasattr(msg, "tool_calls") and msg.tool_calls:
                    for tool_call in msg.tool_calls:
                        if isinstance(tool_call, dict):
                            tool_calls.append(tool_call.get("name", "unknown"))
                        else:
                            tool_calls.append(getattr(tool_call, "name", "unknown"))
            
            if tool_calls:
                step_info["tool_calls"] = tool_calls
            
            summary["steps_summary"].append(step_info)
        
        # ä¿å­˜æ±‡æ€»æ–‡ä»¶
        summary_file = output_dir / "steps_summary.json"
        try:
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“Š [æ­¥éª¤æ±‡æ€»] å·²ä¿å­˜æ±‡æ€»æ–‡ä»¶: {summary_file}")
        except Exception as e:
            logger.error(f"âŒ [æ­¥éª¤æ±‡æ€»] ä¿å­˜æ±‡æ€»æ–‡ä»¶å¤±è´¥: {e}")
        
        # åŒæ—¶ä¿å­˜æ‰€æœ‰åºåˆ—åŒ–çš„chunkåˆ°ä¸€ä¸ªæ–‡ä»¶ï¼ˆä¾¿äºæŸ¥çœ‹ï¼‰
        all_steps_file = output_dir / "all_steps.json"
        try:
            with open(all_steps_file, 'w', encoding='utf-8') as f:
                json.dump(self.step_traces, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“Š [æ­¥éª¤æ±‡æ€»] å·²ä¿å­˜æ‰€æœ‰æ­¥éª¤åˆ°: {all_steps_file}")
        except Exception as e:
            logger.error(f"âŒ [æ­¥éª¤æ±‡æ€»] ä¿å­˜æ‰€æœ‰æ­¥éª¤å¤±è´¥: {e}")

    def _log_state(self, trade_date, final_state):
        """Log the final state to a JSON file."""
        self.log_states_dict[str(trade_date)] = {
            "company_of_interest": final_state["company_of_interest"],
            "trade_date": final_state["trade_date"],
            "market_report": final_state["market_report"],
            "sentiment_report": final_state["sentiment_report"],
            "news_report": final_state["news_report"],
            "fundamentals_report": final_state["fundamentals_report"],
            "investment_debate_state": {
                "bull_history": final_state["investment_debate_state"]["bull_history"],
                "bear_history": final_state["investment_debate_state"]["bear_history"],
                "history": final_state["investment_debate_state"]["history"],
                "current_response": final_state["investment_debate_state"][
                    "current_response"
                ],
                "judge_decision": final_state["investment_debate_state"][
                    "judge_decision"
                ],
            },
            "trader_investment_decision": final_state["trader_investment_plan"],
            "risk_debate_state": {
                "risky_history": final_state["risk_debate_state"]["risky_history"],
                "safe_history": final_state["risk_debate_state"]["safe_history"],
                "neutral_history": final_state["risk_debate_state"]["neutral_history"],
                "history": final_state["risk_debate_state"]["history"],
                "judge_decision": final_state["risk_debate_state"]["judge_decision"],
            },
            "investment_plan": final_state["investment_plan"],
            "final_trade_decision": final_state["final_trade_decision"],
        }

        # Save to file
        directory = Path(f"eval_results/{self.ticker}/TradingAgentsStrategy_logs/")
        directory.mkdir(parents=True, exist_ok=True)

        with open(
            f"eval_results/{self.ticker}/TradingAgentsStrategy_logs/full_states_log.json",
            "w",
        ) as f:
            json.dump(self.log_states_dict, f, indent=4)

    def reflect_and_remember(self, returns_losses):
        """Reflect on decisions and update memory based on returns."""
        self.reflector.reflect_bull_researcher(
            self.curr_state, returns_losses, self.bull_memory
        )
        self.reflector.reflect_bear_researcher(
            self.curr_state, returns_losses, self.bear_memory
        )
        self.reflector.reflect_trader(
            self.curr_state, returns_losses, self.trader_memory
        )
        self.reflector.reflect_invest_judge(
            self.curr_state, returns_losses, self.invest_judge_memory
        )
        self.reflector.reflect_risk_manager(
            self.curr_state, returns_losses, self.risk_manager_memory
        )

    def process_signal(self, full_signal, stock_symbol=None, analysis_id=None):
        """Process a signal to extract the core decision."""
        return self.signal_processor.process_signal(full_signal, stock_symbol, analysis_id=analysis_id)
