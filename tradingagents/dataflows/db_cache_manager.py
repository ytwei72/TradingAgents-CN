#!/usr/bin/env python3
"""
MongoDB + Redis æ•°æ®åº“ç¼“å­˜ç®¡ç†å™¨
æä¾›é«˜æ€§èƒ½çš„è‚¡ç¥¨æ•°æ®ç¼“å­˜å’ŒæŒä¹…åŒ–å­˜å‚¨
"""

import os
import json
import pickle
import hashlib
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List, Union
import pandas as pd

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('agents')

# MongoDB
try:
    from pymongo import MongoClient
    from pymongo.errors import ConnectionFailure, ServerSelectionTimeoutError
    MONGODB_AVAILABLE = True
except ImportError:
    MONGODB_AVAILABLE = False
    logger.warning(f"âš ï¸ pymongo æœªå®‰è£…ï¼ŒMongoDBåŠŸèƒ½ä¸å¯ç”¨")

# Redis - ä½¿ç”¨ç»Ÿä¸€çš„è¿æ¥ç®¡ç†
try:
    from tradingagents.storage.redis.connection import get_redis_client, REDIS_AVAILABLE
    REDIS_AVAILABLE = REDIS_AVAILABLE
except ImportError:
    REDIS_AVAILABLE = False
    logger.warning(f"âš ï¸ redis æœªå®‰è£…ï¼ŒRedisåŠŸèƒ½ä¸å¯ç”¨")


class DatabaseCacheManager:
    """MongoDB + Redis æ•°æ®åº“ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self,
                 redis_url: Optional[str] = None,
                 redis_db: int = 0):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç¼“å­˜ç®¡ç†å™¨

        Args:
            redis_url: Redisè¿æ¥URLï¼ˆå·²å¼ƒç”¨ï¼Œä½¿ç”¨ç»Ÿä¸€è¿æ¥ç®¡ç†ï¼‰
            redis_db: Redisæ•°æ®åº“ç¼–å·ï¼ˆå·²å¼ƒç”¨ï¼Œä½¿ç”¨ç»Ÿä¸€è¿æ¥ç®¡ç†ï¼‰
        """
        # ä½¿ç”¨ç»Ÿä¸€çš„ Redis è¿æ¥ç®¡ç†
        self.redis_client = None
        
        # åˆå§‹åŒ– MongoDB ç´¢å¼•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self._create_mongodb_indexes()
        self._init_redis()
        
        logger.info(f"ğŸ—„ï¸ æ•°æ®åº“ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   MongoDB: {'âœ… å¯ç”¨' if MONGODB_AVAILABLE else 'âŒ ä¸å¯ç”¨'}")
        logger.info(f"   Redis: {'âœ… å·²è¿æ¥' if self.redis_client else 'âŒ æœªè¿æ¥'}")
    
    def _init_redis(self):
        """åˆå§‹åŒ–Redisè¿æ¥ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„è¿æ¥ç®¡ç†ï¼‰"""
        if not REDIS_AVAILABLE:
            return
        
        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„ Redis è¿æ¥ç®¡ç†
            self.redis_client = get_redis_client()
            
            if self.redis_client:
                logger.info(f"âœ… Redisè¿æ¥æˆåŠŸï¼ˆä½¿ç”¨ç»Ÿä¸€è¿æ¥ç®¡ç†ï¼‰")
            else:
                logger.warning(f"âš ï¸ Redisè¿æ¥ä¸å¯ç”¨")
            
        except Exception as e:
            logger.error(f"âŒ Redisè¿æ¥å¤±è´¥: {e}")
            self.redis_client = None
    
    def _create_mongodb_indexes(self):
        """åˆ›å»ºMongoDBç´¢å¼•ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„è¿æ¥ç®¡ç†ï¼‰"""
        if not MONGODB_AVAILABLE:
            return
        
        try:
            from tradingagents.storage.manager import get_mongo_collection
            
            # è‚¡ç¥¨æ•°æ®é›†åˆç´¢å¼•
            stock_collection = get_mongo_collection("stock_data")
            if stock_collection:
                stock_collection.create_index([
                    ("symbol", 1),
                    ("data_source", 1),
                    ("start_date", 1),
                    ("end_date", 1)
                ])
                stock_collection.create_index([("created_at", 1)])
            
            # æ–°é—»æ•°æ®é›†åˆç´¢å¼•
            news_collection = get_mongo_collection("news_data")
            if news_collection:
                news_collection.create_index([
                    ("symbol", 1),
                    ("data_source", 1),
                    ("date_range", 1)
                ])
                news_collection.create_index([("created_at", 1)])
            
            # åŸºæœ¬é¢æ•°æ®é›†åˆç´¢å¼•
            fundamentals_collection = get_mongo_collection("fundamentals_data")
            if fundamentals_collection:
                fundamentals_collection.create_index([
                    ("symbol", 1),
                    ("data_source", 1),
                    ("analysis_date", 1)
                ])
                fundamentals_collection.create_index([("created_at", 1)])
            
            logger.info(f"âœ… MongoDBç´¢å¼•åˆ›å»ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"âš ï¸ MongoDBç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
    
    def _generate_cache_key(self, data_type: str, symbol: str, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        params_str = f"{data_type}_{symbol}"
        for key, value in sorted(kwargs.items()):
            params_str += f"_{key}_{value}"
        
        cache_key = hashlib.md5(params_str.encode()).hexdigest()[:16]
        return f"{data_type}:{symbol}:{cache_key}"
    
    def save_stock_data(self, symbol: str, data: Union[pd.DataFrame, str],
                       start_date: str = None, end_date: str = None,
                       data_source: str = "unknown", market_type: str = None) -> str:
        """
        ä¿å­˜è‚¡ç¥¨æ•°æ®åˆ°MongoDBå’ŒRedis
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data: è‚¡ç¥¨æ•°æ®
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            data_source: æ•°æ®æº
            market_type: å¸‚åœºç±»å‹ (us/china)
        
        Returns:
            cache_key: ç¼“å­˜é”®
        """
        cache_key = self._generate_cache_key("stock", symbol,
                                           start_date=start_date,
                                           end_date=end_date,
                                           source=data_source)
        
        # è‡ªåŠ¨æ¨æ–­å¸‚åœºç±»å‹
        if market_type is None:
            # æ ¹æ®è‚¡ç¥¨ä»£ç æ ¼å¼æ¨æ–­å¸‚åœºç±»å‹
            import re

            if re.match(r'^\d{6}$', symbol):  # 6ä½æ•°å­—ä¸ºAè‚¡
                market_type = "china"
            else:  # å…¶ä»–æ ¼å¼ä¸ºç¾è‚¡
                market_type = "us"
        
        # å‡†å¤‡æ–‡æ¡£æ•°æ®
        doc = {
            "_id": cache_key,
            "symbol": symbol,
            "market_type": market_type,
            "data_type": "stock_data",
            "start_date": start_date,
            "end_date": end_date,
            "data_source": data_source,
            "created_at": datetime.utcnow(),
            "updated_at": datetime.utcnow()
        }
        
        # å¤„ç†æ•°æ®æ ¼å¼
        if isinstance(data, pd.DataFrame):
            doc["data"] = data.to_json(orient='records', date_format='iso')
            doc["data_format"] = "dataframe_json"
        else:
            doc["data"] = str(data)
            doc["data_format"] = "text"
        
        # ä¿å­˜åˆ°MongoDBï¼ˆæŒä¹…åŒ–ï¼‰
        if MONGODB_AVAILABLE:
            try:
                from tradingagents.storage.manager import get_mongo_collection
                collection = get_mongo_collection("stock_data")
                if collection:
                    collection.replace_one({"_id": cache_key}, doc, upsert=True)
                    logger.info(f"ğŸ’¾ è‚¡ç¥¨æ•°æ®å·²ä¿å­˜åˆ°MongoDB: {symbol} -> {cache_key}")
            except Exception as e:
                logger.error(f"âš ï¸ MongoDBä¿å­˜å¤±è´¥: {e}")
        
        # ä¿å­˜åˆ°Redisï¼ˆå¿«é€Ÿç¼“å­˜ï¼Œ6å°æ—¶è¿‡æœŸï¼‰
        if self.redis_client:
            try:
                redis_data = {
                    "data": doc["data"],
                    "data_format": doc["data_format"],
                    "symbol": symbol,
                    "data_source": data_source,
                    "created_at": doc["created_at"].isoformat()
                }
                self.redis_client.setex(
                    cache_key,
                    6 * 3600,  # 6å°æ—¶è¿‡æœŸ
                    json.dumps(redis_data, ensure_ascii=False)
                )
                logger.info(f"âš¡ è‚¡ç¥¨æ•°æ®å·²ç¼“å­˜åˆ°Redis: {symbol} -> {cache_key}")
            except Exception as e:
                logger.error(f"âš ï¸ Redisç¼“å­˜å¤±è´¥: {e}")
        
        return cache_key
    
    def load_stock_data(self, cache_key: str) -> Optional[Union[pd.DataFrame, str]]:
        """ä»Redisæˆ–MongoDBåŠ è½½è‚¡ç¥¨æ•°æ®"""
        
        # é¦–å…ˆå°è¯•ä»RedisåŠ è½½ï¼ˆæ›´å¿«ï¼‰
        if self.redis_client:
            try:
                redis_data = self.redis_client.get(cache_key)
                if redis_data:
                    data_dict = json.loads(redis_data)
                    logger.info(f"âš¡ ä»RedisåŠ è½½æ•°æ®: {cache_key}")
                    
                    if data_dict["data_format"] == "dataframe_json":
                        return pd.read_json(data_dict["data"], orient='records')
                    else:
                        return data_dict["data"]
            except Exception as e:
                logger.error(f"âš ï¸ RedisåŠ è½½å¤±è´¥: {e}")
        
        # å¦‚æœRedisæ²¡æœ‰ï¼Œä»MongoDBåŠ è½½
        if MONGODB_AVAILABLE:
            try:
                from tradingagents.storage.manager import get_mongo_collection
                collection = get_mongo_collection("stock_data")
                if collection:
                    doc = collection.find_one({"_id": cache_key})
                    
                    if doc:
                        logger.info(f"ğŸ’¾ ä»MongoDBåŠ è½½æ•°æ®: {cache_key}")
                        
                        # åŒæ—¶æ›´æ–°åˆ°Redisç¼“å­˜
                        if self.redis_client:
                            try:
                                redis_data = {
                                    "data": doc["data"],
                                    "data_format": doc["data_format"],
                                    "symbol": doc["symbol"],
                                    "data_source": doc["data_source"],
                                    "created_at": doc["created_at"].isoformat()
                                }
                                self.redis_client.setex(
                                    cache_key,
                                    6 * 3600,
                                    json.dumps(redis_data, ensure_ascii=False)
                                )
                                logger.info(f"âš¡ æ•°æ®å·²åŒæ­¥åˆ°Redisç¼“å­˜")
                            except Exception as e:
                                logger.error(f"âš ï¸ RedisåŒæ­¥å¤±è´¥: {e}")
                        
                        if doc["data_format"] == "dataframe_json":
                            return pd.read_json(doc["data"], orient='records')
                        else:
                            return doc["data"]
                        
            except Exception as e:
                logger.error(f"âš ï¸ MongoDBåŠ è½½å¤±è´¥: {e}")
        
        return None
    
    def find_cached_stock_data(self, symbol: str, start_date: str = None,
                              end_date: str = None, data_source: str = None,
                              max_age_hours: int = 6) -> Optional[str]:
        """æŸ¥æ‰¾åŒ¹é…çš„ç¼“å­˜æ•°æ®"""
        
        # ç”Ÿæˆç²¾ç¡®åŒ¹é…çš„ç¼“å­˜é”®
        exact_key = self._generate_cache_key("stock", symbol,
                                           start_date=start_date,
                                           end_date=end_date,
                                           source=data_source)
        
        # æ£€æŸ¥Redisä¸­æ˜¯å¦æœ‰ç²¾ç¡®åŒ¹é…
        if self.redis_client and self.redis_client.exists(exact_key):
            logger.info(f"âš¡ Redisä¸­æ‰¾åˆ°ç²¾ç¡®åŒ¹é…: {symbol} -> {exact_key}")
            return exact_key
        
        # æ£€æŸ¥MongoDBä¸­çš„åŒ¹é…é¡¹
        if MONGODB_AVAILABLE:
            try:
                from tradingagents.storage.manager import get_mongo_collection
                collection = get_mongo_collection("stock_data")
                if collection:
                    cutoff_time = datetime.utcnow() - timedelta(hours=max_age_hours)
                    
                    query = {
                        "symbol": symbol,
                        "created_at": {"$gte": cutoff_time}
                    }
                    
                    if data_source:
                        query["data_source"] = data_source
                    if start_date:
                        query["start_date"] = start_date
                    if end_date:
                        query["end_date"] = end_date
                    
                    doc = collection.find_one(query, sort=[("created_at", -1)])
                    
                    if doc:
                        cache_key = doc["_id"]
                        logger.info(f"ğŸ’¾ MongoDBä¸­æ‰¾åˆ°åŒ¹é…: {symbol} -> {cache_key}")
                        return cache_key
                        
            except Exception as e:
                logger.error(f"âš ï¸ MongoDBæŸ¥è¯¢å¤±è´¥: {e}")
        
        logger.error(f"âŒ æœªæ‰¾åˆ°æœ‰æ•ˆç¼“å­˜: {symbol}")
        return None

    def save_news_data(self, symbol: str, news_data: str,
                      start_date: str = None, end_date: str = None,
                      data_source: str = "unknown") -> str:
        """ä¿å­˜æ–°é—»æ•°æ®åˆ°MongoDBå’ŒRedis"""
        cache_key = self._generate_cache_key("news", symbol,
                                           start_date=start_date,
                                           end_date=end_date,
                                           source=data_source)

        doc = {
            "_id": cache_key,
            "symbol": symbol,
            "data_type": "news_data",
            "date_range": f"{start_date}_{end_date}",
            "start_date": start_date,
            "end_date": end_date,
            "data_source": data_source,
            "data": news_data,
            "created_at": datetime.utcnow(),
            "updated_at": datetime.utcnow()
        }

        # ä¿å­˜åˆ°MongoDB
        if MONGODB_AVAILABLE:
            try:
                from tradingagents.storage.manager import get_mongo_collection
                collection = get_mongo_collection("news_data")
                if collection:
                    collection.replace_one({"_id": cache_key}, doc, upsert=True)
                    logger.info(f"ğŸ“° æ–°é—»æ•°æ®å·²ä¿å­˜åˆ°MongoDB: {symbol} -> {cache_key}")
            except Exception as e:
                logger.error(f"âš ï¸ MongoDBä¿å­˜å¤±è´¥: {e}")

        # ä¿å­˜åˆ°Redisï¼ˆ24å°æ—¶è¿‡æœŸï¼‰
        if self.redis_client:
            try:
                redis_data = {
                    "data": news_data,
                    "symbol": symbol,
                    "data_source": data_source,
                    "created_at": doc["created_at"].isoformat()
                }
                self.redis_client.setex(
                    cache_key,
                    24 * 3600,  # 24å°æ—¶è¿‡æœŸ
                    json.dumps(redis_data, ensure_ascii=False)
                )
                logger.info(f"âš¡ æ–°é—»æ•°æ®å·²ç¼“å­˜åˆ°Redis: {symbol} -> {cache_key}")
            except Exception as e:
                logger.error(f"âš ï¸ Redisç¼“å­˜å¤±è´¥: {e}")

        return cache_key

    def save_fundamentals_data(self, symbol: str, fundamentals_data: str,
                              analysis_date: str = None,
                              data_source: str = "unknown") -> str:
        """ä¿å­˜åŸºæœ¬é¢æ•°æ®åˆ°MongoDBå’ŒRedis"""
        if not analysis_date:
            analysis_date = datetime.now().strftime("%Y-%m-%d")

        cache_key = self._generate_cache_key("fundamentals", symbol,
                                           date=analysis_date,
                                           source=data_source)

        doc = {
            "_id": cache_key,
            "symbol": symbol,
            "data_type": "fundamentals_data",
            "analysis_date": analysis_date,
            "data_source": data_source,
            "data": fundamentals_data,
            "created_at": datetime.utcnow(),
            "updated_at": datetime.utcnow()
        }

        # ä¿å­˜åˆ°MongoDB
        if MONGODB_AVAILABLE:
            try:
                from tradingagents.storage.manager import get_mongo_collection
                collection = get_mongo_collection("fundamentals_data")
                if collection:
                    collection.replace_one({"_id": cache_key}, doc, upsert=True)
                    logger.info(f"ğŸ’¼ åŸºæœ¬é¢æ•°æ®å·²ä¿å­˜åˆ°MongoDB: {symbol} -> {cache_key}")
            except Exception as e:
                logger.error(f"âš ï¸ MongoDBä¿å­˜å¤±è´¥: {e}")

        # ä¿å­˜åˆ°Redisï¼ˆ24å°æ—¶è¿‡æœŸï¼‰
        if self.redis_client:
            try:
                redis_data = {
                    "data": fundamentals_data,
                    "symbol": symbol,
                    "data_source": data_source,
                    "analysis_date": analysis_date,
                    "created_at": doc["created_at"].isoformat()
                }
                self.redis_client.setex(
                    cache_key,
                    24 * 3600,  # 24å°æ—¶è¿‡æœŸ
                    json.dumps(redis_data, ensure_ascii=False)
                )
                logger.info(f"âš¡ åŸºæœ¬é¢æ•°æ®å·²ç¼“å­˜åˆ°Redis: {symbol} -> {cache_key}")
            except Exception as e:
                logger.error(f"âš ï¸ Redisç¼“å­˜å¤±è´¥: {e}")

        return cache_key

    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        from tradingagents.storage.manager import get_mongodb_db, is_mongodb_available
        
        stats = {
            "mongodb": {"available": is_mongodb_available(), "collections": {}},
            "redis": {"available": self.redis_client is not None, "keys": 0, "memory_usage": "N/A"}
        }

        # MongoDBç»Ÿè®¡
        if MONGODB_AVAILABLE and is_mongodb_available():
            try:
                from tradingagents.storage.manager import get_mongo_collection, get_mongodb_db
                db = get_mongodb_db()
                if db:
                    for collection_name in ["stock_data", "news_data", "fundamentals_data"]:
                        collection = get_mongo_collection(collection_name)
                        if collection:
                            count = collection.count_documents({})
                            size = db.command("collStats", collection_name).get("size", 0)
                            stats["mongodb"]["collections"][collection_name] = {
                                "count": count,
                                "size_mb": round(size / (1024 * 1024), 2)
                            }
            except Exception as e:
                logger.error(f"âš ï¸ MongoDBç»Ÿè®¡è·å–å¤±è´¥: {e}")

        # Redisç»Ÿè®¡
        if self.redis_client:
            try:
                info = self.redis_client.info()
                stats["redis"]["keys"] = info.get("db0", {}).get("keys", 0)
                stats["redis"]["memory_usage"] = f"{info.get('used_memory_human', 'N/A')}"
            except Exception as e:
                logger.error(f"âš ï¸ Redisç»Ÿè®¡è·å–å¤±è´¥: {e}")

        return stats

    def clear_old_cache(self, max_age_days: int = 7):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        cutoff_time = datetime.utcnow() - timedelta(days=max_age_days)
        cleared_count = 0

        # æ¸…ç†MongoDB
        if MONGODB_AVAILABLE:
            try:
                from tradingagents.storage.manager import get_mongo_collection
                for collection_name in ["stock_data", "news_data", "fundamentals_data"]:
                    collection = get_mongo_collection(collection_name)
                    if collection:
                        result = collection.delete_many({"created_at": {"$lt": cutoff_time}})
                        cleared_count += result.deleted_count
                        logger.info(f"ğŸ§¹ MongoDB {collection_name} æ¸…ç†äº† {result.deleted_count} æ¡è®°å½•")
            except Exception as e:
                logger.error(f"âš ï¸ MongoDBæ¸…ç†å¤±è´¥: {e}")

        # Redisä¼šè‡ªåŠ¨è¿‡æœŸï¼Œä¸éœ€è¦æ‰‹åŠ¨æ¸…ç†
        logger.info(f"ğŸ§¹ æ€»å…±æ¸…ç†äº† {cleared_count} æ¡è¿‡æœŸè®°å½•")
        return cleared_count

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥ï¼ˆMongoDBå’ŒRedisè¿æ¥ç”±ç»Ÿä¸€ç®¡ç†å™¨ç®¡ç†ï¼Œæ— éœ€æ‰‹åŠ¨å…³é—­ï¼‰"""
        # Redis è¿æ¥ç”±ç»Ÿä¸€ç®¡ç†å™¨ç®¡ç†ï¼Œä¸éœ€è¦æ‰‹åŠ¨å…³é—­
        logger.info(f"ğŸ”’ æ•°æ®åº“ç¼“å­˜ç®¡ç†å™¨å·²å…³é—­ï¼ˆè¿æ¥ç”±ç»Ÿä¸€ç®¡ç†å™¨ç®¡ç†ï¼‰")


# å…¨å±€æ•°æ®åº“ç¼“å­˜å®ä¾‹
_db_cache_instance = None

def get_db_cache() -> DatabaseCacheManager:
    """è·å–å…¨å±€æ•°æ®åº“ç¼“å­˜å®ä¾‹"""
    global _db_cache_instance
    if _db_cache_instance is None:
        _db_cache_instance = DatabaseCacheManager()
    return _db_cache_instance
